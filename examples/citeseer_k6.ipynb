{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycq/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP,CHGNN\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\t\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "weight = 50\n",
    "\"\"\"\n",
    "h_hyper_prmts[\"convlayers11\"] = {\"in_channels\": 2048, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "# h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 1024, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 2048, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.05}\n",
    "\n",
    "l_hyper_prmts[\"linerlayer113\"] = {\"in_channels\":2048, \"out_channels\":2048, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer13\"] = {\"in_channels\":2048, \"out_channels\":1024, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer12334\"] = {\"in_channels\":512, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer123\"] = {\"in_channels\":256, \"out_channels\":128, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer121\"] = {\"in_channels\":128, \"out_channels\":64, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer31\"] = {\"in_channels\":64, \"out_channels\":2, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "\"\"\"\n",
    "\n",
    "partitions = 6\n",
    "\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 1019, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers12\"] = {\"in_channels\": 512, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers13\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers2\"] = {\"in_channels\": 256, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers3\"] = {\"in_channels\": 256, \"out_channels\": 128, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers5\"] = {\"in_channels\": 128, \"out_channels\": 64, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers51\"] = {\"in_channels\": 64, \"out_channels\": 128, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "#h_hyper_prmts[\"convlayers52\"] = {\"in_channels\": 128, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "#h_hyper_prmts[\"convlayers53\"] = {\"in_channels\": 32, \"out_channels\": 64, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "#h_hyper_prmts[\"convlayers54\"] = {\"in_channels\": 256, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "#h_hyper_prmts[\"convlayers55\"] = {\"in_channels\": 512, \"out_channels\": 64, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "\n",
    "\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":list(h_hyper_prmts.values())[-1][\"out_channels\"], \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":32, \"out_channels\":64, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer2\"] = {\"in_channels\":64, \"out_channels\":128, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer21\"] = {\"in_channels\":128, \"out_channels\":256, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer22\"] = {\"in_channels\":256, \"out_channels\":512, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer23\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer24\"] = {\"in_channels\":64, \"out_channels\":64, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer33\"] = {\"in_channels\":64, \"out_channels\":32, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer4\"] = {\"in_channels\":64, \"out_channels\":6, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device,weight):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "    loss = weight * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        self.weight = 200\n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE,weight=self.weight)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 1019)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hgp.utils\n",
    "G = hgp.utils.from_pickle_to_hypergraph(\"../data/citeseer\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGNNP(\n",
       "    (layers): ModuleList(\n",
       "      (0): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (theta): Linear(in_features=1019, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (4): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (5): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): HGNNPConv(\n",
       "        (act): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (theta): Linear(in_features=64, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.05, inplace=False)\n",
       "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.05, inplace=False)\n",
       "  (8): Linear(in_features=64, out_features=6, bias=True)\n",
       "  (9): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "# X = torch.eye(hyper[\"init_features_dim\"])\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    if v[\"drop_rate\"] > 0:\n",
    "        hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgnn_trainer.layers\n",
    "# for n,p in hgnn_trainer.named_parameters():\n",
    "#     print(n,p)\n",
    "hgnn_trainer.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: 92.59871826171874\n",
      "                , loss1: -1.3355069160461426\n",
      "                , loss2: 159.3727294921875\n",
      "                , weight: 49.999\n",
      "=================================\n",
      "in 10 epoch, average loss: 205.6124267578125\n",
      "                , loss1: -13.382679748535157\n",
      "                , loss2: 874.65859375\n",
      "                , weight: 49.989000000000026\n",
      "=================================\n",
      "in 20 epoch, average loss: -1055.61953125\n",
      "                , loss1: -24.65185089111328\n",
      "                , loss2: 176.5418701171875\n",
      "                , weight: 49.97900000000005\n",
      "=================================\n",
      "in 30 epoch, average loss: -3053.519921875\n",
      "                , loss1: -62.04121704101563\n",
      "                , loss2: 46.85982666015625\n",
      "                , weight: 49.96900000000007\n",
      "=================================\n",
      "in 40 epoch, average loss: -4680.309765625\n",
      "                , loss1: -95.2061767578125\n",
      "                , loss2: 76.49659423828125\n",
      "                , weight: 49.959000000000096\n",
      "=================================\n",
      "in 50 epoch, average loss: -6445.75234375\n",
      "                , loss1: -132.7980712890625\n",
      "                , loss2: 187.95718994140626\n",
      "                , weight: 49.94900000000012\n",
      "=================================\n",
      "in 60 epoch, average loss: -7162.4421875\n",
      "                , loss1: -146.489111328125\n",
      "                , loss2: 153.72705078125\n",
      "                , weight: 49.93900000000014\n",
      "=================================\n",
      "in 70 epoch, average loss: -7705.559375\n",
      "                , loss1: -157.2383056640625\n",
      "                , loss2: 145.88883056640626\n",
      "                , weight: 49.929000000000165\n",
      "=================================\n",
      "in 80 epoch, average loss: -8474.0015625\n",
      "                , loss1: -174.50438232421874\n",
      "                , loss2: 237.845654296875\n",
      "                , weight: 49.91900000000019\n",
      "=================================\n",
      "in 90 epoch, average loss: -9720.19375\n",
      "                , loss1: -200.8063720703125\n",
      "                , loss2: 302.73662109375\n",
      "                , weight: 49.90900000000021\n",
      "=================================\n",
      "in 100 epoch, average loss: -10860.52421875\n",
      "                , loss1: -223.7583984375\n",
      "                , loss2: 305.7872802734375\n",
      "                , weight: 49.899000000000235\n",
      "=================================\n",
      "in 110 epoch, average loss: -11754.86328125\n",
      "                , loss1: -239.649169921875\n",
      "                , loss2: 202.06185302734374\n",
      "                , weight: 49.88900000000026\n",
      "=================================\n",
      "in 120 epoch, average loss: -12409.946875\n",
      "                , loss1: -252.073876953125\n",
      "                , loss2: 164.372265625\n",
      "                , weight: 49.87900000000028\n",
      "=================================\n",
      "in 130 epoch, average loss: -12958.946875\n",
      "                , loss1: -262.6534912109375\n",
      "                , loss2: 140.494873046875\n",
      "                , weight: 49.869000000000305\n",
      "=================================\n",
      "in 140 epoch, average loss: -13273.959375\n",
      "                , loss1: -268.2280029296875\n",
      "                , loss2: 100.8237060546875\n",
      "                , weight: 49.85900000000033\n",
      "=================================\n",
      "in 150 epoch, average loss: -13515.58125\n",
      "                , loss1: -272.553125\n",
      "                , loss2: 72.14298706054687\n",
      "                , weight: 49.84900000000035\n",
      "=================================\n",
      "in 160 epoch, average loss: -13704.546875\n",
      "                , loss1: -275.876513671875\n",
      "                , loss2: 46.10104675292969\n",
      "                , weight: 49.839000000000375\n",
      "=================================\n",
      "in 170 epoch, average loss: -13909.1171875\n",
      "                , loss1: -279.944921875\n",
      "                , loss2: 41.51130981445313\n",
      "                , weight: 49.8290000000004\n",
      "=================================\n",
      "in 180 epoch, average loss: -14865.315625\n",
      "                , loss1: -307.4002685546875\n",
      "                , loss2: 450.40986328125\n",
      "                , weight: 49.81900000000042\n",
      "=================================\n",
      "in 190 epoch, average loss: -15584.1703125\n",
      "                , loss1: -325.361767578125\n",
      "                , loss2: 623.231298828125\n",
      "                , weight: 49.809000000000445\n",
      "=================================\n",
      "in 200 epoch, average loss: -15972.2640625\n",
      "                , loss1: -329.9722412109375\n",
      "                , loss2: 461.5048828125\n",
      "                , weight: 49.79900000000047\n",
      "=================================\n",
      "in 210 epoch, average loss: -16225.7109375\n",
      "                , loss1: -333.5025146484375\n",
      "                , loss2: 380.5415771484375\n",
      "                , weight: 49.78900000000049\n",
      "=================================\n",
      "in 220 epoch, average loss: -16406.9859375\n",
      "                , loss1: -336.704638671875\n",
      "                , loss2: 355.3477294921875\n",
      "                , weight: 49.779000000000515\n",
      "=================================\n",
      "in 230 epoch, average loss: -16538.934375\n",
      "                , loss1: -339.2351806640625\n",
      "                , loss2: 345.986083984375\n",
      "                , weight: 49.76900000000054\n",
      "=================================\n",
      "in 240 epoch, average loss: -16664.3921875\n",
      "                , loss1: -341.191455078125\n",
      "                , loss2: 314.4889404296875\n",
      "                , weight: 49.75900000000056\n",
      "=================================\n",
      "in 250 epoch, average loss: -16757.3578125\n",
      "                , loss1: -342.91923828125\n",
      "                , loss2: 304.0719482421875\n",
      "                , weight: 49.749000000000585\n",
      "=================================\n",
      "in 260 epoch, average loss: -16853.4625\n",
      "                , loss1: -344.1626953125\n",
      "                , loss2: 266.393212890625\n",
      "                , weight: 49.73900000000061\n",
      "=================================\n",
      "in 270 epoch, average loss: -17004.31875\n",
      "                , loss1: -346.910595703125\n",
      "                , loss2: 248.755908203125\n",
      "                , weight: 49.72900000000063\n",
      "=================================\n",
      "in 280 epoch, average loss: -17271.109375\n",
      "                , loss1: -351.995947265625\n",
      "                , loss2: 231.354638671875\n",
      "                , weight: 49.719000000000655\n",
      "=================================\n",
      "in 290 epoch, average loss: -17407.3671875\n",
      "                , loss1: -354.3939453125\n",
      "                , loss2: 210.797216796875\n",
      "                , weight: 49.70900000000068\n",
      "=================================\n",
      "in 300 epoch, average loss: -17472.8625\n",
      "                , loss1: -355.450048828125\n",
      "                , loss2: 194.24813232421874\n",
      "                , weight: 49.6990000000007\n",
      "=================================\n",
      "in 310 epoch, average loss: -17524.4984375\n",
      "                , loss1: -356.1839111328125\n",
      "                , loss2: 175.52584228515624\n",
      "                , weight: 49.689000000000725\n",
      "=================================\n",
      "in 320 epoch, average loss: -17570.128125\n",
      "                , loss1: -357.0372314453125\n",
      "                , loss2: 168.73145751953126\n",
      "                , weight: 49.67900000000075\n",
      "=================================\n",
      "in 330 epoch, average loss: -17611.0734375\n",
      "                , loss1: -357.79521484375\n",
      "                , loss2: 161.86903076171876\n",
      "                , weight: 49.66900000000077\n",
      "=================================\n",
      "in 340 epoch, average loss: -17637.9484375\n",
      "                , loss1: -358.23798828125\n",
      "                , loss2: 153.40281982421874\n",
      "                , weight: 49.659000000000795\n",
      "=================================\n",
      "in 350 epoch, average loss: -17667.3875\n",
      "                , loss1: -358.845068359375\n",
      "                , loss2: 150.5257568359375\n",
      "                , weight: 49.64900000000082\n",
      "=================================\n",
      "in 360 epoch, average loss: -17700.434375\n",
      "                , loss1: -359.497265625\n",
      "                , loss2: 146.2667236328125\n",
      "                , weight: 49.63900000000084\n",
      "=================================\n",
      "in 370 epoch, average loss: -17738.1734375\n",
      "                , loss1: -360.1780029296875\n",
      "                , loss2: 138.7209228515625\n",
      "                , weight: 49.629000000000865\n",
      "=================================\n",
      "in 380 epoch, average loss: -17777.6828125\n",
      "                , loss1: -361.070947265625\n",
      "                , loss2: 139.920263671875\n",
      "                , weight: 49.61900000000089\n",
      "=================================\n",
      "in 390 epoch, average loss: -17887.696875\n",
      "                , loss1: -363.8748046875\n",
      "                , loss2: 165.4034423828125\n",
      "                , weight: 49.60900000000091\n",
      "=================================\n",
      "in 400 epoch, average loss: -18444.890625\n",
      "                , loss1: -376.3284423828125\n",
      "                , loss2: 222.3005126953125\n",
      "                , weight: 49.599000000000935\n",
      "=================================\n",
      "in 410 epoch, average loss: -19948.39375\n",
      "                , loss1: -407.2283447265625\n",
      "                , loss2: 247.4559814453125\n",
      "                , weight: 49.58900000000096\n",
      "=================================\n",
      "in 420 epoch, average loss: -21480.9171875\n",
      "                , loss1: -439.37958984375\n",
      "                , loss2: 305.0356201171875\n",
      "                , weight: 49.57900000000098\n",
      "=================================\n",
      "in 430 epoch, average loss: -22827.8859375\n",
      "                , loss1: -468.2033203125\n",
      "                , loss2: 382.5712158203125\n",
      "                , weight: 49.569000000001004\n",
      "=================================\n",
      "in 440 epoch, average loss: -23816.2640625\n",
      "                , loss1: -488.861669921875\n",
      "                , loss2: 413.410546875\n",
      "                , weight: 49.55900000000103\n",
      "=================================\n",
      "in 450 epoch, average loss: -24468.2203125\n",
      "                , loss1: -500.454443359375\n",
      "                , loss2: 331.0419921875\n",
      "                , weight: 49.54900000000105\n",
      "=================================\n",
      "in 460 epoch, average loss: -24787.4875\n",
      "                , loss1: -506.62431640625\n",
      "                , loss2: 312.4509521484375\n",
      "                , weight: 49.539000000001074\n",
      "=================================\n",
      "in 470 epoch, average loss: -25044.2515625\n",
      "                , loss1: -512.2203125\n",
      "                , loss2: 327.80615234375\n",
      "                , weight: 49.5290000000011\n",
      "=================================\n",
      "in 480 epoch, average loss: -25232.484375\n",
      "                , loss1: -515.75361328125\n",
      "                , loss2: 309.4353759765625\n",
      "                , weight: 49.51900000000112\n",
      "=================================\n",
      "in 490 epoch, average loss: -25419.0671875\n",
      "                , loss1: -519.257080078125\n",
      "                , loss2: 291.167724609375\n",
      "                , weight: 49.509000000001144\n",
      "=================================\n",
      "in 500 epoch, average loss: -25796.134375\n",
      "                , loss1: -526.826513671875\n",
      "                , loss2: 283.60673828125\n",
      "                , weight: 49.49900000000117\n",
      "=================================\n",
      "in 510 epoch, average loss: -27512.7125\n",
      "                , loss1: -561.01728515625\n",
      "                , loss2: 253.9556396484375\n",
      "                , weight: 49.48900000000119\n",
      "=================================\n",
      "in 520 epoch, average loss: -29589.340625\n",
      "                , loss1: -602.69638671875\n",
      "                , loss2: 234.158544921875\n",
      "                , weight: 49.479000000001214\n",
      "=================================\n",
      "in 530 epoch, average loss: -30855.828125\n",
      "                , loss1: -628.70234375\n",
      "                , loss2: 248.25966796875\n",
      "                , weight: 49.46900000000124\n",
      "=================================\n",
      "in 540 epoch, average loss: -31674.0125\n",
      "                , loss1: -645.304638671875\n",
      "                , loss2: 245.0039306640625\n",
      "                , weight: 49.45900000000126\n",
      "=================================\n",
      "in 550 epoch, average loss: -32173.846875\n",
      "                , loss1: -655.703173828125\n",
      "                , loss2: 252.9618408203125\n",
      "                , weight: 49.449000000001284\n",
      "=================================\n",
      "in 560 epoch, average loss: -32638.63125\n",
      "                , loss1: -663.90185546875\n",
      "                , loss2: 186.9923828125\n",
      "                , weight: 49.43900000000131\n",
      "=================================\n",
      "in 570 epoch, average loss: -32916.60625\n",
      "                , loss1: -669.6287109375\n",
      "                , loss2: 185.4837158203125\n",
      "                , weight: 49.42900000000133\n",
      "=================================\n",
      "in 580 epoch, average loss: -33069.3125\n",
      "                , loss1: -672.64921875\n",
      "                , loss2: 175.3637939453125\n",
      "                , weight: 49.419000000001354\n",
      "=================================\n",
      "in 590 epoch, average loss: -33219.603125\n",
      "                , loss1: -675.762158203125\n",
      "                , loss2: 172.16693115234375\n",
      "                , weight: 49.40900000000138\n",
      "=================================\n",
      "in 600 epoch, average loss: -33326.66875\n",
      "                , loss1: -678.033447265625\n",
      "                , loss2: 170.5523193359375\n",
      "                , weight: 49.3990000000014\n",
      "=================================\n",
      "in 610 epoch, average loss: -33391.759375\n",
      "                , loss1: -679.458935546875\n",
      "                , loss2: 169.0971923828125\n",
      "                , weight: 49.389000000001424\n",
      "=================================\n",
      "in 620 epoch, average loss: -33466.240625\n",
      "                , loss1: -681.03349609375\n",
      "                , loss2: 165.5782470703125\n",
      "                , weight: 49.37900000000145\n",
      "=================================\n",
      "in 630 epoch, average loss: -33502.334375\n",
      "                , loss1: -681.991943359375\n",
      "                , loss2: 169.99403076171876\n",
      "                , weight: 49.36900000000147\n",
      "=================================\n",
      "in 640 epoch, average loss: -33546.078125\n",
      "                , loss1: -682.945751953125\n",
      "                , loss2: 166.50947265625\n",
      "                , weight: 49.359000000001494\n",
      "=================================\n",
      "in 650 epoch, average loss: -33569.390625\n",
      "                , loss1: -683.541748046875\n",
      "                , loss2: 165.7830810546875\n",
      "                , weight: 49.34900000000152\n",
      "=================================\n",
      "in 660 epoch, average loss: -33602.4\n",
      "                , loss1: -684.276123046875\n",
      "                , loss2: 162.17603759765626\n",
      "                , weight: 49.33900000000154\n",
      "=================================\n",
      "in 670 epoch, average loss: -33628.60625\n",
      "                , loss1: -684.937890625\n",
      "                , loss2: 161.77677001953126\n",
      "                , weight: 49.329000000001564\n",
      "=================================\n",
      "in 680 epoch, average loss: -33635.03125\n",
      "                , loss1: -685.074072265625\n",
      "                , loss2: 155.22108154296876\n",
      "                , weight: 49.31900000000159\n",
      "=================================\n",
      "in 690 epoch, average loss: -33667.19375\n",
      "                , loss1: -685.868798828125\n",
      "                , loss2: 155.39473876953124\n",
      "                , weight: 49.30900000000161\n",
      "=================================\n",
      "in 700 epoch, average loss: -33677.934375\n",
      "                , loss1: -686.13515625\n",
      "                , loss2: 150.93104248046876\n",
      "                , weight: 49.299000000001634\n",
      "=================================\n",
      "in 710 epoch, average loss: -33698.053125\n",
      "                , loss1: -686.665234375\n",
      "                , loss2: 150.079345703125\n",
      "                , weight: 49.28900000000166\n",
      "=================================\n",
      "in 720 epoch, average loss: -33725.528125\n",
      "                , loss1: -687.75361328125\n",
      "                , loss2: 169.3777099609375\n",
      "                , weight: 49.27900000000168\n",
      "=================================\n",
      "in 730 epoch, average loss: -33740.615625\n",
      "                , loss1: -688.106298828125\n",
      "                , loss2: 164.79232177734374\n",
      "                , weight: 49.269000000001704\n",
      "=================================\n",
      "in 740 epoch, average loss: -33747.271875\n",
      "                , loss1: -688.37275390625\n",
      "                , loss2: 164.3767822265625\n",
      "                , weight: 49.25900000000173\n",
      "=================================\n",
      "in 750 epoch, average loss: -33755.08125\n",
      "                , loss1: -688.67646484375\n",
      "                , loss2: 164.64674072265626\n",
      "                , weight: 49.24900000000175\n",
      "=================================\n",
      "in 760 epoch, average loss: -33752.1125\n",
      "                , loss1: -688.88212890625\n",
      "                , loss2: 170.8537841796875\n",
      "                , weight: 49.239000000001774\n",
      "=================================\n",
      "in 770 epoch, average loss: -33762.20625\n",
      "                , loss1: -689.174462890625\n",
      "                , loss2: 168.26666259765625\n",
      "                , weight: 49.2290000000018\n",
      "=================================\n",
      "in 780 epoch, average loss: -33767.696875\n",
      "                , loss1: -689.25947265625\n",
      "                , loss2: 160.06395263671874\n",
      "                , weight: 49.21900000000182\n",
      "=================================\n",
      "in 790 epoch, average loss: -33777.315625\n",
      "                , loss1: -689.578564453125\n",
      "                , loss2: 159.25498046875\n",
      "                , weight: 49.20900000000184\n",
      "=================================\n",
      "in 800 epoch, average loss: -33785.878125\n",
      "                , loss1: -689.87158203125\n",
      "                , loss2: 158.22442626953125\n",
      "                , weight: 49.19900000000187\n",
      "=================================\n",
      "in 810 epoch, average loss: -33783.75625\n",
      "                , loss1: -689.981591796875\n",
      "                , loss2: 158.85364990234376\n",
      "                , weight: 49.18900000000189\n",
      "=================================\n",
      "in 820 epoch, average loss: -33781.628125\n",
      "                , loss1: -690.1353515625\n",
      "                , loss2: 161.6459716796875\n",
      "                , weight: 49.17900000000191\n",
      "=================================\n",
      "in 830 epoch, average loss: -33782.009375\n",
      "                , loss1: -690.3064453125\n",
      "                , loss2: 162.7744873046875\n",
      "                , weight: 49.16900000000194\n",
      "=================================\n",
      "in 840 epoch, average loss: -33782.978125\n",
      "                , loss1: -690.426708984375\n",
      "                , loss2: 160.81661376953124\n",
      "                , weight: 49.15900000000196\n",
      "=================================\n",
      "in 850 epoch, average loss: -33783.078125\n",
      "                , loss1: -690.5029296875\n",
      "                , loss2: 157.55623779296874\n",
      "                , weight: 49.14900000000198\n",
      "=================================\n",
      "in 860 epoch, average loss: -33780.2125\n",
      "                , loss1: -690.7107421875\n",
      "                , loss2: 163.730322265625\n",
      "                , weight: 49.13900000000201\n",
      "=================================\n",
      "in 870 epoch, average loss: -33775.821875\n",
      "                , loss1: -690.628759765625\n",
      "                , loss2: 157.18514404296874\n",
      "                , weight: 49.12900000000203\n",
      "=================================\n",
      "in 880 epoch, average loss: -33778.64375\n",
      "                , loss1: -690.856884765625\n",
      "                , loss2: 158.6618408203125\n",
      "                , weight: 49.11900000000205\n",
      "=================================\n",
      "in 890 epoch, average loss: -33778.434375\n",
      "                , loss1: -690.92265625\n",
      "                , loss2: 155.1945068359375\n",
      "                , weight: 49.10900000000208\n",
      "=================================\n",
      "in 900 epoch, average loss: -33782.1125\n",
      "                , loss1: -691.139599609375\n",
      "                , loss2: 155.2601318359375\n",
      "                , weight: 49.0990000000021\n",
      "=================================\n",
      "in 910 epoch, average loss: -33769.778125\n",
      "                , loss1: -691.2234375\n",
      "                , loss2: 164.800439453125\n",
      "                , weight: 49.08900000000212\n",
      "=================================\n",
      "in 920 epoch, average loss: -33771.684375\n",
      "                , loss1: -691.248193359375\n",
      "                , loss2: 157.19710693359374\n",
      "                , weight: 49.07900000000215\n",
      "=================================\n",
      "in 930 epoch, average loss: -33776.7125\n",
      "                , loss1: -691.4404296875\n",
      "                , loss2: 154.68782958984374\n",
      "                , weight: 49.06900000000217\n",
      "=================================\n",
      "in 940 epoch, average loss: -33770.3125\n",
      "                , loss1: -691.445068359375\n",
      "                , loss2: 154.40504150390626\n",
      "                , weight: 49.05900000000219\n",
      "=================================\n",
      "in 950 epoch, average loss: -33765.690625\n",
      "                , loss1: -691.560400390625\n",
      "                , loss2: 157.77120361328124\n",
      "                , weight: 49.049000000002216\n",
      "=================================\n",
      "in 960 epoch, average loss: -33766.73125\n",
      "                , loss1: -691.63115234375\n",
      "                , loss2: 153.282080078125\n",
      "                , weight: 49.03900000000224\n",
      "=================================\n",
      "in 970 epoch, average loss: -33764.140625\n",
      "                , loss1: -691.755224609375\n",
      "                , loss2: 155.0402099609375\n",
      "                , weight: 49.02900000000226\n",
      "=================================\n",
      "in 980 epoch, average loss: -33756.025\n",
      "                , loss1: -691.724169921875\n",
      "                , loss2: 154.71396484375\n",
      "                , weight: 49.019000000002286\n",
      "=================================\n",
      "in 990 epoch, average loss: -33752.14375\n",
      "                , loss1: -691.83603515625\n",
      "                , loss2: 157.1587158203125\n",
      "                , weight: 49.00900000000231\n",
      "=================================\n",
      "in 1000 epoch, average loss: -33752.26875\n",
      "                , loss1: -691.95791015625\n",
      "                , loss2: 156.088720703125\n",
      "                , weight: 48.99900000000233\n",
      "=================================\n",
      "in 1010 epoch, average loss: -33747.809375\n",
      "                , loss1: -691.965283203125\n",
      "                , loss2: 153.9937255859375\n",
      "                , weight: 48.989000000002356\n",
      "=================================\n",
      "in 1020 epoch, average loss: -33745.95625\n",
      "                , loss1: -692.03154296875\n",
      "                , loss2: 152.1716552734375\n",
      "                , weight: 48.97900000000238\n",
      "=================================\n",
      "in 1030 epoch, average loss: -33734.20625\n",
      "                , loss1: -691.9814453125\n",
      "                , loss2: 154.54698486328124\n",
      "                , weight: 48.9690000000024\n",
      "=================================\n",
      "in 1040 epoch, average loss: -33731.565625\n",
      "                , loss1: -692.170703125\n",
      "                , loss2: 159.5329345703125\n",
      "                , weight: 48.959000000002426\n",
      "=================================\n",
      "in 1050 epoch, average loss: -33730.015625\n",
      "                , loss1: -692.256103515625\n",
      "                , loss2: 158.34124755859375\n",
      "                , weight: 48.94900000000245\n",
      "=================================\n",
      "in 1060 epoch, average loss: -33724.584375\n",
      "                , loss1: -692.151953125\n",
      "                , loss2: 151.753564453125\n",
      "                , weight: 48.93900000000247\n",
      "=================================\n",
      "in 1070 epoch, average loss: -33724.478125\n",
      "                , loss1: -692.345947265625\n",
      "                , loss2: 154.43291015625\n",
      "                , weight: 48.929000000002496\n",
      "=================================\n",
      "in 1080 epoch, average loss: -33717.03125\n",
      "                , loss1: -692.386962890625\n",
      "                , loss2: 156.9600341796875\n",
      "                , weight: 48.91900000000252\n",
      "=================================\n",
      "in 1090 epoch, average loss: -33711.834375\n",
      "                , loss1: -692.486083984375\n",
      "                , loss2: 160.0848876953125\n",
      "                , weight: 48.90900000000254\n",
      "=================================\n",
      "in 1100 epoch, average loss: -33704.4\n",
      "                , loss1: -692.382080078125\n",
      "                , loss2: 155.5049560546875\n",
      "                , weight: 48.899000000002566\n",
      "=================================\n",
      "in 1110 epoch, average loss: -33698.909375\n",
      "                , loss1: -692.480419921875\n",
      "                , loss2: 158.88553466796876\n",
      "                , weight: 48.88900000000259\n",
      "=================================\n",
      "in 1120 epoch, average loss: -33700.2375\n",
      "                , loss1: -692.512890625\n",
      "                , loss2: 152.21268310546876\n",
      "                , weight: 48.87900000000261\n",
      "=================================\n",
      "in 1130 epoch, average loss: -33697.65\n",
      "                , loss1: -692.6064453125\n",
      "                , loss2: 152.446826171875\n",
      "                , weight: 48.869000000002636\n",
      "=================================\n",
      "in 1140 epoch, average loss: -33688.465625\n",
      "                , loss1: -692.539794921875\n",
      "                , loss2: 151.45250244140624\n",
      "                , weight: 48.85900000000266\n",
      "=================================\n",
      "in 1150 epoch, average loss: -33684.428125\n",
      "                , loss1: -692.59619140625\n",
      "                , loss2: 151.32100830078124\n",
      "                , weight: 48.84900000000268\n",
      "=================================\n",
      "in 1160 epoch, average loss: -33680.5125\n",
      "                , loss1: -692.679248046875\n",
      "                , loss2: 152.3674560546875\n",
      "                , weight: 48.839000000002706\n",
      "=================================\n",
      "in 1170 epoch, average loss: -33675.415625\n",
      "                , loss1: -692.72626953125\n",
      "                , loss2: 152.8406494140625\n",
      "                , weight: 48.82900000000273\n",
      "=================================\n",
      "in 1180 epoch, average loss: -33670.55625\n",
      "                , loss1: -692.73046875\n",
      "                , loss2: 150.9722412109375\n",
      "                , weight: 48.81900000000275\n",
      "=================================\n",
      "in 1190 epoch, average loss: -33658.63125\n",
      "                , loss1: -692.6638671875\n",
      "                , loss2: 152.713134765625\n",
      "                , weight: 48.809000000002776\n",
      "=================================\n",
      "in 1200 epoch, average loss: -33647.64375\n",
      "                , loss1: -692.722021484375\n",
      "                , loss2: 159.61490478515626\n",
      "                , weight: 48.7990000000028\n",
      "=================================\n",
      "in 1210 epoch, average loss: -33648.81875\n",
      "                , loss1: -692.815673828125\n",
      "                , loss2: 156.08304443359376\n",
      "                , weight: 48.78900000000282\n",
      "=================================\n",
      "in 1220 epoch, average loss: -33639.934375\n",
      "                , loss1: -692.8009765625\n",
      "                , loss2: 157.32052001953124\n",
      "                , weight: 48.779000000002846\n",
      "=================================\n",
      "in 1230 epoch, average loss: -33640.71875\n",
      "                , loss1: -692.880224609375\n",
      "                , loss2: 153.47276611328124\n",
      "                , weight: 48.76900000000287\n",
      "=================================\n",
      "in 1240 epoch, average loss: -33640.115625\n",
      "                , loss1: -692.971484375\n",
      "                , loss2: 151.593505859375\n",
      "                , weight: 48.75900000000289\n",
      "=================================\n",
      "in 1250 epoch, average loss: -33618.125\n",
      "                , loss1: -692.869091796875\n",
      "                , loss2: 161.6674560546875\n",
      "                , weight: 48.749000000002916\n",
      "=================================\n",
      "in 1260 epoch, average loss: -33599.11875\n",
      "                , loss1: -692.835546875\n",
      "                , loss2: 172.1072021484375\n",
      "                , weight: 48.73900000000294\n",
      "=================================\n",
      "in 1270 epoch, average loss: -33584.9375\n",
      "                , loss1: -692.874169921875\n",
      "                , loss2: 181.24276123046874\n",
      "                , weight: 48.72900000000296\n",
      "=================================\n",
      "in 1280 epoch, average loss: -33584.69375\n",
      "                , loss1: -693.065771484375\n",
      "                , loss2: 183.899365234375\n",
      "                , weight: 48.719000000002985\n",
      "=================================\n",
      "in 1290 epoch, average loss: -33585.115625\n",
      "                , loss1: -693.167236328125\n",
      "                , loss2: 181.4852294921875\n",
      "                , weight: 48.70900000000301\n",
      "=================================\n",
      "in 1300 epoch, average loss: -33578.24375\n",
      "                , loss1: -693.179345703125\n",
      "                , loss2: 182.01055908203125\n",
      "                , weight: 48.69900000000303\n",
      "=================================\n",
      "in 1310 epoch, average loss: -33567.953125\n",
      "                , loss1: -693.141357421875\n",
      "                , loss2: 183.52686767578126\n",
      "                , weight: 48.689000000003055\n",
      "=================================\n",
      "in 1320 epoch, average loss: -33556.3\n",
      "                , loss1: -693.146044921875\n",
      "                , loss2: 188.4746337890625\n",
      "                , weight: 48.67900000000308\n",
      "=================================\n",
      "in 1330 epoch, average loss: -33549.71875\n",
      "                , loss1: -693.17939453125\n",
      "                , loss2: 189.74578857421875\n",
      "                , weight: 48.6690000000031\n",
      "=================================\n",
      "in 1340 epoch, average loss: -33542.871875\n",
      "                , loss1: -693.1890625\n",
      "                , loss2: 190.135888671875\n",
      "                , weight: 48.659000000003125\n",
      "=================================\n",
      "in 1350 epoch, average loss: -33525.953125\n",
      "                , loss1: -693.09375\n",
      "                , loss2: 195.48408203125\n",
      "                , weight: 48.64900000000315\n",
      "=================================\n",
      "in 1360 epoch, average loss: -33516.4125\n",
      "                , loss1: -693.289306640625\n",
      "                , loss2: 207.60634765625\n",
      "                , weight: 48.63900000000317\n",
      "=================================\n",
      "in 1370 epoch, average loss: -33531.265625\n",
      "                , loss1: -693.27685546875\n",
      "                , loss2: 185.21591796875\n",
      "                , weight: 48.629000000003195\n",
      "=================================\n",
      "in 1380 epoch, average loss: -33526.675\n",
      "                , loss1: -693.24521484375\n",
      "                , loss2: 181.33280029296876\n",
      "                , weight: 48.61900000000322\n",
      "=================================\n",
      "in 1390 epoch, average loss: -33517.74375\n",
      "                , loss1: -693.2712890625\n",
      "                , loss2: 184.6006591796875\n",
      "                , weight: 48.60900000000324\n",
      "=================================\n",
      "in 1400 epoch, average loss: -33509.196875\n",
      "                , loss1: -693.337109375\n",
      "                , loss2: 189.412353515625\n",
      "                , weight: 48.599000000003265\n",
      "=================================\n",
      "in 1410 epoch, average loss: -33506.19375\n",
      "                , loss1: -693.25224609375\n",
      "                , loss2: 181.353955078125\n",
      "                , weight: 48.58900000000329\n",
      "=================================\n",
      "in 1420 epoch, average loss: -33502.84375\n",
      "                , loss1: -693.364697265625\n",
      "                , loss2: 183.2365478515625\n",
      "                , weight: 48.57900000000331\n",
      "=================================\n",
      "in 1430 epoch, average loss: -33499.334375\n",
      "                , loss1: -693.4521484375\n",
      "                , loss2: 184.0673828125\n",
      "                , weight: 48.569000000003335\n",
      "=================================\n",
      "in 1440 epoch, average loss: -33488.965625\n",
      "                , loss1: -693.339404296875\n",
      "                , loss2: 182.02451171875\n",
      "                , weight: 48.55900000000336\n",
      "=================================\n",
      "in 1450 epoch, average loss: -33484.68125\n",
      "                , loss1: -693.415185546875\n",
      "                , loss2: 183.0479736328125\n",
      "                , weight: 48.54900000000338\n",
      "=================================\n",
      "in 1460 epoch, average loss: -33477.721875\n",
      "                , loss1: -693.455859375\n",
      "                , loss2: 185.0544677734375\n",
      "                , weight: 48.539000000003405\n",
      "=================================\n",
      "in 1470 epoch, average loss: -33475.534375\n",
      "                , loss1: -693.50302734375\n",
      "                , loss2: 182.59205322265626\n",
      "                , weight: 48.52900000000343\n",
      "=================================\n",
      "in 1480 epoch, average loss: -33468.384375\n",
      "                , loss1: -693.48154296875\n",
      "                , loss2: 181.77596435546874\n",
      "                , weight: 48.51900000000345\n",
      "=================================\n",
      "in 1490 epoch, average loss: -33453.84375\n",
      "                , loss1: -693.381103515625\n",
      "                , loss2: 184.498486328125\n",
      "                , weight: 48.509000000003475\n",
      "=================================\n",
      "in 1500 epoch, average loss: -33454.484375\n",
      "                , loss1: -693.4931640625\n",
      "                , loss2: 182.364599609375\n",
      "                , weight: 48.4990000000035\n",
      "=================================\n",
      "in 1510 epoch, average loss: -33446.75\n",
      "                , loss1: -693.50146484375\n",
      "                , loss2: 183.561279296875\n",
      "                , weight: 48.48900000000352\n",
      "=================================\n",
      "in 1520 epoch, average loss: -33442.51875\n",
      "                , loss1: -693.55302734375\n",
      "                , loss2: 183.3609130859375\n",
      "                , weight: 48.479000000003545\n",
      "=================================\n",
      "in 1530 epoch, average loss: -33432.903125\n",
      "                , loss1: -693.55908203125\n",
      "                , loss2: 186.33597412109376\n",
      "                , weight: 48.46900000000357\n",
      "=================================\n",
      "in 1540 epoch, average loss: -33428.1625\n",
      "                , loss1: -693.542529296875\n",
      "                , loss2: 183.33497314453126\n",
      "                , weight: 48.45900000000359\n",
      "=================================\n",
      "in 1550 epoch, average loss: -33420.071875\n",
      "                , loss1: -693.584130859375\n",
      "                , loss2: 186.50699462890626\n",
      "                , weight: 48.449000000003615\n",
      "=================================\n",
      "in 1560 epoch, average loss: -33416.25625\n",
      "                , loss1: -693.5392578125\n",
      "                , loss2: 181.21793212890626\n",
      "                , weight: 48.43900000000364\n",
      "=================================\n",
      "in 1570 epoch, average loss: -33402.6\n",
      "                , loss1: -693.415380859375\n",
      "                , loss2: 181.9369384765625\n",
      "                , weight: 48.42900000000366\n",
      "=================================\n",
      "in 1580 epoch, average loss: -33394.95\n",
      "                , loss1: -693.51630859375\n",
      "                , loss2: 187.5355224609375\n",
      "                , weight: 48.419000000003685\n",
      "=================================\n",
      "in 1590 epoch, average loss: -33398.221875\n",
      "                , loss1: -693.61494140625\n",
      "                , loss2: 182.10594482421874\n",
      "                , weight: 48.40900000000371\n",
      "=================================\n",
      "in 1600 epoch, average loss: -33391.45625\n",
      "                , loss1: -693.64072265625\n",
      "                , loss2: 183.18125\n",
      "                , weight: 48.39900000000373\n",
      "=================================\n",
      "in 1610 epoch, average loss: -33388.7875\n",
      "                , loss1: -693.720263671875\n",
      "                , loss2: 182.76729736328124\n",
      "                , weight: 48.389000000003755\n",
      "=================================\n",
      "in 1620 epoch, average loss: -33378.7\n",
      "                , loss1: -693.57080078125\n",
      "                , loss2: 178.687158203125\n",
      "                , weight: 48.37900000000378\n",
      "=================================\n",
      "in 1630 epoch, average loss: -33376.79375\n",
      "                , loss1: -693.730322265625\n",
      "                , loss2: 181.370263671875\n",
      "                , weight: 48.3690000000038\n",
      "=================================\n",
      "in 1640 epoch, average loss: -33368.575\n",
      "                , loss1: -693.689599609375\n",
      "                , loss2: 180.68319091796874\n",
      "                , weight: 48.359000000003824\n",
      "=================================\n",
      "in 1650 epoch, average loss: -33362.084375\n",
      "                , loss1: -693.710498046875\n",
      "                , loss2: 181.2470947265625\n",
      "                , weight: 48.34900000000385\n",
      "=================================\n",
      "in 1660 epoch, average loss: -33357.41875\n",
      "                , loss1: -693.7615234375\n",
      "                , loss2: 181.4422119140625\n",
      "                , weight: 48.33900000000387\n",
      "=================================\n",
      "in 1670 epoch, average loss: -33346.4625\n",
      "                , loss1: -693.67587890625\n",
      "                , loss2: 181.315234375\n",
      "                , weight: 48.329000000003894\n",
      "=================================\n",
      "in 1680 epoch, average loss: -33333.9625\n",
      "                , loss1: -693.693310546875\n",
      "                , loss2: 187.73065185546875\n",
      "                , weight: 48.31900000000392\n",
      "=================================\n",
      "in 1690 epoch, average loss: -33329.375\n",
      "                , loss1: -693.84208984375\n",
      "                , loss2: 192.56015625\n",
      "                , weight: 48.30900000000394\n",
      "=================================\n",
      "in 1700 epoch, average loss: -33320.5\n",
      "                , loss1: -693.79482421875\n",
      "                , loss2: 192.21844482421875\n",
      "                , weight: 48.299000000003964\n",
      "=================================\n",
      "in 1710 epoch, average loss: -33313.0125\n",
      "                , loss1: -693.80947265625\n",
      "                , loss2: 193.47769775390626\n",
      "                , weight: 48.28900000000399\n",
      "=================================\n",
      "in 1720 epoch, average loss: -33310.6875\n",
      "                , loss1: -693.88564453125\n",
      "                , loss2: 192.53359375\n",
      "                , weight: 48.27900000000401\n",
      "=================================\n",
      "in 1730 epoch, average loss: -33300.7375\n",
      "                , loss1: -693.806103515625\n",
      "                , loss2: 191.7131591796875\n",
      "                , weight: 48.269000000004034\n",
      "=================================\n",
      "in 1740 epoch, average loss: -33292.25625\n",
      "                , loss1: -693.813037109375\n",
      "                , loss2: 193.591357421875\n",
      "                , weight: 48.25900000000406\n",
      "=================================\n",
      "in 1750 epoch, average loss: -33287.24375\n",
      "                , loss1: -693.87626953125\n",
      "                , loss2: 194.71280517578126\n",
      "                , weight: 48.24900000000408\n",
      "=================================\n",
      "in 1760 epoch, average loss: -33283.45625\n",
      "                , loss1: -693.86064453125\n",
      "                , loss2: 190.81468505859374\n",
      "                , weight: 48.239000000004104\n",
      "=================================\n",
      "in 1770 epoch, average loss: -33276.5875\n",
      "                , loss1: -693.894189453125\n",
      "                , loss2: 192.3617919921875\n",
      "                , weight: 48.22900000000413\n",
      "=================================\n",
      "in 1780 epoch, average loss: -33269.975\n",
      "                , loss1: -693.88037109375\n",
      "                , loss2: 191.3665283203125\n",
      "                , weight: 48.21900000000415\n",
      "=================================\n",
      "in 1790 epoch, average loss: -33260.2375\n",
      "                , loss1: -693.825537109375\n",
      "                , loss2: 191.517041015625\n",
      "                , weight: 48.209000000004174\n",
      "=================================\n",
      "in 1800 epoch, average loss: -33256.828125\n",
      "                , loss1: -693.914208984375\n",
      "                , loss2: 192.26524658203124\n",
      "                , weight: 48.1990000000042\n",
      "=================================\n",
      "in 1810 epoch, average loss: -33248.6125\n",
      "                , loss1: -693.85830078125\n",
      "                , loss2: 190.84383544921874\n",
      "                , weight: 48.18900000000422\n",
      "=================================\n",
      "in 1820 epoch, average loss: -33245.25625\n",
      "                , loss1: -693.9564453125\n",
      "                , loss2: 191.99573974609376\n",
      "                , weight: 48.179000000004244\n",
      "=================================\n",
      "in 1830 epoch, average loss: -33238.803125\n",
      "                , loss1: -693.776806640625\n",
      "                , loss2: 182.85157470703126\n",
      "                , weight: 48.16900000000427\n",
      "=================================\n",
      "in 1840 epoch, average loss: -33234.29375\n",
      "                , loss1: -693.887060546875\n",
      "                , loss2: 185.7359375\n",
      "                , weight: 48.15900000000429\n",
      "=================================\n",
      "in 1850 epoch, average loss: -33225.9125\n",
      "                , loss1: -693.8310546875\n",
      "                , loss2: 184.484521484375\n",
      "                , weight: 48.149000000004314\n",
      "=================================\n",
      "in 1860 epoch, average loss: -33221.709375\n",
      "                , loss1: -693.81669921875\n",
      "                , loss2: 181.05679931640626\n",
      "                , weight: 48.13900000000434\n",
      "=================================\n",
      "in 1870 epoch, average loss: -33215.86875\n",
      "                , loss1: -693.84931640625\n",
      "                , loss2: 181.53037109375\n",
      "                , weight: 48.12900000000436\n",
      "=================================\n",
      "in 1880 epoch, average loss: -33211.321875\n",
      "                , loss1: -693.925439453125\n",
      "                , loss2: 182.7982421875\n",
      "                , weight: 48.119000000004384\n",
      "=================================\n",
      "in 1890 epoch, average loss: -33203.134375\n",
      "                , loss1: -693.890283203125\n",
      "                , loss2: 182.35531005859374\n",
      "                , weight: 48.10900000000441\n",
      "=================================\n",
      "in 1900 epoch, average loss: -33197.0625\n",
      "                , loss1: -693.9408203125\n",
      "                , loss2: 183.91719970703124\n",
      "                , weight: 48.09900000000443\n",
      "=================================\n",
      "in 1910 epoch, average loss: -33186.725\n",
      "                , loss1: -693.808203125\n",
      "                , loss2: 180.9400390625\n",
      "                , weight: 48.089000000004454\n",
      "=================================\n",
      "in 1920 epoch, average loss: -33183.521875\n",
      "                , loss1: -693.95537109375\n",
      "                , loss2: 184.280908203125\n",
      "                , weight: 48.07900000000448\n",
      "=================================\n",
      "in 1930 epoch, average loss: -33175.575\n",
      "                , loss1: -693.886572265625\n",
      "                , loss2: 181.9802001953125\n",
      "                , weight: 48.0690000000045\n",
      "=================================\n",
      "in 1940 epoch, average loss: -33171.378125\n",
      "                , loss1: -693.957958984375\n",
      "                , loss2: 182.67178955078126\n",
      "                , weight: 48.059000000004524\n",
      "=================================\n",
      "in 1950 epoch, average loss: -33162.040625\n",
      "                , loss1: -693.89521484375\n",
      "                , loss2: 182.05162353515624\n",
      "                , weight: 48.04900000000455\n",
      "=================================\n",
      "in 1960 epoch, average loss: -33157.996875\n",
      "                , loss1: -693.993603515625\n",
      "                , loss2: 183.88819580078126\n",
      "                , weight: 48.03900000000457\n",
      "=================================\n",
      "in 1970 epoch, average loss: -33153.309375\n",
      "                , loss1: -693.965185546875\n",
      "                , loss2: 180.26551513671876\n",
      "                , weight: 48.029000000004594\n",
      "=================================\n",
      "in 1980 epoch, average loss: -33145.49375\n",
      "                , loss1: -694.00517578125\n",
      "                , loss2: 183.06405029296874\n",
      "                , weight: 48.01900000000462\n",
      "=================================\n",
      "in 1990 epoch, average loss: -33136.496875\n",
      "                , loss1: -693.885986328125\n",
      "                , loss2: 179.3953369140625\n",
      "                , weight: 48.00900000000464\n",
      "=================================\n",
      "in 2000 epoch, average loss: -33125.834375\n",
      "                , loss1: -694.045654296875\n",
      "                , loss2: 190.789306640625\n",
      "                , weight: 47.99900000000466\n",
      "=================================\n",
      "in 2010 epoch, average loss: -33115.1\n",
      "                , loss1: -694.035888671875\n",
      "                , loss2: 194.1080322265625\n",
      "                , weight: 47.98900000000469\n",
      "=================================\n",
      "in 2020 epoch, average loss: -33112.528125\n",
      "                , loss1: -694.05869140625\n",
      "                , loss2: 190.83604736328124\n",
      "                , weight: 47.97900000000471\n",
      "=================================\n",
      "in 2030 epoch, average loss: -33105.253125\n",
      "                , loss1: -694.072314453125\n",
      "                , loss2: 191.830224609375\n",
      "                , weight: 47.96900000000473\n",
      "=================================\n",
      "in 2040 epoch, average loss: -33098.484375\n",
      "                , loss1: -694.05439453125\n",
      "                , loss2: 190.79622802734374\n",
      "                , weight: 47.95900000000476\n",
      "=================================\n",
      "in 2050 epoch, average loss: -33097.315625\n",
      "                , loss1: -694.041259765625\n",
      "                , loss2: 184.39417724609376\n",
      "                , weight: 47.94900000000478\n",
      "=================================\n",
      "in 2060 epoch, average loss: -33084.153125\n",
      "                , loss1: -693.9685546875\n",
      "                , loss2: 187.12672119140626\n",
      "                , weight: 47.9390000000048\n",
      "=================================\n",
      "in 2070 epoch, average loss: -33082.790625\n",
      "                , loss1: -693.9431640625\n",
      "                , loss2: 180.33642578125\n",
      "                , weight: 47.92900000000483\n",
      "=================================\n",
      "in 2080 epoch, average loss: -33078.11875\n",
      "                , loss1: -694.035791015625\n",
      "                , loss2: 182.5103759765625\n",
      "                , weight: 47.91900000000485\n",
      "=================================\n",
      "in 2090 epoch, average loss: -33072.778125\n",
      "                , loss1: -694.03515625\n",
      "                , loss2: 180.86915283203126\n",
      "                , weight: 47.90900000000487\n",
      "=================================\n",
      "in 2100 epoch, average loss: -33060.88125\n",
      "                , loss1: -694.02412109375\n",
      "                , loss2: 185.2997802734375\n",
      "                , weight: 47.8990000000049\n",
      "=================================\n",
      "in 2110 epoch, average loss: -33060.33125\n",
      "                , loss1: -694.046728515625\n",
      "                , loss2: 179.992822265625\n",
      "                , weight: 47.88900000000492\n",
      "=================================\n",
      "in 2120 epoch, average loss: -33051.1375\n",
      "                , loss1: -694.040234375\n",
      "                , loss2: 181.94056396484376\n",
      "                , weight: 47.87900000000494\n",
      "=================================\n",
      "in 2130 epoch, average loss: -33041.91875\n",
      "                , loss1: -694.057568359375\n",
      "                , loss2: 185.047216796875\n",
      "                , weight: 47.86900000000497\n",
      "=================================\n",
      "in 2140 epoch, average loss: -33035.640625\n",
      "                , loss1: -694.00439453125\n",
      "                , loss2: 181.8390625\n",
      "                , weight: 47.85900000000499\n",
      "=================================\n",
      "in 2150 epoch, average loss: -33028.1875\n",
      "                , loss1: -694.0666015625\n",
      "                , loss2: 185.3248779296875\n",
      "                , weight: 47.84900000000501\n",
      "=================================\n",
      "in 2160 epoch, average loss: -33021.45625\n",
      "                , loss1: -694.02099609375\n",
      "                , loss2: 182.9420166015625\n",
      "                , weight: 47.839000000005036\n",
      "=================================\n",
      "in 2170 epoch, average loss: -33017.571875\n",
      "                , loss1: -694.048486328125\n",
      "                , loss2: 181.19384765625\n",
      "                , weight: 47.82900000000506\n",
      "=================================\n",
      "in 2180 epoch, average loss: -33010.540625\n",
      "                , loss1: -694.0859375\n",
      "                , loss2: 183.07939453125\n",
      "                , weight: 47.81900000000508\n",
      "=================================\n",
      "in 2190 epoch, average loss: -32996.153125\n",
      "                , loss1: -693.966943359375\n",
      "                , loss2: 184.8331298828125\n",
      "                , weight: 47.809000000005106\n",
      "=================================\n",
      "in 2200 epoch, average loss: -32987.1625\n",
      "                , loss1: -694.0693359375\n",
      "                , loss2: 191.7793212890625\n",
      "                , weight: 47.79900000000513\n",
      "=================================\n",
      "in 2210 epoch, average loss: -32949.95625\n",
      "                , loss1: -693.9416015625\n",
      "                , loss2: 215.9420654296875\n",
      "                , weight: 47.78900000000515\n",
      "=================================\n",
      "in 2220 epoch, average loss: -32950.7125\n",
      "                , loss1: -694.009326171875\n",
      "                , loss2: 211.479248046875\n",
      "                , weight: 47.779000000005176\n",
      "=================================\n",
      "in 2230 epoch, average loss: -32945.59375\n",
      "                , loss1: -693.84130859375\n",
      "                , loss2: 201.63665771484375\n",
      "                , weight: 47.7690000000052\n",
      "=================================\n",
      "in 2240 epoch, average loss: -32939.6375\n",
      "                , loss1: -694.056982421875\n",
      "                , loss2: 210.9500732421875\n",
      "                , weight: 47.75900000000522\n",
      "=================================\n",
      "in 2250 epoch, average loss: -32954.234375\n",
      "                , loss1: -693.8541015625\n",
      "                , loss2: 179.72745361328126\n",
      "                , weight: 47.749000000005246\n",
      "=================================\n",
      "in 2260 epoch, average loss: -32955.446875\n",
      "                , loss1: -694.064013671875\n",
      "                , loss2: 181.60057373046874\n",
      "                , weight: 47.73900000000527\n",
      "=================================\n",
      "in 2270 epoch, average loss: -32950.971875\n",
      "                , loss1: -694.091552734375\n",
      "                , loss2: 180.44691162109376\n",
      "                , weight: 47.72900000000529\n",
      "=================================\n",
      "in 2280 epoch, average loss: -32944.7125\n",
      "                , loss1: -694.122021484375\n",
      "                , loss2: 181.22327880859376\n",
      "                , weight: 47.719000000005316\n",
      "=================================\n",
      "in 2290 epoch, average loss: -32938.1875\n",
      "                , loss1: -694.119287109375\n",
      "                , loss2: 180.6687744140625\n",
      "                , weight: 47.70900000000534\n",
      "=================================\n",
      "in 2300 epoch, average loss: -32929.334375\n",
      "                , loss1: -694.07451171875\n",
      "                , loss2: 180.4521240234375\n",
      "                , weight: 47.69900000000536\n",
      "=================================\n",
      "in 2310 epoch, average loss: -32921.9375\n",
      "                , loss1: -694.109423828125\n",
      "                , loss2: 182.57412109375\n",
      "                , weight: 47.689000000005386\n",
      "=================================\n",
      "in 2320 epoch, average loss: -32914.609375\n",
      "                , loss1: -694.06572265625\n",
      "                , loss2: 180.87591552734375\n",
      "                , weight: 47.67900000000541\n",
      "=================================\n",
      "in 2330 epoch, average loss: -32908.984375\n",
      "                , loss1: -694.1412109375\n",
      "                , loss2: 183.15506591796876\n",
      "                , weight: 47.66900000000543\n",
      "=================================\n",
      "in 2340 epoch, average loss: -32902.45\n",
      "                , loss1: -694.12607421875\n",
      "                , loss2: 182.02353515625\n",
      "                , weight: 47.659000000005456\n",
      "=================================\n",
      "in 2350 epoch, average loss: -32893.309375\n",
      "                , loss1: -694.080810546875\n",
      "                , loss2: 182.0732177734375\n",
      "                , weight: 47.64900000000548\n",
      "=================================\n",
      "in 2360 epoch, average loss: -32889.95625\n",
      "                , loss1: -694.1513671875\n",
      "                , loss2: 181.83848876953124\n",
      "                , weight: 47.6390000000055\n",
      "=================================\n",
      "in 2370 epoch, average loss: -32883.075\n",
      "                , loss1: -694.141796875\n",
      "                , loss2: 181.32752685546876\n",
      "                , weight: 47.629000000005526\n",
      "=================================\n",
      "in 2380 epoch, average loss: -32873.028125\n",
      "                , loss1: -694.148388671875\n",
      "                , loss2: 184.74578857421875\n",
      "                , weight: 47.61900000000555\n",
      "=================================\n",
      "in 2390 epoch, average loss: -32860.040625\n",
      "                , loss1: -694.154052734375\n",
      "                , loss2: 191.06357421875\n",
      "                , weight: 47.60900000000557\n",
      "=================================\n",
      "in 2400 epoch, average loss: -32854.9375\n",
      "                , loss1: -694.060986328125\n",
      "                , loss2: 184.79686279296874\n",
      "                , weight: 47.599000000005596\n",
      "=================================\n",
      "in 2410 epoch, average loss: -32855.721875\n",
      "                , loss1: -694.138134765625\n",
      "                , loss2: 180.73902587890626\n",
      "                , weight: 47.58900000000562\n",
      "=================================\n",
      "in 2420 epoch, average loss: -32847.9125\n",
      "                , loss1: -694.179345703125\n",
      "                , loss2: 183.5727294921875\n",
      "                , weight: 47.57900000000564\n",
      "=================================\n",
      "in 2430 epoch, average loss: -32843.040625\n",
      "                , loss1: -694.1513671875\n",
      "                , loss2: 180.1724853515625\n",
      "                , weight: 47.569000000005666\n",
      "=================================\n",
      "in 2440 epoch, average loss: -32835.575\n",
      "                , loss1: -694.2103515625\n",
      "                , loss2: 183.50389404296874\n",
      "                , weight: 47.55900000000569\n",
      "=================================\n",
      "in 2450 epoch, average loss: -32830.23125\n",
      "                , loss1: -694.1728515625\n",
      "                , loss2: 180.115185546875\n",
      "                , weight: 47.54900000000571\n",
      "=================================\n",
      "in 2460 epoch, average loss: -32823.003125\n",
      "                , loss1: -694.193603515625\n",
      "                , loss2: 181.38795166015626\n",
      "                , weight: 47.539000000005736\n",
      "=================================\n",
      "in 2470 epoch, average loss: -32814.853125\n",
      "                , loss1: -694.164892578125\n",
      "                , loss2: 181.234912109375\n",
      "                , weight: 47.52900000000576\n",
      "=================================\n",
      "in 2480 epoch, average loss: -32808.275\n",
      "                , loss1: -694.193505859375\n",
      "                , loss2: 182.228515625\n",
      "                , weight: 47.51900000000578\n",
      "=================================\n",
      "in 2490 epoch, average loss: -32803.609375\n",
      "                , loss1: -694.211376953125\n",
      "                , loss2: 180.8035888671875\n",
      "                , weight: 47.509000000005805\n",
      "=================================\n",
      "in 2500 epoch, average loss: -32795.634375\n",
      "                , loss1: -694.1955078125\n",
      "                , loss2: 181.08712158203124\n",
      "                , weight: 47.49900000000583\n",
      "=================================\n",
      "in 2510 epoch, average loss: -32789.528125\n",
      "                , loss1: -694.203857421875\n",
      "                , loss2: 180.64766845703124\n",
      "                , weight: 47.48900000000585\n",
      "=================================\n",
      "in 2520 epoch, average loss: -32782.6125\n",
      "                , loss1: -694.20751953125\n",
      "                , loss2: 180.78619384765625\n",
      "                , weight: 47.479000000005875\n",
      "=================================\n",
      "in 2530 epoch, average loss: -32775.50625\n",
      "                , loss1: -694.21689453125\n",
      "                , loss2: 181.395947265625\n",
      "                , weight: 47.4690000000059\n",
      "=================================\n",
      "in 2540 epoch, average loss: -32769.575\n",
      "                , loss1: -694.21005859375\n",
      "                , loss2: 180.0610107421875\n",
      "                , weight: 47.45900000000592\n",
      "=================================\n",
      "in 2550 epoch, average loss: -32762.934375\n",
      "                , loss1: -694.218359375\n",
      "                , loss2: 180.15506591796876\n",
      "                , weight: 47.449000000005945\n",
      "=================================\n",
      "in 2560 epoch, average loss: -32755.3125\n",
      "                , loss1: -694.221630859375\n",
      "                , loss2: 180.99478759765626\n",
      "                , weight: 47.43900000000597\n",
      "=================================\n",
      "in 2570 epoch, average loss: -32746.825\n",
      "                , loss1: -694.18271484375\n",
      "                , loss2: 180.6902099609375\n",
      "                , weight: 47.42900000000599\n",
      "=================================\n",
      "in 2580 epoch, average loss: -32739.01875\n",
      "                , loss1: -694.21962890625\n",
      "                , loss2: 183.3074462890625\n",
      "                , weight: 47.419000000006015\n",
      "=================================\n",
      "in 2590 epoch, average loss: -32735.809375\n",
      "                , loss1: -694.23369140625\n",
      "                , loss2: 180.24129638671874\n",
      "                , weight: 47.40900000000604\n",
      "=================================\n",
      "in 2600 epoch, average loss: -32727.85625\n",
      "                , loss1: -694.2267578125\n",
      "                , loss2: 180.92666015625\n",
      "                , weight: 47.39900000000606\n",
      "=================================\n",
      "in 2610 epoch, average loss: -32721.28125\n",
      "                , loss1: -694.24716796875\n",
      "                , loss2: 181.524169921875\n",
      "                , weight: 47.389000000006085\n",
      "=================================\n",
      "in 2620 epoch, average loss: -32714.33125\n",
      "                , loss1: -694.215625\n",
      "                , loss2: 180.03804931640624\n",
      "                , weight: 47.37900000000611\n",
      "=================================\n",
      "in 2630 epoch, average loss: -32705.5375\n",
      "                , loss1: -694.260400390625\n",
      "                , loss2: 184.005810546875\n",
      "                , weight: 47.36900000000613\n",
      "=================================\n",
      "in 2640 epoch, average loss: -32699.425\n",
      "                , loss1: -694.18310546875\n",
      "                , loss2: 179.5180908203125\n",
      "                , weight: 47.359000000006155\n",
      "=================================\n",
      "in 2650 epoch, average loss: -32693.6875\n",
      "                , loss1: -694.25234375\n",
      "                , loss2: 181.5899169921875\n",
      "                , weight: 47.34900000000618\n",
      "=================================\n",
      "in 2660 epoch, average loss: -32687.79375\n",
      "                , loss1: -694.2458984375\n",
      "                , loss2: 180.23212890625\n",
      "                , weight: 47.3390000000062\n",
      "=================================\n",
      "in 2670 epoch, average loss: -32678.940625\n",
      "                , loss1: -694.20380859375\n",
      "                , loss2: 180.15853271484374\n",
      "                , weight: 47.329000000006225\n",
      "=================================\n",
      "in 2680 epoch, average loss: -32673.453125\n",
      "                , loss1: -694.26201171875\n",
      "                , loss2: 181.45623779296875\n",
      "                , weight: 47.31900000000625\n",
      "=================================\n",
      "in 2690 epoch, average loss: -32665.153125\n",
      "                , loss1: -694.1962890625\n",
      "                , loss2: 179.7052978515625\n",
      "                , weight: 47.30900000000627\n",
      "=================================\n",
      "in 2700 epoch, average loss: -32659.79375\n",
      "                , loss1: -694.27158203125\n",
      "                , loss2: 181.67767333984375\n",
      "                , weight: 47.299000000006295\n",
      "=================================\n",
      "in 2710 epoch, average loss: -32653.1875\n",
      "                , loss1: -694.2470703125\n",
      "                , loss2: 180.18677978515626\n",
      "                , weight: 47.28900000000632\n",
      "=================================\n",
      "in 2720 epoch, average loss: -32645.94375\n",
      "                , loss1: -694.260009765625\n",
      "                , loss2: 181.1009033203125\n",
      "                , weight: 47.27900000000634\n",
      "=================================\n",
      "in 2730 epoch, average loss: -32635.246875\n",
      "                , loss1: -694.21845703125\n",
      "                , loss2: 182.89005126953126\n",
      "                , weight: 47.269000000006365\n",
      "=================================\n",
      "in 2740 epoch, average loss: -32623.328125\n",
      "                , loss1: -694.184130859375\n",
      "                , loss2: 186.24168701171874\n",
      "                , weight: 47.25900000000639\n",
      "=================================\n",
      "in 2750 epoch, average loss: -32625.2875\n",
      "                , loss1: -694.2458984375\n",
      "                , loss2: 180.26104736328125\n",
      "                , weight: 47.24900000000641\n",
      "=================================\n",
      "in 2760 epoch, average loss: -32618.528125\n",
      "                , loss1: -694.274365234375\n",
      "                , loss2: 181.42391357421874\n",
      "                , weight: 47.239000000006435\n",
      "=================================\n",
      "in 2770 epoch, average loss: -32597.590625\n",
      "                , loss1: -694.084228515625\n",
      "                , loss2: 186.43790283203126\n",
      "                , weight: 47.22900000000646\n",
      "=================================\n",
      "in 2780 epoch, average loss: -32587.10625\n",
      "                , loss1: -694.39228515625\n",
      "                , loss2: 204.5265869140625\n",
      "                , weight: 47.21900000000648\n",
      "=================================\n",
      "in 2790 epoch, average loss: -32597.934375\n",
      "                , loss1: -695.018701171875\n",
      "                , loss2: 216.3289306640625\n",
      "                , weight: 47.209000000006505\n",
      "=================================\n",
      "in 2800 epoch, average loss: -32596.84375\n",
      "                , loss1: -695.144580078125\n",
      "                , loss2: 216.4125244140625\n",
      "                , weight: 47.19900000000653\n",
      "=================================\n",
      "in 2810 epoch, average loss: -32588.53125\n",
      "                , loss1: -695.065576171875\n",
      "                , loss2: 214.0421142578125\n",
      "                , weight: 47.18900000000655\n",
      "=================================\n",
      "in 2820 epoch, average loss: -32576.021875\n",
      "                , loss1: -695.15322265625\n",
      "                , loss2: 223.7438720703125\n",
      "                , weight: 47.179000000006575\n",
      "=================================\n",
      "in 2830 epoch, average loss: -32577.99375\n",
      "                , loss1: -695.12412109375\n",
      "                , loss2: 213.4408447265625\n",
      "                , weight: 47.1690000000066\n",
      "=================================\n",
      "in 2840 epoch, average loss: -32569.4375\n",
      "                , loss1: -695.218701171875\n",
      "                , loss2: 219.507763671875\n",
      "                , weight: 47.15900000000662\n",
      "=================================\n",
      "in 2850 epoch, average loss: -32561.99375\n",
      "                , loss1: -695.11962890625\n",
      "                , loss2: 215.329931640625\n",
      "                , weight: 47.149000000006644\n",
      "=================================\n",
      "in 2860 epoch, average loss: -32560.515625\n",
      "                , loss1: -695.230810546875\n",
      "                , loss2: 215.0963623046875\n",
      "                , weight: 47.13900000000667\n",
      "=================================\n",
      "in 2870 epoch, average loss: -32554.359375\n",
      "                , loss1: -695.1947265625\n",
      "                , loss2: 212.60048828125\n",
      "                , weight: 47.12900000000669\n",
      "=================================\n",
      "in 2880 epoch, average loss: -32548.44375\n",
      "                , loss1: -695.23095703125\n",
      "                , loss2: 213.2728515625\n",
      "                , weight: 47.119000000006714\n",
      "=================================\n",
      "in 2890 epoch, average loss: -32542.93125\n",
      "                , loss1: -695.230078125\n",
      "                , loss2: 211.796435546875\n",
      "                , weight: 47.10900000000674\n",
      "=================================\n",
      "in 2900 epoch, average loss: -32535.83125\n",
      "                , loss1: -695.2255859375\n",
      "                , loss2: 211.7250244140625\n",
      "                , weight: 47.09900000000676\n",
      "=================================\n",
      "in 2910 epoch, average loss: -32526.975\n",
      "                , loss1: -695.223095703125\n",
      "                , loss2: 213.513671875\n",
      "                , weight: 47.089000000006784\n",
      "=================================\n",
      "in 2920 epoch, average loss: -32521.246875\n",
      "                , loss1: -695.24892578125\n",
      "                , loss2: 213.5071533203125\n",
      "                , weight: 47.07900000000681\n",
      "=================================\n",
      "in 2930 epoch, average loss: -32511.54375\n",
      "                , loss1: -695.21767578125\n",
      "                , loss2: 214.7808349609375\n",
      "                , weight: 47.06900000000683\n",
      "=================================\n",
      "in 2940 epoch, average loss: -32508.0125\n",
      "                , loss1: -695.20810546875\n",
      "                , loss2: 210.912548828125\n",
      "                , weight: 47.059000000006854\n",
      "=================================\n",
      "in 2950 epoch, average loss: -32498.775\n",
      "                , loss1: -695.19462890625\n",
      "                , loss2: 212.56279296875\n",
      "                , weight: 47.04900000000688\n",
      "=================================\n",
      "in 2960 epoch, average loss: -32492.940625\n",
      "                , loss1: -695.210546875\n",
      "                , loss2: 212.1950927734375\n",
      "                , weight: 47.0390000000069\n",
      "=================================\n",
      "in 2970 epoch, average loss: -32487.746875\n",
      "                , loss1: -695.237060546875\n",
      "                , loss2: 211.68720703125\n",
      "                , weight: 47.029000000006924\n",
      "=================================\n",
      "in 2980 epoch, average loss: -32481.240625\n",
      "                , loss1: -695.23779296875\n",
      "                , loss2: 211.2728515625\n",
      "                , weight: 47.01900000000695\n",
      "=================================\n",
      "in 2990 epoch, average loss: -32474.95\n",
      "                , loss1: -695.254541015625\n",
      "                , loss2: 211.397900390625\n",
      "                , weight: 47.00900000000697\n",
      "=================================\n",
      "in 3000 epoch, average loss: -32468.003125\n",
      "                , loss1: -695.263525390625\n",
      "                , loss2: 211.8167724609375\n",
      "                , weight: 46.999000000006994\n",
      "=================================\n",
      "in 3010 epoch, average loss: -32460.45625\n",
      "                , loss1: -695.252587890625\n",
      "                , loss2: 211.898486328125\n",
      "                , weight: 46.98900000000702\n",
      "=================================\n",
      "in 3020 epoch, average loss: -32454.315625\n",
      "                , loss1: -695.248291015625\n",
      "                , loss2: 210.8810302734375\n",
      "                , weight: 46.97900000000704\n",
      "=================================\n",
      "in 3030 epoch, average loss: -32447.090625\n",
      "                , loss1: -695.26455078125\n",
      "                , loss2: 211.9197021484375\n",
      "                , weight: 46.969000000007064\n",
      "=================================\n",
      "in 3040 epoch, average loss: -32438.153125\n",
      "                , loss1: -695.188427734375\n",
      "                , loss2: 210.3282958984375\n",
      "                , weight: 46.95900000000709\n",
      "=================================\n",
      "in 3050 epoch, average loss: -32430.465625\n",
      "                , loss1: -695.1904296875\n",
      "                , loss2: 211.1593994140625\n",
      "                , weight: 46.94900000000711\n",
      "=================================\n",
      "in 3060 epoch, average loss: -32424.6\n",
      "                , loss1: -695.25673828125\n",
      "                , loss2: 213.1859375\n",
      "                , weight: 46.939000000007134\n",
      "=================================\n",
      "in 3070 epoch, average loss: -32418.390625\n",
      "                , loss1: -695.23984375\n",
      "                , loss2: 211.6504638671875\n",
      "                , weight: 46.92900000000716\n",
      "=================================\n",
      "in 3080 epoch, average loss: -32413.56875\n",
      "                , loss1: -695.272607421875\n",
      "                , loss2: 211.057861328125\n",
      "                , weight: 46.91900000000718\n",
      "=================================\n",
      "in 3090 epoch, average loss: -32406.88125\n",
      "                , loss1: -695.281201171875\n",
      "                , loss2: 211.1940673828125\n",
      "                , weight: 46.909000000007204\n",
      "=================================\n",
      "in 3100 epoch, average loss: -32399.84375\n",
      "                , loss1: -695.26357421875\n",
      "                , loss2: 210.4498046875\n",
      "                , weight: 46.89900000000723\n",
      "=================================\n",
      "in 3110 epoch, average loss: -32390.80625\n",
      "                , loss1: -695.24111328125\n",
      "                , loss2: 211.4836181640625\n",
      "                , weight: 46.88900000000725\n",
      "=================================\n",
      "in 3120 epoch, average loss: -32383.8875\n",
      "                , loss1: -695.28291015625\n",
      "                , loss2: 213.4101806640625\n",
      "                , weight: 46.879000000007274\n",
      "=================================\n",
      "in 3130 epoch, average loss: -32376.81875\n",
      "                , loss1: -695.216357421875\n",
      "                , loss2: 210.40654296875\n",
      "                , weight: 46.8690000000073\n",
      "=================================\n",
      "in 3140 epoch, average loss: -32362.896875\n",
      "                , loss1: -695.260205078125\n",
      "                , loss2: 219.4277099609375\n",
      "                , weight: 46.85900000000732\n",
      "=================================\n",
      "in 3150 epoch, average loss: -32363.43125\n",
      "                , loss1: -695.234326171875\n",
      "                , loss2: 210.730859375\n",
      "                , weight: 46.849000000007344\n",
      "=================================\n",
      "in 3160 epoch, average loss: -32356.43125\n",
      "                , loss1: -695.285595703125\n",
      "                , loss2: 213.1806640625\n",
      "                , weight: 46.83900000000737\n",
      "=================================\n",
      "in 3170 epoch, average loss: -32344.9125\n",
      "                , loss1: -695.15732421875\n",
      "                , loss2: 211.7379638671875\n",
      "                , weight: 46.82900000000739\n",
      "=================================\n",
      "in 3180 epoch, average loss: -32342.809375\n",
      "                , loss1: -695.2822265625\n",
      "                , loss2: 212.73505859375\n",
      "                , weight: 46.819000000007414\n",
      "=================================\n",
      "in 3190 epoch, average loss: -32334.50625\n",
      "                , loss1: -695.195458984375\n",
      "                , loss2: 210.0244873046875\n",
      "                , weight: 46.80900000000744\n",
      "=================================\n",
      "in 3200 epoch, average loss: -32330.825\n",
      "                , loss1: -695.2833984375\n",
      "                , loss2: 210.8662841796875\n",
      "                , weight: 46.79900000000746\n",
      "=================================\n",
      "in 3210 epoch, average loss: -32319.378125\n",
      "                , loss1: -695.248828125\n",
      "                , loss2: 213.7470458984375\n",
      "                , weight: 46.78900000000748\n",
      "=================================\n",
      "in 3220 epoch, average loss: -32315.809375\n",
      "                , loss1: -695.2525390625\n",
      "                , loss2: 210.538916015625\n",
      "                , weight: 46.77900000000751\n",
      "=================================\n",
      "in 3230 epoch, average loss: -32303.25625\n",
      "                , loss1: -695.199462890625\n",
      "                , loss2: 213.6591796875\n",
      "                , weight: 46.76900000000753\n",
      "=================================\n",
      "in 3240 epoch, average loss: -32301.678125\n",
      "                , loss1: -695.28095703125\n",
      "                , loss2: 212.0892333984375\n",
      "                , weight: 46.75900000000755\n",
      "=================================\n",
      "in 3250 epoch, average loss: -32295.196875\n",
      "                , loss1: -695.294384765625\n",
      "                , loss2: 212.2454345703125\n",
      "                , weight: 46.74900000000758\n",
      "=================================\n",
      "in 3260 epoch, average loss: -32289.284375\n",
      "                , loss1: -695.2958984375\n",
      "                , loss2: 211.274560546875\n",
      "                , weight: 46.7390000000076\n",
      "=================================\n",
      "in 3270 epoch, average loss: -32281.84375\n",
      "                , loss1: -695.273095703125\n",
      "                , loss2: 210.70185546875\n",
      "                , weight: 46.72900000000762\n",
      "=================================\n",
      "in 3280 epoch, average loss: -32274.759375\n",
      "                , loss1: -695.286572265625\n",
      "                , loss2: 211.4638916015625\n",
      "                , weight: 46.71900000000765\n",
      "=================================\n",
      "in 3290 epoch, average loss: -32269.05625\n",
      "                , loss1: -695.289453125\n",
      "                , loss2: 210.3500732421875\n",
      "                , weight: 46.70900000000767\n",
      "=================================\n",
      "in 3300 epoch, average loss: -32261.784375\n",
      "                , loss1: -695.297705078125\n",
      "                , loss2: 211.05078125\n",
      "                , weight: 46.69900000000769\n",
      "=================================\n",
      "in 3310 epoch, average loss: -32253.7375\n",
      "                , loss1: -695.308544921875\n",
      "                , loss2: 212.6484619140625\n",
      "                , weight: 46.68900000000772\n",
      "=================================\n",
      "in 3320 epoch, average loss: -32247.353125\n",
      "                , loss1: -695.289013671875\n",
      "                , loss2: 211.1708740234375\n",
      "                , weight: 46.67900000000774\n",
      "=================================\n",
      "in 3330 epoch, average loss: -32240.909375\n",
      "                , loss1: -695.2966796875\n",
      "                , loss2: 211.02177734375\n",
      "                , weight: 46.66900000000776\n",
      "=================================\n",
      "in 3340 epoch, average loss: -32233.91875\n",
      "                , loss1: -695.297802734375\n",
      "                , loss2: 211.1078369140625\n",
      "                , weight: 46.65900000000779\n",
      "=================================\n",
      "in 3350 epoch, average loss: -32227.15625\n",
      "                , loss1: -695.291455078125\n",
      "                , loss2: 210.620361328125\n",
      "                , weight: 46.64900000000781\n",
      "=================================\n",
      "in 3360 epoch, average loss: -32221.240625\n",
      "                , loss1: -695.324267578125\n",
      "                , loss2: 211.116552734375\n",
      "                , weight: 46.63900000000783\n",
      "=================================\n",
      "in 3370 epoch, average loss: -32212.225\n",
      "                , loss1: -695.27607421875\n",
      "                , loss2: 210.93095703125\n",
      "                , weight: 46.629000000007856\n",
      "=================================\n",
      "in 3380 epoch, average loss: -32204.9125\n",
      "                , loss1: -695.315185546875\n",
      "                , loss2: 213.1140625\n",
      "                , weight: 46.61900000000788\n",
      "=================================\n",
      "in 3390 epoch, average loss: -32197.259375\n",
      "                , loss1: -695.25478515625\n",
      "                , loss2: 210.997607421875\n",
      "                , weight: 46.6090000000079\n",
      "=================================\n",
      "in 3400 epoch, average loss: -32193.0125\n",
      "                , loss1: -695.31962890625\n",
      "                , loss2: 211.3136474609375\n",
      "                , weight: 46.599000000007926\n",
      "=================================\n",
      "in 3410 epoch, average loss: -32185.559375\n",
      "                , loss1: -695.292822265625\n",
      "                , loss2: 210.57021484375\n",
      "                , weight: 46.58900000000795\n",
      "=================================\n",
      "in 3420 epoch, average loss: -32178.928125\n",
      "                , loss1: -695.3220703125\n",
      "                , loss2: 211.6078857421875\n",
      "                , weight: 46.57900000000797\n",
      "=================================\n",
      "in 3430 epoch, average loss: -32172.76875\n",
      "                , loss1: -695.320654296875\n",
      "                , loss2: 210.7473388671875\n",
      "                , weight: 46.569000000007996\n",
      "=================================\n",
      "in 3440 epoch, average loss: -32163.68125\n",
      "                , loss1: -695.25517578125\n",
      "                , loss2: 209.83349609375\n",
      "                , weight: 46.55900000000802\n",
      "=================================\n",
      "in 3450 epoch, average loss: -32159.2\n",
      "                , loss1: -695.326708984375\n",
      "                , loss2: 210.690087890625\n",
      "                , weight: 46.54900000000804\n",
      "=================================\n",
      "in 3460 epoch, average loss: -32152.234375\n",
      "                , loss1: -695.327978515625\n",
      "                , loss2: 210.760888671875\n",
      "                , weight: 46.539000000008066\n",
      "=================================\n",
      "in 3470 epoch, average loss: -32144.5875\n",
      "                , loss1: -695.3130859375\n",
      "                , loss2: 210.7661865234375\n",
      "                , weight: 46.52900000000809\n",
      "=================================\n",
      "in 3480 epoch, average loss: -32136.5375\n",
      "                , loss1: -695.27578125\n",
      "                , loss2: 210.1235107421875\n",
      "                , weight: 46.51900000000811\n",
      "=================================\n",
      "in 3490 epoch, average loss: -32127.1375\n",
      "                , loss1: -695.267333984375\n",
      "                , loss2: 212.183203125\n",
      "                , weight: 46.509000000008136\n",
      "=================================\n",
      "in 3500 epoch, average loss: -32120.5375\n",
      "                , loss1: -695.287939453125\n",
      "                , loss2: 212.78994140625\n",
      "                , weight: 46.49900000000816\n",
      "=================================\n",
      "in 3510 epoch, average loss: -32114.071875\n",
      "                , loss1: -695.23779296875\n",
      "                , loss2: 209.9672607421875\n",
      "                , weight: 46.48900000000818\n",
      "=================================\n",
      "in 3520 epoch, average loss: -32108.659375\n",
      "                , loss1: -695.32451171875\n",
      "                , loss2: 212.454248046875\n",
      "                , weight: 46.479000000008206\n",
      "=================================\n",
      "in 3530 epoch, average loss: -32103.065625\n",
      "                , loss1: -695.324951171875\n",
      "                , loss2: 211.1191162109375\n",
      "                , weight: 46.46900000000823\n",
      "=================================\n",
      "in 3540 epoch, average loss: -32096.475\n",
      "                , loss1: -695.335009765625\n",
      "                , loss2: 211.22138671875\n",
      "                , weight: 46.45900000000825\n",
      "=================================\n",
      "in 3550 epoch, average loss: -32089.928125\n",
      "                , loss1: -695.3439453125\n",
      "                , loss2: 211.2308837890625\n",
      "                , weight: 46.449000000008276\n",
      "=================================\n",
      "in 3560 epoch, average loss: -32083.2125\n",
      "                , loss1: -695.346533203125\n",
      "                , loss2: 211.117919921875\n",
      "                , weight: 46.4390000000083\n",
      "=================================\n",
      "in 3570 epoch, average loss: -32076.359375\n",
      "                , loss1: -695.3451171875\n",
      "                , loss2: 210.94697265625\n",
      "                , weight: 46.42900000000832\n",
      "=================================\n",
      "in 3580 epoch, average loss: -32067.125\n",
      "                , loss1: -695.27568359375\n",
      "                , loss2: 210.005615234375\n",
      "                , weight: 46.419000000008346\n",
      "=================================\n",
      "in 3590 epoch, average loss: -32062.5\n",
      "                , loss1: -695.343212890625\n",
      "                , loss2: 210.811083984375\n",
      "                , weight: 46.40900000000837\n",
      "=================================\n",
      "in 3600 epoch, average loss: -32053.871875\n",
      "                , loss1: -695.31201171875\n",
      "                , loss2: 211.03740234375\n",
      "                , weight: 46.39900000000839\n",
      "=================================\n",
      "in 3610 epoch, average loss: -32046.709375\n",
      "                , loss1: -695.34130859375\n",
      "                , loss2: 212.605078125\n",
      "                , weight: 46.389000000008416\n",
      "=================================\n",
      "in 3620 epoch, average loss: -32041.515625\n",
      "                , loss1: -695.331591796875\n",
      "                , loss2: 210.3929443359375\n",
      "                , weight: 46.37900000000844\n",
      "=================================\n",
      "in 3630 epoch, average loss: -32034.690625\n",
      "                , loss1: -695.3408203125\n",
      "                , loss2: 210.6998046875\n",
      "                , weight: 46.36900000000846\n",
      "=================================\n",
      "in 3640 epoch, average loss: -32028.021875\n",
      "                , loss1: -695.342626953125\n",
      "                , loss2: 210.492236328125\n",
      "                , weight: 46.359000000008486\n",
      "=================================\n",
      "in 3650 epoch, average loss: -32021.3625\n",
      "                , loss1: -695.344921875\n",
      "                , loss2: 210.3085205078125\n",
      "                , weight: 46.34900000000851\n",
      "=================================\n",
      "in 3660 epoch, average loss: -32014.3125\n",
      "                , loss1: -695.347802734375\n",
      "                , loss2: 210.53662109375\n",
      "                , weight: 46.33900000000853\n",
      "=================================\n",
      "in 3670 epoch, average loss: -32007.471875\n",
      "                , loss1: -695.3470703125\n",
      "                , loss2: 210.390966796875\n",
      "                , weight: 46.329000000008556\n",
      "=================================\n",
      "in 3680 epoch, average loss: -31997.584375\n",
      "                , loss1: -695.28642578125\n",
      "                , loss2: 210.5177734375\n",
      "                , weight: 46.31900000000858\n",
      "=================================\n",
      "in 3690 epoch, average loss: -31991.803125\n",
      "                , loss1: -695.32880859375\n",
      "                , loss2: 211.305322265625\n",
      "                , weight: 46.3090000000086\n",
      "=================================\n",
      "in 3700 epoch, average loss: -31983.7125\n",
      "                , loss1: -695.30087890625\n",
      "                , loss2: 211.1542236328125\n",
      "                , weight: 46.299000000008625\n",
      "=================================\n",
      "in 3710 epoch, average loss: -31896.053125\n",
      "                , loss1: -693.681201171875\n",
      "                , loss2: 216.883203125\n",
      "                , weight: 46.28900000000865\n",
      "=================================\n",
      "in 3720 epoch, average loss: -31708.00625\n",
      "                , loss1: -691.92998046875\n",
      "                , loss2: 316.922509765625\n",
      "                , weight: 46.27900000000867\n",
      "=================================\n",
      "in 3730 epoch, average loss: -31881.034375\n",
      "                , loss1: -695.09658203125\n",
      "                , loss2: 283.5227294921875\n",
      "                , weight: 46.269000000008695\n",
      "=================================\n",
      "in 3740 epoch, average loss: -31903.071875\n",
      "                , loss1: -696.25107421875\n",
      "                , loss2: 307.9430419921875\n",
      "                , weight: 46.25900000000872\n",
      "=================================\n",
      "in 3750 epoch, average loss: -31919.35\n",
      "                , loss1: -696.558349609375\n",
      "                , loss2: 298.9074951171875\n",
      "                , weight: 46.24900000000874\n",
      "=================================\n",
      "in 3760 epoch, average loss: -31940.11875\n",
      "                , loss1: -696.690380859375\n",
      "                , loss2: 277.2830322265625\n",
      "                , weight: 46.239000000008765\n",
      "=================================\n",
      "in 3770 epoch, average loss: -31941.328125\n",
      "                , loss1: -696.7951171875\n",
      "                , loss2: 273.9504150390625\n",
      "                , weight: 46.22900000000879\n",
      "=================================\n",
      "in 3780 epoch, average loss: -31945.3375\n",
      "                , loss1: -696.87255859375\n",
      "                , loss2: 266.54873046875\n",
      "                , weight: 46.21900000000881\n",
      "=================================\n",
      "in 3790 epoch, average loss: -31950.396875\n",
      "                , loss1: -696.62099609375\n",
      "                , loss2: 242.8962646484375\n",
      "                , weight: 46.209000000008835\n",
      "=================================\n",
      "in 3800 epoch, average loss: -31949.74375\n",
      "                , loss1: -696.90107421875\n",
      "                , loss2: 249.5258056640625\n",
      "                , weight: 46.19900000000886\n",
      "=================================\n",
      "in 3810 epoch, average loss: -31941.040625\n",
      "                , loss1: -696.65087890625\n",
      "                , loss2: 239.6996826171875\n",
      "                , weight: 46.18900000000888\n",
      "=================================\n",
      "in 3820 epoch, average loss: -31941.18125\n",
      "                , loss1: -696.881298828125\n",
      "                , loss2: 243.23623046875\n",
      "                , weight: 46.179000000008905\n",
      "=================================\n",
      "in 3830 epoch, average loss: -31943.50625\n",
      "                , loss1: -696.90859375\n",
      "                , loss2: 235.199658203125\n",
      "                , weight: 46.16900000000893\n",
      "=================================\n",
      "in 3840 epoch, average loss: -31928.115625\n",
      "                , loss1: -696.6111328125\n",
      "                , loss2: 229.88994140625\n",
      "                , weight: 46.15900000000895\n",
      "=================================\n",
      "in 3850 epoch, average loss: -31918.240625\n",
      "                , loss1: -696.55146484375\n",
      "                , loss2: 230.0482177734375\n",
      "                , weight: 46.149000000008975\n",
      "=================================\n",
      "in 3860 epoch, average loss: -31911.11875\n",
      "                , loss1: -696.69423828125\n",
      "                , loss2: 236.7920166015625\n",
      "                , weight: 46.139000000009\n",
      "=================================\n",
      "in 3870 epoch, average loss: -31898.28125\n",
      "                , loss1: -696.98828125\n",
      "                , loss2: 256.2289794921875\n",
      "                , weight: 46.12900000000902\n",
      "=================================\n",
      "in 3880 epoch, average loss: -31908.453125\n",
      "                , loss1: -696.7890625\n",
      "                , loss2: 229.8959228515625\n",
      "                , weight: 46.119000000009045\n",
      "=================================\n",
      "in 3890 epoch, average loss: -31903.659375\n",
      "                , loss1: -696.870849609375\n",
      "                , loss2: 231.494580078125\n",
      "                , weight: 46.10900000000907\n",
      "=================================\n",
      "in 3900 epoch, average loss: -31898.528125\n",
      "                , loss1: -696.844189453125\n",
      "                , loss2: 228.4273193359375\n",
      "                , weight: 46.09900000000909\n",
      "=================================\n",
      "in 3910 epoch, average loss: -31896.18125\n",
      "                , loss1: -696.78701171875\n",
      "                , loss2: 221.173681640625\n",
      "                , weight: 46.089000000009115\n",
      "=================================\n",
      "in 3920 epoch, average loss: -31896.5125\n",
      "                , loss1: -696.815771484375\n",
      "                , loss2: 215.1950927734375\n",
      "                , weight: 46.07900000000914\n",
      "=================================\n",
      "in 3930 epoch, average loss: -31882.990625\n",
      "                , loss1: -696.947119140625\n",
      "                , loss2: 227.7998046875\n",
      "                , weight: 46.06900000000916\n",
      "=================================\n",
      "in 3940 epoch, average loss: -31874.5375\n",
      "                , loss1: -696.705859375\n",
      "                , loss2: 218.1701171875\n",
      "                , weight: 46.059000000009185\n",
      "=================================\n",
      "in 3950 epoch, average loss: -31874.265625\n",
      "                , loss1: -696.918798828125\n",
      "                , loss2: 221.283349609375\n",
      "                , weight: 46.04900000000921\n",
      "=================================\n",
      "in 3960 epoch, average loss: -31868.890625\n",
      "                , loss1: -696.693359375\n",
      "                , loss2: 209.31005859375\n",
      "                , weight: 46.03900000000923\n",
      "=================================\n",
      "in 3970 epoch, average loss: -31868.8875\n",
      "                , loss1: -696.896875\n",
      "                , loss2: 211.716455078125\n",
      "                , weight: 46.029000000009255\n",
      "=================================\n",
      "in 3980 epoch, average loss: -31861.096875\n",
      "                , loss1: -696.874267578125\n",
      "                , loss2: 211.49912109375\n",
      "                , weight: 46.01900000000928\n",
      "=================================\n",
      "in 3990 epoch, average loss: -31847.109375\n",
      "                , loss1: -696.84501953125\n",
      "                , loss2: 217.1685546875\n",
      "                , weight: 46.0090000000093\n",
      "=================================\n",
      "in 4000 epoch, average loss: -31848.05\n",
      "                , loss1: -696.865576171875\n",
      "                , loss2: 210.2056396484375\n",
      "                , weight: 45.999000000009325\n",
      "=================================\n",
      "in 4010 epoch, average loss: -31846.16875\n",
      "                , loss1: -696.93974609375\n",
      "                , loss2: 208.5305419921875\n",
      "                , weight: 45.98900000000935\n",
      "=================================\n",
      "in 4020 epoch, average loss: -31846.0875\n",
      "                , loss1: -696.875732421875\n",
      "                , loss2: 198.69808349609374\n",
      "                , weight: 45.97900000000937\n",
      "=================================\n",
      "in 4030 epoch, average loss: -31848.06875\n",
      "                , loss1: -696.67109375\n",
      "                , loss2: 180.3370361328125\n",
      "                , weight: 45.969000000009395\n",
      "=================================\n",
      "in 4040 epoch, average loss: -31845.828125\n",
      "                , loss1: -696.772314453125\n",
      "                , loss2: 180.2712646484375\n",
      "                , weight: 45.95900000000942\n",
      "=================================\n",
      "in 4050 epoch, average loss: -31847.853125\n",
      "                , loss1: -696.829345703125\n",
      "                , loss2: 173.895654296875\n",
      "                , weight: 45.94900000000944\n",
      "=================================\n",
      "in 4060 epoch, average loss: -31840.925\n",
      "                , loss1: -696.9373046875\n",
      "                , loss2: 178.81722412109374\n",
      "                , weight: 45.939000000009464\n",
      "=================================\n",
      "in 4070 epoch, average loss: -31837.16875\n",
      "                , loss1: -696.940771484375\n",
      "                , loss2: 175.76195068359374\n",
      "                , weight: 45.92900000000949\n",
      "=================================\n",
      "in 4080 epoch, average loss: -31833.603125\n",
      "                , loss1: -696.92607421875\n",
      "                , loss2: 171.68231201171875\n",
      "                , weight: 45.91900000000951\n",
      "=================================\n",
      "in 4090 epoch, average loss: -31826.628125\n",
      "                , loss1: -696.99736328125\n",
      "                , loss2: 174.96199951171874\n",
      "                , weight: 45.909000000009534\n",
      "=================================\n",
      "in 4100 epoch, average loss: -31821.06875\n",
      "                , loss1: -696.98544921875\n",
      "                , loss2: 173.0023681640625\n",
      "                , weight: 45.89900000000956\n",
      "=================================\n",
      "in 4110 epoch, average loss: -31814.884375\n",
      "                , loss1: -697.00146484375\n",
      "                , loss2: 172.9506591796875\n",
      "                , weight: 45.88900000000958\n",
      "=================================\n",
      "in 4120 epoch, average loss: -31802.14375\n",
      "                , loss1: -696.885009765625\n",
      "                , loss2: 173.377685546875\n",
      "                , weight: 45.879000000009604\n",
      "=================================\n",
      "in 4130 epoch, average loss: -31798.296875\n",
      "                , loss1: -697.00390625\n",
      "                , loss2: 175.70802001953126\n",
      "                , weight: 45.86900000000963\n",
      "=================================\n",
      "in 4140 epoch, average loss: -31785.765625\n",
      "                , loss1: -696.829833984375\n",
      "                , loss2: 173.29071044921875\n",
      "                , weight: 45.85900000000965\n",
      "=================================\n",
      "in 4150 epoch, average loss: -31760.634375\n",
      "                , loss1: -696.7326171875\n",
      "                , loss2: 186.99842529296876\n",
      "                , weight: 45.849000000009674\n",
      "=================================\n",
      "in 4160 epoch, average loss: -31773.53125\n",
      "                , loss1: -696.893310546875\n",
      "                , loss2: 174.494384765625\n",
      "                , weight: 45.8390000000097\n",
      "=================================\n",
      "in 4170 epoch, average loss: -31770.325\n",
      "                , loss1: -696.9986328125\n",
      "                , loss2: 175.5576416015625\n",
      "                , weight: 45.82900000000972\n",
      "=================================\n",
      "in 4180 epoch, average loss: -31767.484375\n",
      "                , loss1: -697.0095703125\n",
      "                , loss2: 171.9354248046875\n",
      "                , weight: 45.819000000009744\n",
      "=================================\n",
      "in 4190 epoch, average loss: -31761.675\n",
      "                , loss1: -697.03623046875\n",
      "                , loss2: 171.99178466796874\n",
      "                , weight: 45.80900000000977\n",
      "=================================\n",
      "in 4200 epoch, average loss: -31751.946875\n",
      "                , loss1: -696.99462890625\n",
      "                , loss2: 172.84224853515624\n",
      "                , weight: 45.79900000000979\n",
      "=================================\n",
      "in 4210 epoch, average loss: -31742.45\n",
      "                , loss1: -697.017724609375\n",
      "                , loss2: 176.43448486328126\n",
      "                , weight: 45.789000000009814\n",
      "=================================\n",
      "in 4220 epoch, average loss: -31736.796875\n",
      "                , loss1: -697.008447265625\n",
      "                , loss2: 174.68841552734375\n",
      "                , weight: 45.77900000000984\n",
      "=================================\n",
      "in 4230 epoch, average loss: -31731.765625\n",
      "                , loss1: -696.98564453125\n",
      "                , loss2: 171.7096435546875\n",
      "                , weight: 45.76900000000986\n",
      "=================================\n",
      "in 4240 epoch, average loss: -31722.859375\n",
      "                , loss1: -697.031298828125\n",
      "                , loss2: 175.73106689453124\n",
      "                , weight: 45.759000000009884\n",
      "=================================\n",
      "in 4250 epoch, average loss: -31719.921875\n",
      "                , loss1: -697.0283203125\n",
      "                , loss2: 171.56671142578125\n",
      "                , weight: 45.74900000000991\n",
      "=================================\n",
      "in 4260 epoch, average loss: -31711.6375\n",
      "                , loss1: -697.03369140625\n",
      "                , loss2: 173.12747802734376\n",
      "                , weight: 45.73900000000993\n",
      "=================================\n",
      "in 4270 epoch, average loss: -31705.978125\n",
      "                , loss1: -697.046337890625\n",
      "                , loss2: 172.3877685546875\n",
      "                , weight: 45.729000000009954\n",
      "=================================\n",
      "in 4280 epoch, average loss: -31698.55625\n",
      "                , loss1: -697.04873046875\n",
      "                , loss2: 172.949609375\n",
      "                , weight: 45.71900000000998\n",
      "=================================\n",
      "in 4290 epoch, average loss: -31692.79375\n",
      "                , loss1: -697.04921875\n",
      "                , loss2: 171.7659912109375\n",
      "                , weight: 45.70900000001\n",
      "=================================\n",
      "in 4300 epoch, average loss: -31682.56875\n",
      "                , loss1: -697.042724609375\n",
      "                , loss2: 174.722509765625\n",
      "                , weight: 45.699000000010024\n",
      "=================================\n",
      "in 4310 epoch, average loss: -31676.959375\n",
      "                , loss1: -697.027392578125\n",
      "                , loss2: 172.66163330078126\n",
      "                , weight: 45.68900000001005\n",
      "=================================\n",
      "in 4320 epoch, average loss: -31671.509375\n",
      "                , loss1: -697.050146484375\n",
      "                , loss2: 172.18240966796876\n",
      "                , weight: 45.67900000001007\n",
      "=================================\n",
      "in 4330 epoch, average loss: -31664.5875\n",
      "                , loss1: -697.044482421875\n",
      "                , loss2: 171.87451171875\n",
      "                , weight: 45.669000000010094\n",
      "=================================\n",
      "in 4340 epoch, average loss: -31657.296875\n",
      "                , loss1: -697.05048828125\n",
      "                , loss2: 172.46800537109374\n",
      "                , weight: 45.65900000001012\n",
      "=================================\n",
      "in 4350 epoch, average loss: -31647.64375\n",
      "                , loss1: -696.9958984375\n",
      "                , loss2: 172.6557861328125\n",
      "                , weight: 45.64900000001014\n",
      "=================================\n",
      "in 4360 epoch, average loss: -31645.390625\n",
      "                , loss1: -697.04970703125\n",
      "                , loss2: 170.3951904296875\n",
      "                , weight: 45.639000000010164\n",
      "=================================\n",
      "in 4370 epoch, average loss: -31634.15625\n",
      "                , loss1: -697.045703125\n",
      "                , loss2: 174.47681884765626\n",
      "                , weight: 45.62900000001019\n",
      "=================================\n",
      "in 4380 epoch, average loss: -31629.609375\n",
      "                , loss1: -697.05830078125\n",
      "                , loss2: 172.63150634765626\n",
      "                , weight: 45.61900000001021\n",
      "=================================\n",
      "in 4390 epoch, average loss: -31621.28125\n",
      "                , loss1: -697.029052734375\n",
      "                , loss2: 172.65374755859375\n",
      "                , weight: 45.609000000010234\n",
      "=================================\n",
      "in 4400 epoch, average loss: -31614.50625\n",
      "                , loss1: -697.0154296875\n",
      "                , loss2: 171.83604736328124\n",
      "                , weight: 45.59900000001026\n",
      "=================================\n",
      "in 4410 epoch, average loss: -31602.1625\n",
      "                , loss1: -696.86025390625\n",
      "                , loss2: 170.13621826171874\n",
      "                , weight: 45.58900000001028\n",
      "=================================\n",
      "in 4420 epoch, average loss: -31598.775\n",
      "                , loss1: -696.997021484375\n",
      "                , loss2: 172.79219970703124\n",
      "                , weight: 45.5790000000103\n",
      "=================================\n",
      "in 4430 epoch, average loss: -31593.059375\n",
      "                , loss1: -697.077978515625\n",
      "                , loss2: 175.226611328125\n",
      "                , weight: 45.56900000001033\n",
      "=================================\n",
      "in 4440 epoch, average loss: -31582.871875\n",
      "                , loss1: -696.93408203125\n",
      "                , loss2: 171.8878173828125\n",
      "                , weight: 45.55900000001035\n",
      "=================================\n",
      "in 4450 epoch, average loss: -31566.25625\n",
      "                , loss1: -696.946923828125\n",
      "                , loss2: 182.11390380859376\n",
      "                , weight: 45.54900000001037\n",
      "=================================\n",
      "in 4460 epoch, average loss: -31522.253125\n",
      "                , loss1: -696.795703125\n",
      "                , loss2: 212.2585205078125\n",
      "                , weight: 45.5390000000104\n",
      "=================================\n",
      "in 4470 epoch, average loss: -31519.60625\n",
      "                , loss1: -696.823193359375\n",
      "                , loss2: 209.189990234375\n",
      "                , weight: 45.52900000001042\n",
      "=================================\n",
      "in 4480 epoch, average loss: -31509.6125\n",
      "                , loss1: -696.863427734375\n",
      "                , loss2: 214.0464111328125\n",
      "                , weight: 45.51900000001044\n",
      "=================================\n",
      "in 4490 epoch, average loss: -31499.978125\n",
      "                , loss1: -697.099072265625\n",
      "                , loss2: 227.4400634765625\n",
      "                , weight: 45.50900000001047\n",
      "=================================\n",
      "in 4500 epoch, average loss: -31501.334375\n",
      "                , loss1: -697.102783203125\n",
      "                , loss2: 219.2833251953125\n",
      "                , weight: 45.49900000001049\n",
      "=================================\n",
      "in 4510 epoch, average loss: -31495.528125\n",
      "                , loss1: -697.11787109375\n",
      "                , loss2: 218.8030517578125\n",
      "                , weight: 45.48900000001051\n",
      "=================================\n",
      "in 4520 epoch, average loss: -31489.778125\n",
      "                , loss1: -697.1671875\n",
      "                , loss2: 219.826513671875\n",
      "                , weight: 45.47900000001054\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0036\u001b[39m:\n\u001b[1;32m      6\u001b[0m     hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m hgnn_trainer\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[0;32m----> 7\u001b[0m loss,loss_1,loss_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhgnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m temp_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m temp_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     31\u001b[0m loss, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_bs_matrix(outs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhg, device\u001b[38;5;241m=\u001b[39mDEVICE,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), loss_1\u001b[38;5;241m.\u001b[39mitem(), loss_2\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "optim1 = optim.Adam(hgnn_trainer.parameters(), lr=3e-4, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim1\n",
    "for epoch in range(20000):\n",
    "    if hgnn_trainer.weight > 0.0036:\n",
    "        hgnn_trainer.weight = hgnn_trainer.weight - 0.001\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"                , weight: {hgnn_trainer.weight}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([157., 156., 190., 159., 184., 173.], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.033366045142296366"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = outs_straight.sum(dim=0)\n",
    "print(num_nodes)\n",
    "(torch.max(num_nodes).item() - torch.min(num_nodes).item()) / num_nodes.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(torch.tensor([53.,56,53,54,56,55]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
