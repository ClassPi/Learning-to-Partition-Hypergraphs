{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 运行前请安装dhg: `pip install git+https://github.com/iMoonLab/DeepHypergraph.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # 添加项目根目录到路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycq/work/graph-partition-with-gcn/.env-HGP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#orch.manual_seed(42)\n",
    "torch.manual_seed(600)\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "import dhg\n",
    "from dhg import Hypergraph\n",
    "\n",
    "import hgp\n",
    "from hgp.models import HGNNP\n",
    "from hgp.loss import loss_bs_matrix\n",
    "from hgp.utils import from_pickle_to_hypergraph\n",
    "from hgp.function import StraightThroughEstimator\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hgp.models import ParameterDict\n",
    "\n",
    "# fmt: off\n",
    "h_hyper_prmts = ParameterDict()\n",
    "l_hyper_prmts = ParameterDict()\n",
    "\n",
    "partitions = 5\n",
    "\n",
    "h_hyper_prmts[\"convlayers1\"] = {\"in_channels\": 3824, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.3}\n",
    "h_hyper_prmts[\"convlayers12\"] = {\"in_channels\": 2048, \"out_channels\": 1536, \"use_bn\": False, \"drop_rate\": 0.3}\n",
    "h_hyper_prmts[\"convlayers13\"] = {\"in_channels\": 1536, \"out_channels\": 1024, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers14\"] = {\"in_channels\": 1024, \"out_channels\": 768, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers15\"] = {\"in_channels\": 768, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "#h_hyper_prmts[\"convlayers16\"] = {\"in_channels\": 2048, \"out_channels\": 1536, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers3\"] = {\"in_channels\": 512, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers4\"] = {\"in_channels\": 512, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.2}\n",
    "h_hyper_prmts[\"convlayers5\"] = {\"in_channels\": 256, \"out_channels\": 128, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers52\"] = {\"in_channels\": 128, \"out_channels\": 256, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers53\"] = {\"in_channels\": 256, \"out_channels\": 512, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "h_hyper_prmts[\"convlayers54\"] = {\"in_channels\": 512, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "#h_hyper_prmts[\"convlayers55\"] = {\"in_channels\": 1024, \"out_channels\": 2048, \"use_bn\": False, \"drop_rate\": 0.1}\n",
    "\n",
    "\n",
    "l_hyper_prmts[\"linerlayer1\"] = {\"in_channels\":list(h_hyper_prmts.values())[-1][\"out_channels\"], \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "#l_hyper_prmts[\"linerlayer12\"] = {\"in_channels\":1024, \"out_channels\":512, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer2\"] = {\"in_channels\":512, \"out_channels\":256, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer3\"] = {\"in_channels\":256, \"out_channels\":128, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer32\"] = {\"in_channels\":128, \"out_channels\":64, \"use_bn\":True, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer33\"] = {\"in_channels\":64, \"out_channels\":32, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer34\"] = {\"in_channels\":32, \"out_channels\":16, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "l_hyper_prmts[\"linerlayer4\"] = {\"in_channels\":16, \"out_channels\":5, \"use_bn\":False, \"drop_rate\":0.05}\n",
    "\n",
    "\n",
    "hyper = {\n",
    "    \"h_hyper_prmts\": h_hyper_prmts,\n",
    "    \"l_hyper_prmts\":l_hyper_prmts,\n",
    "    \"init_features_dim\":list(h_hyper_prmts.values())[0][\"in_channels\"],\n",
    "    \"partitions\":partitions\n",
    "}\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bs_matrix(outs, hg, device):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    对于超图的损失函数的矩阵形式.\n",
    "    \n",
    "        1.计算与顶点``vₙ``处于不同partition的顶点在超边``eₖ``上的数量``ne_k``.  \n",
    "        2.计算与顶点``vₙ``是否处于该超边``eₖ``上.  \n",
    "        3.若在,则说明``vₙ``所在的边为 **cut** , 记录该边的损失.  \n",
    "    \n",
    "    Args:\n",
    "        ``outs``(`torch.nn.Module`):  模型的输出. Size :math:`(N, nums_classes)`.   \n",
    "        ``hg``(`Hypergraph`):  超图对象.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    H = hg.H.to_dense().to(device)\n",
    "    outs = outs.to(device)\n",
    "    nn = torch.matmul(outs, (1 - torch.transpose(outs, 0, 1)))\n",
    "    ne_k = torch.matmul(nn, H)\n",
    "    ne_k = ne_k.mul(H)\n",
    "\n",
    "    H_degree = torch.sum(H, dim=0)\n",
    "    H_degree = H_degree\n",
    "\n",
    "    H_1 = ne_k / H_degree\n",
    "    a2 = 1 - H_1\n",
    "    a3 = torch.prod(a2, dim=0)\n",
    "    a3 = a3.sum()\n",
    "    loss_1 = -1 * a3\n",
    "\n",
    "    # pun = torch.mul(ne_k, H)\n",
    "\n",
    "    # loss_1 = pun.sum()\n",
    "    loss_2 = torch.var(torch.sum(outs, dim=0)).to(device)\n",
    "\n",
    "    #loss = 50 * loss_1 + loss_2\n",
    "    loss = 10 * loss_1 + loss_2\n",
    "    return loss, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义用于训练的类Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    # fmt: off\n",
    "    r\"\"\"\n",
    "    用于承担训练的类.\n",
    "    ---\n",
    "    Args:\n",
    "        ``net``: (``torch.nn.Module``): 网络模型.  \n",
    "        ``X``: (``torch.Tensor``): 作为输入的顶点特征矩阵. Size :math:`(N, C_{in})`.  \n",
    "        ``hg``: (``dhg.Hypergraph``): 包含 :math:`N` 个顶点的超图结构.  \n",
    "    \"\"\"\n",
    "    # fmt: on\n",
    "    def __init__(self, net, X, hg, optimizer):\n",
    "        super().__init__()\n",
    "        self.X: torch.Tensor = X.to(DEVICE)\n",
    "        self.hg = hg.to(DEVICE)\n",
    "        self.de = self.hg.H.to_dense().sum(dim=0).to(\"cpu\").to(DEVICE)\n",
    "        self.optimizer: torch.optim.Optimizer = optimizer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(net.to(DEVICE))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.layers[0](X, self.hg)\n",
    "        for layer in self.layers[1:]:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def run(self, epoch):\n",
    "        self.train()  # train mode | 设置为训练模式\n",
    "        self.optimizer.zero_grad()\n",
    "        outs = self.forward(self.X)\n",
    "        loss, loss_1, loss_2 = loss_bs_matrix(outs, self.hg, device=DEVICE)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), loss_1.item(), loss_2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7523, 3824)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = from_pickle_to_hypergraph(\"../data/pubmed\")\n",
    "edges, _ = G.e\n",
    "G.num_e,G.num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = torch.randn(size=(G.num_v, hyper[\"init_features_dim\"]))\n",
    "X = torch.eye(n=G.num_v)\n",
    "net = HGNNP(hyper[\"h_hyper_prmts\"]).to(DEVICE)\n",
    "hgnn_trainer = Trainer(net=net, X=X, hg=G, optimizer=None).to(DEVICE)\n",
    "\n",
    "for (k,v) in hyper[\"l_hyper_prmts\"].items():\n",
    "    hgnn_trainer.layers.append(nn.BatchNorm1d(num_features=v[\"in_channels\"]).to(DEVICE)) if v[\"use_bn\"] else None\n",
    "    hgnn_trainer.layers.append(nn.ReLU().to(DEVICE))\n",
    "    hgnn_trainer.layers.append(nn.Dropout(v[\"drop_rate\"]))\n",
    "    hgnn_trainer.layers.append(nn.Linear(in_features=v[\"in_channels\"],out_features=v[\"out_channels\"],device=DEVICE))\n",
    "hgnn_trainer.layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "optim = optim.Adam(hgnn_trainer.parameters(), lr=4e-5, weight_decay=5e-8)\n",
    "hgnn_trainer.optimizer = optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.layers.0.theta.weight Parameter containing:\n",
      "tensor([[-0.0044,  0.0065, -0.0097,  ...,  0.0069, -0.0004, -0.0056],\n",
      "        [-0.0120,  0.0150,  0.0120,  ...,  0.0038,  0.0021,  0.0075],\n",
      "        [ 0.0050, -0.0109,  0.0076,  ..., -0.0153, -0.0105, -0.0149],\n",
      "        ...,\n",
      "        [-0.0006,  0.0116,  0.0071,  ..., -0.0029,  0.0108,  0.0047],\n",
      "        [-0.0084, -0.0004, -0.0116,  ..., -0.0037, -0.0057,  0.0100],\n",
      "        [ 0.0005, -0.0104, -0.0114,  ..., -0.0055, -0.0038,  0.0012]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.0.theta.bias Parameter containing:\n",
      "tensor([ 0.0128, -0.0013,  0.0099,  ...,  0.0081,  0.0049,  0.0131],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.1.theta.weight Parameter containing:\n",
      "tensor([[ 0.0050,  0.0102,  0.0084,  ...,  0.0196, -0.0082,  0.0123],\n",
      "        [ 0.0218, -0.0199, -0.0189,  ...,  0.0130, -0.0195, -0.0004],\n",
      "        [-0.0141, -0.0007,  0.0033,  ..., -0.0171,  0.0197, -0.0134],\n",
      "        ...,\n",
      "        [ 0.0029, -0.0080,  0.0028,  ..., -0.0024,  0.0203,  0.0177],\n",
      "        [-0.0146,  0.0136, -0.0148,  ...,  0.0151,  0.0120, -0.0050],\n",
      "        [-0.0032,  0.0116, -0.0166,  ..., -0.0016,  0.0205, -0.0190]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.1.theta.bias Parameter containing:\n",
      "tensor([ 0.0202, -0.0024, -0.0039,  ...,  0.0084,  0.0170, -0.0057],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.2.theta.weight Parameter containing:\n",
      "tensor([[-0.0144, -0.0104,  0.0049,  ...,  0.0112, -0.0088,  0.0016],\n",
      "        [-0.0079,  0.0166, -0.0171,  ...,  0.0129,  0.0159, -0.0174],\n",
      "        [ 0.0122,  0.0189,  0.0228,  ...,  0.0064, -0.0112,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0151,  0.0098,  ...,  0.0104, -0.0024, -0.0132],\n",
      "        [ 0.0036, -0.0231,  0.0136,  ...,  0.0135,  0.0096,  0.0167],\n",
      "        [ 0.0027, -0.0244, -0.0212,  ...,  0.0038, -0.0194, -0.0149]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.2.theta.bias Parameter containing:\n",
      "tensor([-0.0021, -0.0010,  0.0238,  ..., -0.0151,  0.0212, -0.0011],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.3.theta.weight Parameter containing:\n",
      "tensor([[ 0.0236,  0.0074, -0.0048,  ..., -0.0056, -0.0258,  0.0311],\n",
      "        [ 0.0132,  0.0148, -0.0090,  ...,  0.0156,  0.0298,  0.0108],\n",
      "        [-0.0230,  0.0205, -0.0219,  ..., -0.0262, -0.0079,  0.0297],\n",
      "        ...,\n",
      "        [-0.0227,  0.0009, -0.0294,  ..., -0.0173, -0.0120, -0.0260],\n",
      "        [-0.0285, -0.0227, -0.0040,  ...,  0.0215,  0.0083,  0.0259],\n",
      "        [ 0.0281, -0.0251,  0.0159,  ...,  0.0085, -0.0233,  0.0287]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.3.theta.bias Parameter containing:\n",
      "tensor([-6.7970e-03,  9.5566e-03,  1.4136e-02, -2.7099e-02,  1.5752e-02,\n",
      "        -2.0638e-02,  2.9260e-02, -2.8404e-02,  3.7623e-03,  1.3130e-02,\n",
      "        -1.4805e-02,  2.7295e-02,  8.6978e-03,  3.0430e-02, -2.6626e-02,\n",
      "        -1.7329e-02,  2.9985e-02,  2.2020e-02, -2.4266e-03,  1.9516e-02,\n",
      "        -2.2862e-02,  1.3861e-02,  6.4323e-03, -1.1774e-03,  2.3397e-02,\n",
      "         1.4950e-02,  1.5787e-02, -2.4149e-02, -2.9365e-02,  1.4534e-02,\n",
      "         3.0683e-02, -1.9556e-02,  6.8657e-03,  2.0731e-02, -1.9899e-02,\n",
      "        -2.5465e-02,  5.3582e-03,  1.7055e-03,  5.2271e-03, -2.9104e-02,\n",
      "         1.9063e-02, -6.7855e-03, -1.8694e-02,  1.0304e-02,  2.3575e-03,\n",
      "         5.6718e-04, -2.3954e-02,  2.5916e-02, -8.9437e-03,  3.7704e-03,\n",
      "         2.7339e-02, -1.4617e-02,  6.4436e-03,  5.4818e-03, -5.3386e-03,\n",
      "         9.2994e-05,  6.2370e-03,  2.0989e-02,  2.2601e-03,  3.2921e-03,\n",
      "         2.5165e-02,  1.9221e-02, -1.6823e-02,  1.9341e-02, -2.7869e-02,\n",
      "         7.9510e-03,  1.5357e-02,  3.3656e-03,  1.1571e-02,  1.9473e-03,\n",
      "        -6.0412e-03, -4.2224e-03, -1.7646e-02,  2.3586e-02,  9.3588e-03,\n",
      "         1.9076e-02, -3.0937e-02, -4.1601e-03,  1.6258e-02, -1.3728e-02,\n",
      "         2.4548e-02,  6.4787e-03, -2.8928e-02, -1.3125e-02, -3.0633e-02,\n",
      "        -1.7687e-02,  7.0099e-03, -1.9487e-02, -2.9524e-02, -1.6171e-02,\n",
      "        -1.2368e-02, -2.6648e-02,  1.0082e-02,  2.6269e-02, -2.1339e-02,\n",
      "        -1.8531e-04,  2.4580e-02, -2.2716e-02,  6.8430e-03, -1.4477e-02,\n",
      "        -1.1936e-02,  2.2503e-03,  1.7803e-02, -2.5986e-02,  5.2438e-03,\n",
      "         2.4325e-02, -2.6009e-02,  4.5062e-03,  5.0924e-03, -2.2414e-02,\n",
      "        -2.2523e-02,  5.1351e-03,  8.1240e-03, -2.6184e-02,  3.0153e-02,\n",
      "         2.2092e-02, -2.8846e-02,  1.1747e-02,  1.0561e-02, -9.6016e-03,\n",
      "        -2.2383e-02,  4.7129e-03,  5.1452e-04,  9.0843e-03,  2.6827e-02,\n",
      "        -5.8206e-03,  1.8200e-03, -7.2447e-03, -1.7946e-02,  2.5784e-02,\n",
      "        -2.3442e-02, -1.0002e-02, -2.7582e-02, -2.0398e-03,  1.4225e-02,\n",
      "        -2.9684e-02, -1.2239e-02,  2.2091e-03,  2.7992e-02, -1.8674e-02,\n",
      "         1.3579e-02, -2.6273e-02, -1.3318e-02,  7.2661e-03, -8.7033e-03,\n",
      "        -1.1507e-02,  1.4991e-02,  2.1975e-02, -2.1730e-02, -2.5495e-02,\n",
      "         2.5259e-02,  1.7089e-02, -2.4115e-02, -4.6898e-03, -7.6973e-03,\n",
      "         2.2850e-02,  1.7212e-02, -1.8780e-02, -2.5569e-02, -1.5403e-02,\n",
      "         1.0832e-02, -4.9035e-03,  7.6907e-03,  5.5181e-03, -2.2606e-02,\n",
      "        -1.1876e-02,  5.6245e-03, -2.3257e-02,  2.1511e-02,  1.0851e-02,\n",
      "        -2.7251e-02, -1.8141e-02,  1.5185e-03,  2.3919e-02,  1.2868e-02,\n",
      "         6.1581e-03, -1.8441e-02,  2.4079e-03,  1.1145e-03,  2.0212e-02,\n",
      "        -1.6714e-03, -2.3267e-02,  7.2227e-03,  1.1862e-02,  5.5021e-03,\n",
      "        -1.3661e-02,  3.0911e-02, -1.9673e-02,  1.3339e-02, -1.2649e-02,\n",
      "        -2.1366e-03,  1.7612e-02,  1.2219e-02,  5.5219e-03,  6.6909e-03,\n",
      "         3.0590e-03,  3.0183e-02, -1.8636e-02,  2.8173e-02, -8.0940e-03,\n",
      "        -2.2889e-02, -2.3920e-02,  1.4442e-02,  3.0897e-02, -1.2979e-02,\n",
      "         2.9538e-02, -2.7289e-02, -1.7576e-02,  2.2614e-02,  1.4451e-02,\n",
      "         1.2391e-02, -2.9054e-02, -1.3013e-02,  3.0960e-02, -1.6321e-02,\n",
      "        -2.0372e-03, -2.5927e-02, -8.0069e-03,  1.8781e-02,  2.0188e-02,\n",
      "        -2.1315e-02,  9.7825e-03,  2.0898e-02, -2.0173e-02, -1.5971e-02,\n",
      "        -2.6361e-04, -2.0573e-02, -4.8861e-03,  2.6798e-02, -1.3770e-02,\n",
      "        -1.1515e-02, -1.9836e-02, -1.1862e-02,  1.0950e-02, -1.9421e-02,\n",
      "         2.3192e-02,  9.1486e-04, -3.3518e-03, -8.3007e-03, -1.7082e-02,\n",
      "        -9.5535e-03,  1.1858e-02, -2.0768e-02, -3.1087e-02,  6.1325e-03,\n",
      "         1.7191e-02,  1.5401e-02,  2.6658e-02, -5.8832e-03, -5.2456e-03,\n",
      "         1.7692e-02,  2.6446e-03,  1.7997e-02, -2.1804e-02, -2.3264e-02,\n",
      "         1.7293e-02, -7.9588e-03,  1.6594e-02, -2.2777e-02, -1.9720e-02,\n",
      "         2.5933e-02,  1.3175e-02,  2.6024e-02, -2.6561e-04, -7.5405e-03,\n",
      "        -1.7877e-02, -1.4369e-02, -2.8278e-02, -3.0238e-02,  2.3788e-02,\n",
      "        -1.2373e-02, -1.6938e-02,  2.1391e-02,  2.4093e-02,  6.7089e-03,\n",
      "         9.1627e-03,  1.9289e-02,  1.1237e-02,  1.4331e-02, -2.7105e-02,\n",
      "         2.6909e-02,  5.6738e-03, -1.4677e-02, -6.0948e-03,  3.8002e-05,\n",
      "         2.2577e-02,  2.1736e-02,  1.4927e-02, -2.0742e-02,  2.7586e-02,\n",
      "        -1.2121e-02,  1.9617e-02,  2.3510e-02,  3.0115e-02, -8.8704e-03,\n",
      "        -7.0421e-03, -2.1004e-02,  2.4594e-02,  3.7941e-03, -4.7140e-03,\n",
      "        -2.1271e-03,  1.1529e-02, -2.0660e-02,  2.7308e-02,  2.4872e-02,\n",
      "         2.2744e-02,  2.9301e-02,  3.0251e-02,  3.0864e-02,  1.0194e-02,\n",
      "        -1.8627e-02,  1.9595e-02, -6.1751e-03, -2.0849e-02,  2.4763e-03,\n",
      "         2.7627e-02,  2.4152e-02,  1.7370e-02,  2.8073e-02,  2.4496e-02,\n",
      "        -2.2891e-02, -3.0212e-03,  2.2699e-02, -1.1163e-02, -1.5126e-02,\n",
      "        -4.5519e-03, -1.6587e-02, -2.8564e-02, -1.3481e-02, -4.6483e-03,\n",
      "        -8.9503e-03, -1.5633e-02, -1.3840e-02, -2.3256e-02, -2.7149e-02,\n",
      "         1.8445e-02,  1.2312e-02, -1.2228e-02, -2.2559e-02, -2.9698e-02,\n",
      "         2.0598e-02,  3.4855e-03,  1.2604e-02,  2.4508e-02,  9.1072e-03,\n",
      "        -1.4043e-02, -2.3360e-02, -7.1038e-03,  2.0240e-02, -1.3718e-02,\n",
      "         2.2257e-02,  4.1311e-03, -2.6884e-02,  2.8370e-02, -2.6024e-03,\n",
      "        -9.5885e-03, -8.5406e-03,  2.4810e-02, -2.4272e-04, -1.7857e-02,\n",
      "        -1.4655e-02,  4.2033e-03,  4.3173e-03,  1.9972e-02,  1.4494e-03,\n",
      "        -1.3695e-02,  2.4662e-02,  1.3187e-02,  2.6681e-02,  1.9545e-02,\n",
      "        -5.5741e-03, -7.9104e-03, -2.8394e-02, -1.5165e-02,  1.9427e-02,\n",
      "         4.0722e-03, -3.0695e-02,  2.5027e-02, -9.1100e-03, -5.3626e-03,\n",
      "        -2.9507e-02, -2.5916e-02, -1.8614e-03,  2.3030e-02,  1.6365e-02,\n",
      "         2.9833e-02, -6.4401e-03, -6.7254e-03, -3.0516e-02,  1.0842e-02,\n",
      "        -7.9501e-03,  1.6451e-02,  2.6152e-03,  1.1958e-02, -9.2783e-03,\n",
      "        -1.2858e-02,  1.2333e-02, -2.8705e-02,  8.6319e-04, -2.8743e-02,\n",
      "         2.4548e-02, -2.0509e-03,  3.0976e-02,  7.6123e-03, -2.7534e-02,\n",
      "        -1.3548e-02, -1.5914e-02, -1.0597e-02,  1.7208e-02,  2.5731e-02,\n",
      "        -2.0672e-02, -6.3233e-03,  1.2794e-02, -2.7139e-02,  8.2690e-03,\n",
      "        -6.8432e-03,  2.9137e-03, -3.8269e-03,  1.9390e-02, -2.9524e-02,\n",
      "         2.1319e-02, -6.4607e-03,  1.6026e-02, -4.0451e-03,  1.6252e-02,\n",
      "        -1.8981e-02,  2.7771e-02,  2.0447e-02,  2.9201e-02, -9.9384e-03,\n",
      "        -1.0311e-02,  1.7448e-02, -6.2943e-03, -5.8841e-03, -2.6632e-02,\n",
      "         3.9547e-03, -1.1550e-02, -1.9713e-02, -2.7853e-02, -1.3506e-02,\n",
      "        -1.9774e-02,  2.0249e-02,  2.4915e-02, -5.6465e-03, -2.0259e-02,\n",
      "         2.5898e-02,  1.8259e-02, -3.7706e-03, -1.5730e-02, -8.7154e-03,\n",
      "        -2.6958e-04,  1.1298e-02,  3.0784e-02,  8.8013e-03, -9.0423e-03,\n",
      "         1.2707e-02, -7.0800e-03,  2.1551e-02,  2.1044e-02, -2.3484e-02,\n",
      "        -2.5358e-02, -2.0751e-02, -2.2774e-02,  1.3682e-02, -7.8432e-03,\n",
      "        -1.7148e-02,  2.4875e-02,  1.4170e-02, -3.1220e-02,  6.4737e-03,\n",
      "        -2.5471e-02, -1.3592e-02,  6.5263e-05,  1.2536e-02,  2.0722e-02,\n",
      "         2.4433e-02, -1.5675e-02, -5.1624e-03, -7.8273e-03, -1.7982e-02,\n",
      "         2.7884e-02, -5.9714e-03, -1.8830e-02, -6.2649e-03,  5.0871e-03,\n",
      "        -1.3695e-02, -2.4886e-02, -6.9524e-03, -2.3751e-02, -2.3495e-02,\n",
      "        -1.2309e-02, -1.7670e-02, -3.6836e-04,  5.0239e-03,  1.5737e-02,\n",
      "         2.6633e-02,  1.2292e-02,  2.7798e-02, -2.0892e-03, -2.4996e-02,\n",
      "        -1.1159e-02, -2.6674e-02, -1.0043e-02,  1.1390e-02,  3.4587e-03,\n",
      "         9.7115e-03,  1.7314e-02, -9.9412e-04,  9.1493e-04,  2.6864e-03,\n",
      "         2.4066e-02, -2.6924e-02,  2.0820e-02,  1.0169e-02, -3.0534e-02,\n",
      "         1.0789e-02,  2.2277e-02, -1.7569e-02,  1.5827e-02, -2.5860e-02,\n",
      "        -2.0991e-02,  1.4156e-02, -3.0066e-02,  4.4679e-03,  2.4325e-02,\n",
      "         2.7916e-02,  2.4064e-03,  2.2014e-02,  2.2884e-02, -1.4265e-02,\n",
      "         6.4723e-03,  2.1098e-02, -9.7648e-04,  6.0204e-03,  7.2069e-03,\n",
      "         2.1912e-02,  2.2912e-02,  1.6477e-02,  1.7789e-02,  2.3949e-02,\n",
      "         1.8404e-02, -3.3533e-03,  2.5592e-02, -1.5139e-02, -1.7826e-03,\n",
      "        -1.2044e-02,  2.1830e-02,  1.7376e-02,  3.0108e-02, -9.1351e-03,\n",
      "        -2.7362e-02, -2.6690e-02, -8.1466e-03, -1.5153e-02, -2.6357e-02,\n",
      "         2.2621e-02, -2.9608e-02, -2.1177e-02, -2.7905e-03,  2.1763e-02,\n",
      "        -1.7101e-02, -1.4720e-02,  2.9808e-03, -5.1062e-03,  1.8568e-02,\n",
      "         2.7448e-02,  1.3986e-02, -1.1919e-02,  2.5581e-02,  1.5242e-02,\n",
      "        -1.9506e-02, -2.8669e-02,  1.9097e-02, -2.8089e-02,  1.0834e-02,\n",
      "        -1.1120e-02,  8.7529e-03,  2.8841e-02, -6.8337e-03, -4.0899e-03,\n",
      "         2.6972e-02,  2.2731e-02,  1.0755e-02, -2.5471e-02, -2.1569e-04,\n",
      "         2.7179e-03,  2.1904e-02, -6.5562e-03,  1.9419e-02,  1.8507e-02,\n",
      "        -1.3601e-02, -1.7384e-02, -2.5488e-02,  4.1836e-03, -2.1307e-02,\n",
      "        -9.3135e-03,  1.9900e-02, -1.2859e-02, -3.7393e-04, -9.2610e-04,\n",
      "         2.7682e-02, -9.7223e-03,  3.0347e-03,  1.8744e-02,  1.4945e-02,\n",
      "         2.2110e-02,  1.3861e-02,  2.0880e-02,  2.3109e-02,  3.0502e-02,\n",
      "         2.2428e-02,  7.9113e-03, -1.9628e-02,  2.6656e-02, -1.4241e-02,\n",
      "         1.1476e-02, -2.5451e-02, -1.5998e-02, -1.3667e-02,  1.9383e-02,\n",
      "         3.0535e-03,  1.2466e-02,  2.7422e-02, -4.5367e-03, -1.3334e-02,\n",
      "         3.0018e-02, -4.8792e-03, -6.5546e-03, -1.9534e-04, -2.5877e-02,\n",
      "        -9.4048e-03,  1.1438e-02,  7.6993e-03, -1.0886e-02, -2.1699e-02,\n",
      "         2.6822e-02,  2.3586e-02,  1.3514e-02,  2.5623e-02, -1.7046e-02,\n",
      "        -1.8204e-02, -1.6474e-02,  2.5312e-02,  2.2639e-02,  2.7608e-02,\n",
      "        -1.6229e-02, -1.0960e-02,  2.6251e-02,  6.0119e-03,  5.0619e-03,\n",
      "        -1.0065e-02, -1.7055e-02, -3.0562e-02,  2.3775e-02,  1.8036e-03,\n",
      "        -1.6989e-02, -2.6324e-02, -2.6708e-02,  1.5008e-02, -1.3983e-02,\n",
      "        -1.4722e-02, -1.4543e-02, -5.9453e-03,  3.6397e-03,  2.4165e-02,\n",
      "        -2.3872e-02,  3.1035e-02, -1.4329e-02, -5.7532e-03,  4.3898e-03,\n",
      "         3.1612e-03,  9.2271e-03,  1.6242e-02,  2.8973e-02,  3.1043e-02,\n",
      "        -2.3499e-03,  2.5235e-02, -8.8167e-03,  7.3982e-03, -1.8244e-02,\n",
      "        -1.7094e-03, -1.6666e-02, -2.4288e-02, -1.6973e-03, -2.4424e-02,\n",
      "         9.6058e-04, -3.0159e-02, -7.7893e-03,  2.8836e-03,  2.7730e-03,\n",
      "         2.7289e-02,  2.4444e-03,  2.1593e-02, -1.8020e-03,  2.1229e-03,\n",
      "        -1.6653e-03,  1.8771e-02,  2.4877e-04, -1.7707e-02, -2.6871e-02,\n",
      "         8.7546e-03,  2.4635e-02, -2.8334e-02,  1.3138e-02, -2.3360e-02,\n",
      "         1.4489e-02,  2.5216e-02,  2.5302e-02,  2.6933e-02, -1.8141e-02,\n",
      "        -6.7509e-03, -2.6188e-02,  1.2184e-02, -6.9367e-03,  2.8339e-02,\n",
      "        -1.4568e-02,  5.6587e-03, -1.1724e-02,  2.8987e-02, -2.1714e-02,\n",
      "        -4.1596e-03,  1.7430e-02, -5.7790e-03,  9.0071e-03, -9.0786e-03,\n",
      "         2.8456e-02,  3.0696e-02,  2.0157e-02,  8.4916e-03,  3.1030e-02,\n",
      "         3.1238e-02,  5.1626e-03, -2.1564e-02, -1.8944e-02, -1.3893e-02,\n",
      "        -2.6483e-02,  2.8270e-02,  2.2363e-02, -1.2070e-02,  6.1913e-03,\n",
      "         6.6403e-03, -5.0352e-03,  1.6379e-02, -7.6890e-03, -1.5887e-02,\n",
      "        -9.1665e-04, -1.6515e-03,  1.2295e-02, -1.7216e-03,  2.9829e-02,\n",
      "         2.3938e-02, -5.3516e-03, -6.2421e-03, -1.3714e-02,  5.9067e-04,\n",
      "         1.8507e-02,  1.2144e-03, -1.1707e-02, -2.1460e-02, -1.2246e-02,\n",
      "        -5.4525e-03, -2.1738e-02, -2.6492e-02,  4.1549e-03, -2.6414e-02,\n",
      "        -1.8110e-02, -6.8769e-03, -2.5770e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "layers.0.layers.4.theta.weight Parameter containing:\n",
      "tensor([[-0.0068, -0.0063, -0.0064,  ..., -0.0036,  0.0259,  0.0192],\n",
      "        [ 0.0263, -0.0329, -0.0151,  ..., -0.0276,  0.0268,  0.0002],\n",
      "        [ 0.0114, -0.0286,  0.0018,  ...,  0.0219,  0.0358, -0.0121],\n",
      "        ...,\n",
      "        [-0.0242,  0.0012, -0.0179,  ...,  0.0054, -0.0323,  0.0347],\n",
      "        [ 0.0194, -0.0287, -0.0014,  ...,  0.0347, -0.0233,  0.0354],\n",
      "        [ 0.0300, -0.0016, -0.0233,  ...,  0.0001, -0.0111, -0.0249]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.4.theta.bias Parameter containing:\n",
      "tensor([-2.6953e-02,  2.6004e-02, -1.8850e-02,  3.2659e-02,  2.8433e-03,\n",
      "        -3.2474e-02,  1.7396e-02, -6.1756e-03,  6.0828e-03,  5.9448e-04,\n",
      "         3.3742e-02,  2.3333e-02,  1.5800e-02, -1.3608e-02, -2.1568e-02,\n",
      "        -2.5228e-02,  3.3809e-02,  1.0492e-02,  3.1216e-02,  7.4934e-03,\n",
      "        -3.4677e-03, -2.8651e-02, -7.0247e-03,  8.2618e-03, -3.2577e-02,\n",
      "        -2.4522e-02, -2.1157e-02,  1.3990e-02,  1.7673e-02, -1.7642e-02,\n",
      "         3.0726e-02, -3.2376e-02,  9.4767e-04,  1.3616e-02,  5.8136e-03,\n",
      "         1.8240e-03,  1.2396e-02,  2.7501e-02,  2.1193e-02, -1.2894e-03,\n",
      "         3.1977e-03, -3.3873e-02,  9.9500e-05,  1.3193e-02, -2.4278e-02,\n",
      "         2.8251e-02,  1.5920e-02, -2.9616e-02, -2.9490e-02, -2.9108e-02,\n",
      "         2.8398e-02, -1.5142e-02, -1.6085e-02,  1.4424e-02,  2.2144e-02,\n",
      "        -3.1824e-02,  3.0397e-02, -3.0976e-03,  2.4795e-02,  3.4023e-02,\n",
      "        -1.0819e-02, -3.2414e-02, -2.2926e-02,  3.5890e-02, -2.9015e-02,\n",
      "        -7.5964e-03,  8.9631e-03, -5.8176e-03, -7.9734e-03, -2.0589e-02,\n",
      "         2.3626e-03,  2.6154e-02, -8.4185e-03,  5.2882e-03,  4.3490e-03,\n",
      "        -3.0809e-02,  1.3731e-02,  2.1622e-02, -2.2801e-02, -1.9787e-02,\n",
      "         1.1460e-02,  2.6750e-02, -1.0248e-03,  5.5692e-03, -3.2214e-02,\n",
      "        -3.3131e-03,  8.4245e-03,  1.2843e-02, -2.4888e-03, -2.9652e-02,\n",
      "        -8.5064e-03, -1.9760e-02,  2.9890e-02,  5.0230e-03,  1.3557e-02,\n",
      "         1.5070e-02,  1.8707e-02,  1.7103e-02, -5.0324e-03,  3.1255e-02,\n",
      "         2.1313e-02, -6.1956e-03,  2.0590e-02,  2.9764e-03,  2.2165e-02,\n",
      "         1.1981e-02,  1.0728e-02, -3.1284e-03,  1.1957e-02, -1.5643e-02,\n",
      "        -3.3991e-02,  2.8718e-02, -1.4541e-02,  3.4386e-02,  2.8021e-03,\n",
      "        -3.5587e-02,  2.6991e-02, -1.8319e-02,  2.9651e-02, -4.4991e-03,\n",
      "         2.6284e-02,  2.5175e-02, -4.3908e-04, -1.3858e-02, -1.3350e-02,\n",
      "         1.6632e-02,  2.4549e-03, -2.8227e-02, -1.5109e-02, -1.0976e-02,\n",
      "         3.5249e-02,  2.9663e-04, -3.1993e-02,  2.6329e-02, -3.2233e-02,\n",
      "         2.6363e-02, -9.3274e-03, -1.7077e-02, -8.8033e-03, -2.1187e-02,\n",
      "        -1.5181e-02,  7.0395e-03, -2.3292e-02,  2.1090e-02, -2.4210e-02,\n",
      "         2.8579e-02,  1.7718e-02,  3.4734e-02,  1.0498e-02,  2.0336e-02,\n",
      "         2.7883e-02,  2.9828e-02,  1.4705e-02, -3.9229e-03,  2.2825e-02,\n",
      "         2.9759e-02,  3.1515e-02,  2.8240e-02,  2.1359e-02,  2.1077e-02,\n",
      "         1.5839e-03, -1.1124e-02,  3.1760e-02,  2.0001e-02,  2.4195e-02,\n",
      "        -8.7570e-03, -3.3621e-02, -1.6539e-02,  1.0642e-02,  3.0476e-02,\n",
      "        -3.2246e-02, -2.8144e-02, -2.2406e-02, -1.9106e-02, -1.3701e-02,\n",
      "        -1.7776e-02, -1.2980e-02, -4.7137e-03,  7.5648e-03, -6.6059e-03,\n",
      "        -2.0665e-02, -3.3864e-02,  5.4717e-03,  8.5354e-03, -8.9649e-03,\n",
      "        -2.0634e-02, -2.4969e-02, -1.2122e-02, -2.5267e-03, -3.0737e-02,\n",
      "         1.5746e-02,  2.8472e-02,  3.2193e-02,  2.0880e-02,  8.6674e-03,\n",
      "        -2.0209e-02,  2.3178e-02,  1.7705e-02,  2.4051e-03,  1.7844e-02,\n",
      "         3.4667e-02,  2.1381e-02, -5.6246e-03, -1.3931e-02,  2.5770e-02,\n",
      "         2.3094e-02, -2.7099e-02, -2.5258e-02,  1.3462e-02,  1.2365e-02,\n",
      "        -3.2899e-03, -1.9758e-02,  3.5022e-02,  8.7902e-03, -5.0810e-03,\n",
      "         1.7764e-02, -1.2099e-02, -3.2261e-02,  3.3479e-02,  2.2496e-02,\n",
      "         1.9712e-02,  3.4425e-03,  3.4383e-02, -2.6723e-02,  3.0560e-02,\n",
      "         2.2271e-02,  2.0957e-02, -1.0147e-02,  2.1523e-02,  1.3770e-02,\n",
      "         2.4907e-02, -1.1655e-02,  3.2143e-02,  1.7287e-02, -3.1961e-02,\n",
      "        -1.8604e-02, -2.2127e-02,  2.9329e-03, -1.6142e-02,  3.4109e-02,\n",
      "        -2.5618e-02, -1.8918e-02, -1.2257e-02,  3.3626e-02, -1.9893e-02,\n",
      "        -2.8712e-02, -3.2404e-02, -1.2755e-02, -1.9289e-02, -9.0520e-03,\n",
      "         1.4001e-04, -1.3796e-03, -2.0691e-02,  1.6332e-02, -3.2295e-02,\n",
      "        -9.8151e-03, -9.4039e-03, -2.9524e-02, -2.8989e-02,  2.3914e-02,\n",
      "        -1.6137e-02,  1.7793e-02,  3.1851e-02,  1.0996e-02,  3.3693e-02,\n",
      "         1.2525e-02,  3.6962e-03, -2.8092e-02,  3.4179e-02, -2.9873e-02,\n",
      "         6.1769e-03, -7.3184e-03,  1.1229e-02,  3.0791e-02, -1.5973e-02,\n",
      "        -1.7797e-02,  3.2366e-02, -1.6260e-03, -2.7994e-02, -3.0823e-02,\n",
      "         1.5918e-02,  3.7648e-03,  1.2746e-02,  1.7355e-02, -4.7279e-03,\n",
      "         2.8499e-02,  1.1903e-02, -3.3320e-02,  3.2095e-02, -2.9495e-02,\n",
      "         2.2107e-02,  1.6148e-02, -1.4292e-02,  3.2716e-02, -2.8954e-02,\n",
      "         2.1517e-02,  7.2268e-03,  3.1109e-03,  5.2884e-03, -1.3796e-02,\n",
      "        -1.7358e-04, -3.3152e-03,  3.3660e-02,  1.9923e-02,  2.2661e-02,\n",
      "         2.6668e-02,  2.9509e-02, -4.0179e-03,  7.6863e-03, -3.1136e-02,\n",
      "         2.2917e-02, -7.3227e-03,  2.8157e-02, -3.4622e-02, -1.3065e-02,\n",
      "        -1.0953e-02, -9.3502e-03, -3.3544e-03, -5.0099e-03, -8.9627e-03,\n",
      "         3.7169e-03, -1.6712e-02, -3.3223e-02, -4.5364e-03,  1.0191e-02,\n",
      "        -2.4034e-02,  3.0817e-02, -4.8037e-03,  2.0642e-02,  1.9442e-02,\n",
      "        -2.2763e-02, -1.7926e-02,  7.5640e-03, -6.4995e-03, -1.2889e-02,\n",
      "         2.1882e-02,  2.7122e-02, -2.8052e-02, -1.5105e-02,  8.2818e-03,\n",
      "        -1.9506e-02, -2.2951e-02,  8.8483e-03,  4.3992e-03, -3.2666e-02,\n",
      "        -1.4996e-02,  3.0160e-02, -1.3725e-02, -3.6071e-02, -1.7396e-02,\n",
      "        -5.2421e-03, -2.4992e-02,  1.2498e-02,  1.2393e-02, -1.9931e-02,\n",
      "         2.3666e-02, -9.9448e-03,  2.3776e-03, -1.8283e-02, -2.9062e-02,\n",
      "         2.2778e-02, -5.7266e-03, -3.4953e-02,  2.1279e-02,  2.7253e-02,\n",
      "         1.4074e-02, -1.8287e-02, -1.6768e-02,  2.5694e-02,  2.5460e-03,\n",
      "        -3.5076e-02,  3.3108e-02, -7.9932e-03, -2.3784e-02,  1.7221e-02,\n",
      "         1.2411e-02,  2.0861e-03, -2.6705e-02,  7.9716e-03,  1.5361e-02,\n",
      "        -2.4147e-02,  2.2369e-02, -1.8929e-03,  2.9632e-02,  3.1854e-02,\n",
      "        -4.9930e-03, -1.2519e-03,  5.2041e-03,  3.0313e-02,  1.6778e-02,\n",
      "         1.7746e-02,  2.5736e-02, -3.4727e-02, -1.7614e-02, -1.5459e-02,\n",
      "        -1.9668e-02,  7.9410e-03, -6.1070e-03,  4.6458e-03,  1.3201e-02,\n",
      "        -1.1227e-02, -7.2734e-03, -2.4161e-02, -1.7559e-02, -2.2173e-02,\n",
      "         1.0804e-02,  3.4088e-02,  4.4409e-03, -1.2307e-02, -1.4505e-02,\n",
      "         3.1143e-02,  6.5301e-03,  1.8095e-02,  2.3133e-02, -2.2920e-02,\n",
      "        -2.3851e-02, -2.5396e-02, -2.0362e-03, -2.3713e-02, -1.5999e-02,\n",
      "         2.1649e-02, -3.3272e-03,  6.8146e-03, -5.1675e-03, -1.0491e-02,\n",
      "         2.2842e-02, -1.5275e-02,  2.7308e-02, -1.3628e-02,  1.2689e-02,\n",
      "        -2.4475e-02, -1.6596e-02, -2.2322e-02, -3.5805e-02,  2.8345e-02,\n",
      "        -3.2505e-02,  4.5806e-03,  4.7861e-03, -2.5993e-02,  3.1735e-02,\n",
      "         4.1116e-03,  1.2744e-02, -1.2055e-02,  3.2270e-03, -1.3149e-02,\n",
      "        -3.0475e-02, -1.2063e-02,  2.6805e-02,  3.2910e-02,  2.5265e-02,\n",
      "        -1.2604e-03,  2.3262e-03, -1.1387e-02, -2.8543e-03, -5.1281e-04,\n",
      "        -5.7377e-03,  2.8743e-02, -3.4274e-02, -1.6522e-02, -2.0112e-02,\n",
      "        -2.7778e-02, -5.5671e-03, -9.9940e-03, -2.7719e-02, -9.3900e-03,\n",
      "        -2.8984e-02,  1.3367e-02, -4.8854e-03, -1.6511e-03,  2.2679e-02,\n",
      "        -5.0006e-03,  2.5764e-03,  3.0540e-02, -2.7380e-02,  3.4312e-02,\n",
      "         5.9676e-03,  2.6362e-02,  1.3552e-02,  1.2057e-02, -1.1334e-02,\n",
      "         1.4650e-02, -1.6579e-02, -2.6426e-02,  2.6928e-02, -3.5332e-02,\n",
      "         1.1686e-02, -1.6623e-02,  2.8236e-02, -2.0743e-02, -2.8003e-02,\n",
      "         1.3630e-02, -2.8213e-02,  2.8469e-03, -2.7766e-02, -2.3554e-04,\n",
      "        -1.6824e-02,  1.1221e-02,  3.3401e-03,  3.8536e-03,  1.7059e-02,\n",
      "        -2.0796e-02, -1.3042e-02,  2.5840e-02,  2.5131e-02, -3.5206e-02,\n",
      "         1.7759e-02,  2.9537e-02,  4.5022e-03,  8.2396e-03,  1.7786e-03,\n",
      "        -1.0762e-02, -3.0323e-02], device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.5.theta.weight Parameter containing:\n",
      "tensor([[ 0.0093, -0.0137,  0.0213,  ..., -0.0072, -0.0134,  0.0139],\n",
      "        [ 0.0143, -0.0264,  0.0160,  ...,  0.0240,  0.0194, -0.0083],\n",
      "        [ 0.0290, -0.0050,  0.0063,  ..., -0.0154,  0.0325, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0412, -0.0146, -0.0252,  ..., -0.0200,  0.0257,  0.0162],\n",
      "        [ 0.0187,  0.0139, -0.0431,  ..., -0.0026,  0.0335, -0.0197],\n",
      "        [ 0.0288,  0.0225, -0.0101,  ..., -0.0231, -0.0370, -0.0069]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.5.theta.bias Parameter containing:\n",
      "tensor([-0.0358,  0.0022, -0.0032,  0.0059,  0.0395, -0.0310,  0.0166,  0.0353,\n",
      "         0.0383,  0.0234,  0.0253,  0.0142, -0.0319,  0.0405, -0.0337, -0.0291,\n",
      "        -0.0144,  0.0185,  0.0216, -0.0040, -0.0097,  0.0259,  0.0374,  0.0111,\n",
      "        -0.0336,  0.0192,  0.0018,  0.0131, -0.0309,  0.0314, -0.0204,  0.0295,\n",
      "         0.0301, -0.0025, -0.0299,  0.0232,  0.0207, -0.0130, -0.0339,  0.0100,\n",
      "         0.0343,  0.0169, -0.0245,  0.0332,  0.0413, -0.0356,  0.0220, -0.0207,\n",
      "        -0.0263,  0.0302, -0.0140, -0.0326, -0.0067,  0.0113,  0.0341, -0.0186,\n",
      "        -0.0027,  0.0074, -0.0234,  0.0135,  0.0105, -0.0051, -0.0181, -0.0214,\n",
      "        -0.0225,  0.0060,  0.0183,  0.0118,  0.0440,  0.0192, -0.0108,  0.0194,\n",
      "         0.0412, -0.0154, -0.0135, -0.0131, -0.0114, -0.0409,  0.0280, -0.0436,\n",
      "        -0.0159, -0.0367,  0.0434, -0.0147,  0.0275, -0.0342, -0.0355,  0.0239,\n",
      "        -0.0029, -0.0083,  0.0203,  0.0261, -0.0025,  0.0107,  0.0187, -0.0372,\n",
      "         0.0319,  0.0253, -0.0124, -0.0182, -0.0382,  0.0009,  0.0043,  0.0107,\n",
      "        -0.0112,  0.0228, -0.0210,  0.0219,  0.0406, -0.0431,  0.0270, -0.0080,\n",
      "        -0.0426, -0.0295, -0.0093,  0.0027,  0.0357,  0.0210,  0.0177,  0.0235,\n",
      "        -0.0390, -0.0343,  0.0264, -0.0397,  0.0348, -0.0294,  0.0119,  0.0056,\n",
      "        -0.0169, -0.0378,  0.0318, -0.0326, -0.0308, -0.0328, -0.0183, -0.0407,\n",
      "         0.0400,  0.0415,  0.0108,  0.0325,  0.0045,  0.0322,  0.0145, -0.0152,\n",
      "        -0.0248,  0.0324,  0.0048, -0.0281, -0.0426, -0.0319,  0.0285, -0.0056,\n",
      "         0.0272, -0.0121,  0.0220,  0.0209, -0.0211,  0.0402,  0.0234, -0.0129,\n",
      "        -0.0217, -0.0104,  0.0135, -0.0148,  0.0355,  0.0068, -0.0282,  0.0054,\n",
      "         0.0094, -0.0362,  0.0167,  0.0256, -0.0073,  0.0195,  0.0155,  0.0284,\n",
      "         0.0259, -0.0157,  0.0284,  0.0428, -0.0421,  0.0065, -0.0136, -0.0203,\n",
      "        -0.0352, -0.0094, -0.0438,  0.0165, -0.0325,  0.0347,  0.0305, -0.0228,\n",
      "        -0.0225, -0.0029,  0.0244, -0.0115,  0.0056, -0.0137,  0.0053, -0.0019,\n",
      "         0.0309, -0.0272, -0.0434, -0.0377, -0.0005, -0.0416, -0.0373, -0.0034,\n",
      "        -0.0237,  0.0420,  0.0359, -0.0129, -0.0087, -0.0209, -0.0438,  0.0412,\n",
      "        -0.0048,  0.0325,  0.0354,  0.0158,  0.0253, -0.0292,  0.0241,  0.0380,\n",
      "         0.0312,  0.0098,  0.0438,  0.0003, -0.0211, -0.0116,  0.0332, -0.0049,\n",
      "        -0.0436,  0.0282,  0.0172, -0.0054, -0.0063,  0.0110, -0.0349, -0.0246,\n",
      "        -0.0377,  0.0275, -0.0312, -0.0002, -0.0396,  0.0074,  0.0393,  0.0056,\n",
      "         0.0286,  0.0233, -0.0336, -0.0368,  0.0028, -0.0326,  0.0165,  0.0153,\n",
      "         0.0120, -0.0269, -0.0370, -0.0245,  0.0438,  0.0379,  0.0055, -0.0046,\n",
      "        -0.0337, -0.0138, -0.0018, -0.0056, -0.0166,  0.0049, -0.0008, -0.0012,\n",
      "        -0.0163,  0.0126, -0.0267,  0.0350, -0.0244,  0.0340,  0.0053,  0.0100,\n",
      "        -0.0416, -0.0022, -0.0048, -0.0269, -0.0163, -0.0356, -0.0223,  0.0294,\n",
      "         0.0372, -0.0289, -0.0103,  0.0417, -0.0230, -0.0196, -0.0186,  0.0354,\n",
      "         0.0037, -0.0343, -0.0071, -0.0266, -0.0337, -0.0331,  0.0347,  0.0379,\n",
      "        -0.0142, -0.0379,  0.0022, -0.0229,  0.0293, -0.0105, -0.0070, -0.0388,\n",
      "         0.0389, -0.0319, -0.0208, -0.0209, -0.0025, -0.0093,  0.0074, -0.0295,\n",
      "        -0.0273, -0.0418, -0.0268, -0.0331,  0.0058,  0.0345,  0.0366, -0.0073,\n",
      "         0.0294, -0.0274, -0.0424, -0.0372,  0.0390, -0.0086, -0.0133,  0.0234,\n",
      "        -0.0228, -0.0413, -0.0348, -0.0060,  0.0018, -0.0090, -0.0254, -0.0053,\n",
      "         0.0186,  0.0114, -0.0120,  0.0205,  0.0234,  0.0316, -0.0125,  0.0397,\n",
      "        -0.0283,  0.0114,  0.0043, -0.0293,  0.0171, -0.0102, -0.0388, -0.0172,\n",
      "        -0.0145, -0.0047, -0.0201,  0.0356,  0.0306,  0.0038, -0.0054, -0.0279,\n",
      "        -0.0300,  0.0018, -0.0008, -0.0190, -0.0113, -0.0222, -0.0412, -0.0342,\n",
      "        -0.0275,  0.0146,  0.0336, -0.0054, -0.0237, -0.0126, -0.0353,  0.0026,\n",
      "        -0.0127, -0.0350, -0.0376, -0.0140,  0.0345, -0.0429,  0.0260, -0.0253,\n",
      "        -0.0184,  0.0344, -0.0014,  0.0402,  0.0082,  0.0352,  0.0422,  0.0266,\n",
      "         0.0140, -0.0053, -0.0126,  0.0097, -0.0164, -0.0056, -0.0320, -0.0109,\n",
      "         0.0345, -0.0101,  0.0032, -0.0019,  0.0410,  0.0063, -0.0405,  0.0009,\n",
      "         0.0104, -0.0030, -0.0280, -0.0259,  0.0413,  0.0194, -0.0284,  0.0396,\n",
      "        -0.0249, -0.0359, -0.0194,  0.0056, -0.0146, -0.0090, -0.0160,  0.0399,\n",
      "         0.0195, -0.0251, -0.0200, -0.0157,  0.0128,  0.0227,  0.0310,  0.0415,\n",
      "         0.0159,  0.0046, -0.0242, -0.0215, -0.0177,  0.0383,  0.0210,  0.0022,\n",
      "         0.0171, -0.0254, -0.0315,  0.0197, -0.0179, -0.0042, -0.0126,  0.0072,\n",
      "        -0.0045, -0.0308, -0.0395,  0.0181,  0.0411, -0.0009,  0.0343, -0.0426,\n",
      "        -0.0268,  0.0425, -0.0018, -0.0085,  0.0063, -0.0261,  0.0015,  0.0177,\n",
      "        -0.0173, -0.0338,  0.0073,  0.0058, -0.0439, -0.0130, -0.0284,  0.0015,\n",
      "         0.0009,  0.0183, -0.0228,  0.0262, -0.0058, -0.0323, -0.0223,  0.0041,\n",
      "        -0.0078,  0.0436,  0.0285, -0.0269, -0.0347, -0.0361,  0.0408,  0.0219,\n",
      "        -0.0031,  0.0169,  0.0253, -0.0082,  0.0204, -0.0047, -0.0226, -0.0385,\n",
      "        -0.0141, -0.0222,  0.0248,  0.0234, -0.0227,  0.0427, -0.0335, -0.0065],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.6.theta.weight Parameter containing:\n",
      "tensor([[-0.0285, -0.0015, -0.0079,  ..., -0.0080, -0.0405, -0.0326],\n",
      "        [ 0.0288,  0.0324, -0.0298,  ...,  0.0032, -0.0389,  0.0069],\n",
      "        [ 0.0222,  0.0384,  0.0344,  ...,  0.0427, -0.0224, -0.0087],\n",
      "        ...,\n",
      "        [ 0.0358, -0.0020, -0.0021,  ..., -0.0155, -0.0272, -0.0201],\n",
      "        [ 0.0313, -0.0367,  0.0092,  ..., -0.0062,  0.0146,  0.0075],\n",
      "        [-0.0394, -0.0022,  0.0356,  ...,  0.0238,  0.0200,  0.0346]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.6.theta.bias Parameter containing:\n",
      "tensor([ 0.0345, -0.0158, -0.0066, -0.0135,  0.0368, -0.0407, -0.0226,  0.0281,\n",
      "        -0.0221,  0.0162, -0.0238, -0.0327, -0.0053,  0.0395, -0.0261,  0.0029,\n",
      "        -0.0007, -0.0186, -0.0355,  0.0351, -0.0442,  0.0048, -0.0282,  0.0209,\n",
      "        -0.0168,  0.0402,  0.0088,  0.0137,  0.0415, -0.0288, -0.0435,  0.0227,\n",
      "         0.0031, -0.0255,  0.0396,  0.0284,  0.0326, -0.0178, -0.0256, -0.0329,\n",
      "        -0.0154, -0.0435, -0.0441, -0.0299, -0.0029, -0.0378,  0.0229, -0.0293,\n",
      "         0.0230,  0.0398,  0.0190,  0.0184, -0.0405,  0.0284, -0.0437,  0.0083,\n",
      "        -0.0376,  0.0202,  0.0227,  0.0396,  0.0390,  0.0317,  0.0403,  0.0423,\n",
      "        -0.0079,  0.0027, -0.0023,  0.0090,  0.0283,  0.0283, -0.0387, -0.0251,\n",
      "         0.0384, -0.0204,  0.0387, -0.0325,  0.0081, -0.0145, -0.0287,  0.0408,\n",
      "        -0.0291,  0.0050, -0.0192,  0.0279,  0.0322, -0.0436, -0.0187,  0.0182,\n",
      "        -0.0317, -0.0252,  0.0435,  0.0142, -0.0357, -0.0008,  0.0403,  0.0305,\n",
      "         0.0058, -0.0044,  0.0313,  0.0342,  0.0346, -0.0258, -0.0418, -0.0292,\n",
      "        -0.0316, -0.0100,  0.0183, -0.0249, -0.0113,  0.0378, -0.0434, -0.0360,\n",
      "        -0.0402,  0.0225, -0.0325, -0.0127,  0.0174,  0.0370,  0.0134, -0.0408,\n",
      "         0.0079,  0.0286, -0.0046, -0.0102,  0.0369,  0.0086, -0.0408,  0.0389,\n",
      "        -0.0394, -0.0194, -0.0424,  0.0206, -0.0174,  0.0172, -0.0076, -0.0020,\n",
      "         0.0307, -0.0021,  0.0012,  0.0321,  0.0063,  0.0171, -0.0356, -0.0359,\n",
      "         0.0403,  0.0004, -0.0175, -0.0325,  0.0364, -0.0319,  0.0183,  0.0267,\n",
      "         0.0392,  0.0351,  0.0280,  0.0292,  0.0002, -0.0385,  0.0284,  0.0180,\n",
      "        -0.0087,  0.0426, -0.0135, -0.0028, -0.0218,  0.0394, -0.0130, -0.0282,\n",
      "        -0.0434,  0.0153,  0.0390, -0.0402, -0.0279,  0.0211, -0.0270, -0.0212,\n",
      "         0.0335, -0.0414,  0.0189, -0.0015,  0.0061,  0.0411,  0.0056,  0.0082,\n",
      "         0.0153,  0.0105, -0.0152,  0.0328, -0.0068,  0.0115,  0.0149, -0.0292,\n",
      "        -0.0221,  0.0363,  0.0112,  0.0218, -0.0313, -0.0197, -0.0396,  0.0088,\n",
      "        -0.0259,  0.0191,  0.0056, -0.0081, -0.0028, -0.0389, -0.0028, -0.0197,\n",
      "        -0.0215,  0.0151, -0.0134,  0.0149, -0.0183,  0.0317,  0.0400, -0.0315,\n",
      "         0.0291, -0.0187,  0.0046,  0.0162,  0.0208,  0.0092,  0.0304, -0.0096,\n",
      "         0.0293,  0.0088,  0.0068,  0.0221,  0.0302,  0.0116, -0.0220,  0.0146,\n",
      "        -0.0278, -0.0320,  0.0379, -0.0370, -0.0120, -0.0021,  0.0004, -0.0190,\n",
      "        -0.0426, -0.0359, -0.0061,  0.0296,  0.0218,  0.0108, -0.0294, -0.0079,\n",
      "        -0.0395,  0.0001, -0.0381,  0.0233,  0.0421, -0.0432,  0.0041,  0.0082],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.7.theta.weight Parameter containing:\n",
      "tensor([[-0.0592,  0.0292, -0.0354,  ..., -0.0231,  0.0001, -0.0166],\n",
      "        [-0.0077,  0.0089,  0.0311,  ..., -0.0541, -0.0588,  0.0156],\n",
      "        [-0.0090,  0.0358,  0.0373,  ..., -0.0425,  0.0393,  0.0512],\n",
      "        ...,\n",
      "        [ 0.0162,  0.0571,  0.0314,  ..., -0.0308,  0.0290, -0.0255],\n",
      "        [ 0.0458, -0.0586, -0.0549,  ...,  0.0018,  0.0412,  0.0103],\n",
      "        [-0.0271, -0.0486, -0.0413,  ...,  0.0075,  0.0523,  0.0244]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.7.theta.bias Parameter containing:\n",
      "tensor([-0.0106, -0.0230,  0.0217, -0.0437,  0.0262,  0.0484, -0.0273,  0.0241,\n",
      "        -0.0181, -0.0125,  0.0603,  0.0345, -0.0521, -0.0327,  0.0190,  0.0238,\n",
      "         0.0002, -0.0494,  0.0597,  0.0410,  0.0027,  0.0019, -0.0100,  0.0361,\n",
      "        -0.0595, -0.0101, -0.0513, -0.0535,  0.0040,  0.0395,  0.0084,  0.0070,\n",
      "         0.0553, -0.0345, -0.0356, -0.0439, -0.0470,  0.0520, -0.0480, -0.0187,\n",
      "        -0.0333,  0.0471,  0.0316,  0.0235,  0.0544,  0.0362, -0.0376,  0.0259,\n",
      "         0.0038, -0.0513, -0.0432, -0.0224,  0.0303,  0.0487,  0.0037,  0.0623,\n",
      "         0.0595, -0.0411,  0.0112,  0.0298,  0.0256, -0.0158, -0.0102, -0.0535,\n",
      "        -0.0538,  0.0547,  0.0267, -0.0123,  0.0215, -0.0493, -0.0605,  0.0069,\n",
      "        -0.0127,  0.0218,  0.0099, -0.0177, -0.0428,  0.0574, -0.0093,  0.0105,\n",
      "         0.0059, -0.0493,  0.0331,  0.0048,  0.0405,  0.0422, -0.0331, -0.0400,\n",
      "        -0.0361,  0.0478, -0.0055,  0.0530, -0.0315,  0.0509, -0.0433, -0.0116,\n",
      "        -0.0428, -0.0393,  0.0001, -0.0353,  0.0318, -0.0565,  0.0329,  0.0325,\n",
      "        -0.0488, -0.0502,  0.0499,  0.0422,  0.0567, -0.0400,  0.0468, -0.0450,\n",
      "        -0.0248,  0.0570,  0.0163,  0.0533, -0.0573, -0.0330,  0.0031, -0.0609,\n",
      "        -0.0247, -0.0201,  0.0529,  0.0508,  0.0259, -0.0061, -0.0145,  0.0603],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.8.theta.weight Parameter containing:\n",
      "tensor([[-0.0076,  0.0293, -0.0320,  ...,  0.0023,  0.0080,  0.0272],\n",
      "        [ 0.0415, -0.0084, -0.0018,  ...,  0.0297,  0.0412, -0.0533],\n",
      "        [ 0.0824, -0.0010, -0.0814,  ..., -0.0455,  0.0504,  0.0261],\n",
      "        ...,\n",
      "        [ 0.0350,  0.0685,  0.0423,  ...,  0.0177, -0.0193,  0.0545],\n",
      "        [ 0.0153, -0.0251, -0.0192,  ...,  0.0688, -0.0620, -0.0224],\n",
      "        [-0.0176, -0.0181,  0.0633,  ...,  0.0282, -0.0673, -0.0289]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.8.theta.bias Parameter containing:\n",
      "tensor([-4.0478e-02, -8.3713e-02, -1.5993e-03, -3.1594e-03, -5.1236e-02,\n",
      "        -3.3972e-02,  7.3600e-02,  8.4886e-02, -6.6163e-02, -3.3893e-02,\n",
      "         3.6084e-02,  6.4844e-02,  6.7632e-02,  3.5982e-02,  6.8100e-02,\n",
      "        -6.7689e-02,  1.6133e-02,  6.1407e-02,  6.6120e-02, -2.1828e-02,\n",
      "        -1.4552e-02,  2.8979e-02,  5.8113e-02,  7.6245e-02, -5.3390e-02,\n",
      "         4.3026e-02, -5.8413e-02, -1.3322e-02, -7.2999e-02,  3.8153e-02,\n",
      "        -4.9039e-02,  8.1734e-02, -2.5795e-02, -8.6889e-02, -8.5341e-02,\n",
      "         3.0364e-02,  4.0819e-05,  2.2039e-02,  6.9106e-02,  1.1324e-02,\n",
      "         2.0410e-02,  5.5928e-02, -7.8456e-02, -3.2903e-02, -6.2008e-02,\n",
      "         7.7240e-02,  8.1083e-02,  2.9741e-02, -7.3436e-02,  6.4229e-02,\n",
      "        -3.5338e-02,  3.5913e-02,  2.2408e-02, -1.7929e-02,  8.6899e-02,\n",
      "        -5.0786e-02, -7.2670e-02, -3.0295e-02, -8.7410e-02, -4.8601e-02,\n",
      "        -7.2235e-02, -6.4466e-03,  5.4972e-04, -8.6866e-02, -2.6938e-02,\n",
      "        -7.1359e-02, -2.2494e-02, -2.1458e-02, -3.3065e-03, -1.9821e-02,\n",
      "         4.5424e-02, -5.2236e-02, -1.1211e-02,  4.8865e-02,  8.2750e-02,\n",
      "         5.3215e-02, -1.6861e-02, -8.0717e-02, -7.9773e-02,  3.8801e-03,\n",
      "         8.6813e-02,  1.0636e-02,  2.6142e-02,  1.5446e-02,  4.8623e-02,\n",
      "        -4.0584e-02,  6.2697e-02, -8.2190e-02, -3.7499e-02,  5.2341e-02,\n",
      "         7.2726e-02, -3.0522e-02, -8.4140e-02,  1.6490e-02, -3.3511e-02,\n",
      "        -7.3910e-02, -4.9786e-02, -6.5914e-02,  6.8394e-02, -3.1207e-02,\n",
      "        -8.2707e-02, -6.9349e-02, -3.5806e-02, -4.1172e-02, -5.6004e-02,\n",
      "         9.0555e-03,  8.0297e-02, -6.4652e-02,  1.4100e-03,  3.4365e-02,\n",
      "        -3.1691e-02, -4.3106e-02,  4.0859e-02,  3.8224e-02, -7.7903e-02,\n",
      "        -4.7309e-02,  3.5236e-02, -3.2545e-02, -8.3166e-02, -4.3346e-02,\n",
      "         8.6851e-02, -3.0454e-02, -3.4846e-02, -3.5815e-02, -8.2409e-02,\n",
      "        -5.5274e-02,  5.5192e-02, -5.9111e-02,  6.3656e-02, -2.0621e-02,\n",
      "        -5.8166e-02, -4.6468e-02,  2.4859e-02,  7.2703e-02,  4.6435e-02,\n",
      "         4.2591e-02, -1.4827e-02,  3.2543e-02,  7.0516e-03, -1.2502e-02,\n",
      "        -5.6280e-02,  6.4921e-03,  4.7925e-02, -4.2656e-02, -8.5277e-02,\n",
      "         6.7619e-02,  6.4318e-03,  8.0454e-02, -5.8843e-02,  5.6688e-02,\n",
      "        -7.4650e-02, -1.0161e-02, -6.3103e-04,  5.4057e-03, -5.0882e-02,\n",
      "         2.8597e-02, -8.2234e-02,  2.4231e-02,  6.1941e-02, -5.7429e-02,\n",
      "         2.9148e-02, -4.0048e-02, -1.2923e-03, -7.9001e-02, -2.9711e-02,\n",
      "        -2.0707e-02,  2.9403e-02, -3.7284e-02,  7.3862e-02,  6.7035e-02,\n",
      "         3.4904e-02,  6.2337e-02,  8.0538e-02, -2.3875e-02, -3.9143e-02,\n",
      "         4.3101e-02, -1.6312e-02, -4.3681e-02,  8.0833e-03,  5.8237e-02,\n",
      "        -3.8171e-02,  7.3642e-02, -4.1917e-02, -8.1724e-02,  6.3508e-02,\n",
      "        -3.0660e-02, -5.4795e-02, -6.2705e-02,  8.1806e-02, -1.9976e-02,\n",
      "         4.4213e-03, -2.5865e-02, -5.3741e-02,  5.6753e-02,  4.1296e-02,\n",
      "         3.2141e-02,  2.5842e-03, -4.5146e-02,  1.5873e-02, -4.3962e-02,\n",
      "         1.1291e-02, -2.4927e-02,  5.4581e-02,  4.5885e-03, -4.3071e-02,\n",
      "        -7.2657e-02, -7.0035e-02,  3.5457e-02, -1.9244e-03, -7.3556e-02,\n",
      "         2.3363e-02,  7.7502e-02,  8.7297e-02, -3.4240e-03, -3.9034e-02,\n",
      "         1.2246e-02,  9.2961e-03, -4.8952e-02,  3.8987e-02,  6.3185e-02,\n",
      "         4.9923e-02, -4.9313e-03, -8.5088e-02, -6.3837e-02, -4.8683e-02,\n",
      "        -4.3373e-02,  9.8649e-03, -5.2287e-02, -3.8845e-03, -3.3431e-02,\n",
      "         4.3987e-02, -5.1697e-02, -8.3937e-02, -5.2609e-02,  5.4746e-02,\n",
      "         3.1035e-02,  1.4516e-02,  5.1019e-02, -2.8417e-02, -4.7436e-02,\n",
      "        -5.8318e-02,  6.6276e-02,  4.0096e-02, -2.2138e-02,  5.8994e-02,\n",
      "         7.2219e-02, -5.7386e-02, -1.5192e-03,  7.7481e-02, -6.8427e-03,\n",
      "        -3.1051e-02, -4.1794e-02,  8.5361e-02,  7.4194e-02, -4.4433e-02,\n",
      "        -4.0009e-02], device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.9.theta.weight Parameter containing:\n",
      "tensor([[-0.0426, -0.0072, -0.0605,  ..., -0.0532, -0.0164,  0.0452],\n",
      "        [-0.0613, -0.0511,  0.0016,  ...,  0.0332, -0.0521,  0.0470],\n",
      "        [ 0.0391,  0.0395, -0.0452,  ...,  0.0162, -0.0203,  0.0004],\n",
      "        ...,\n",
      "        [-0.0090,  0.0174, -0.0030,  ..., -0.0272, -0.0179,  0.0135],\n",
      "        [-0.0528, -0.0416,  0.0425,  ..., -0.0270,  0.0151, -0.0271],\n",
      "        [ 0.0284, -0.0312, -0.0471,  ...,  0.0103,  0.0499,  0.0307]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.9.theta.bias Parameter containing:\n",
      "tensor([-0.0199, -0.0478, -0.0455,  0.0464,  0.0496, -0.0206,  0.0543, -0.0411,\n",
      "         0.0192, -0.0552, -0.0373, -0.0078,  0.0409, -0.0022, -0.0566,  0.0226,\n",
      "        -0.0547, -0.0571,  0.0573, -0.0461, -0.0290, -0.0262, -0.0281,  0.0126,\n",
      "         0.0287,  0.0117,  0.0494,  0.0587,  0.0243,  0.0153, -0.0307,  0.0359,\n",
      "        -0.0077,  0.0228, -0.0033, -0.0003, -0.0397,  0.0200,  0.0540, -0.0425,\n",
      "         0.0560,  0.0175,  0.0150, -0.0339,  0.0487,  0.0623,  0.0371, -0.0246,\n",
      "         0.0237,  0.0178, -0.0290, -0.0563, -0.0219,  0.0313, -0.0159, -0.0196,\n",
      "        -0.0107,  0.0486, -0.0443,  0.0108,  0.0417, -0.0545,  0.0542,  0.0229,\n",
      "        -0.0468, -0.0052, -0.0467,  0.0489,  0.0356,  0.0493,  0.0199,  0.0178,\n",
      "        -0.0074,  0.0330, -0.0598, -0.0083, -0.0404, -0.0605, -0.0089, -0.0001,\n",
      "        -0.0178,  0.0391, -0.0145,  0.0406,  0.0193, -0.0596, -0.0457,  0.0150,\n",
      "        -0.0601,  0.0162, -0.0363, -0.0480, -0.0499, -0.0470, -0.0204, -0.0202,\n",
      "         0.0199,  0.0082,  0.0292,  0.0164, -0.0457, -0.0553, -0.0090, -0.0542,\n",
      "         0.0367,  0.0319, -0.0439, -0.0344, -0.0174, -0.0011,  0.0077, -0.0194,\n",
      "        -0.0490, -0.0575,  0.0522,  0.0340, -0.0279,  0.0040,  0.0533, -0.0375,\n",
      "        -0.0596,  0.0484, -0.0542,  0.0387,  0.0443,  0.0351,  0.0509, -0.0566,\n",
      "         0.0520,  0.0562,  0.0034, -0.0434,  0.0158, -0.0257, -0.0111, -0.0455,\n",
      "        -0.0620, -0.0146,  0.0145, -0.0512, -0.0346, -0.0353, -0.0149,  0.0484,\n",
      "         0.0160,  0.0123,  0.0547, -0.0304, -0.0096, -0.0453,  0.0366, -0.0129,\n",
      "         0.0327,  0.0144,  0.0290,  0.0051, -0.0470, -0.0248,  0.0124,  0.0147,\n",
      "         0.0096, -0.0316,  0.0389,  0.0297,  0.0463, -0.0253,  0.0230, -0.0308,\n",
      "         0.0583, -0.0622,  0.0291, -0.0094, -0.0554, -0.0570, -0.0318,  0.0508,\n",
      "        -0.0128,  0.0049, -0.0421, -0.0465, -0.0084,  0.0225,  0.0556,  0.0201,\n",
      "         0.0354,  0.0589, -0.0585, -0.0081,  0.0454,  0.0251, -0.0140,  0.0375,\n",
      "         0.0554, -0.0288, -0.0063,  0.0213,  0.0582, -0.0190, -0.0042, -0.0328,\n",
      "         0.0378, -0.0122, -0.0149, -0.0310,  0.0233,  0.0112, -0.0453, -0.0183,\n",
      "         0.0413, -0.0208,  0.0550,  0.0198, -0.0406,  0.0379,  0.0257,  0.0436,\n",
      "         0.0371, -0.0511, -0.0238, -0.0270, -0.0109, -0.0584, -0.0519, -0.0422,\n",
      "        -0.0037,  0.0011,  0.0089,  0.0587, -0.0227, -0.0173,  0.0257,  0.0383,\n",
      "        -0.0378, -0.0596, -0.0215, -0.0616, -0.0156, -0.0534,  0.0398, -0.0428,\n",
      "         0.0232, -0.0146,  0.0398,  0.0077, -0.0087,  0.0255,  0.0242,  0.0493,\n",
      "        -0.0145, -0.0131,  0.0480, -0.0424,  0.0343,  0.0269,  0.0060, -0.0368,\n",
      "         0.0040, -0.0200,  0.0612, -0.0140,  0.0380, -0.0096, -0.0503, -0.0364,\n",
      "        -0.0086, -0.0504,  0.0314,  0.0005,  0.0391,  0.0209,  0.0152,  0.0570,\n",
      "         0.0019,  0.0157, -0.0207,  0.0237, -0.0057, -0.0612,  0.0147, -0.0159,\n",
      "        -0.0325, -0.0007, -0.0225, -0.0147, -0.0073, -0.0115,  0.0249,  0.0223,\n",
      "         0.0045,  0.0040,  0.0086, -0.0325, -0.0147,  0.0196,  0.0040,  0.0376,\n",
      "        -0.0433,  0.0469,  0.0201,  0.0042, -0.0491, -0.0281,  0.0389,  0.0561,\n",
      "        -0.0507, -0.0196, -0.0618,  0.0387,  0.0008, -0.0358, -0.0274, -0.0377,\n",
      "         0.0296,  0.0358, -0.0567, -0.0485, -0.0080,  0.0196,  0.0377,  0.0103,\n",
      "        -0.0240, -0.0098,  0.0053,  0.0422, -0.0182, -0.0428, -0.0317,  0.0599,\n",
      "        -0.0578, -0.0099, -0.0372, -0.0008, -0.0241,  0.0203, -0.0421,  0.0247,\n",
      "         0.0579, -0.0147,  0.0415,  0.0169, -0.0312,  0.0571,  0.0355, -0.0233,\n",
      "         0.0319,  0.0468,  0.0100, -0.0348,  0.0327,  0.0363, -0.0354,  0.0118,\n",
      "         0.0183,  0.0612,  0.0479, -0.0085,  0.0382,  0.0164,  0.0393,  0.0151,\n",
      "        -0.0358, -0.0341,  0.0470, -0.0566,  0.0163,  0.0134, -0.0148, -0.0186,\n",
      "         0.0533,  0.0093, -0.0293, -0.0127, -0.0082,  0.0443, -0.0577, -0.0536,\n",
      "        -0.0474,  0.0504, -0.0099,  0.0224, -0.0594,  0.0620, -0.0298, -0.0585,\n",
      "        -0.0405,  0.0514, -0.0329, -0.0573,  0.0284, -0.0160,  0.0018,  0.0189,\n",
      "         0.0353, -0.0587,  0.0610,  0.0080, -0.0173,  0.0557, -0.0369,  0.0574,\n",
      "        -0.0002, -0.0372, -0.0576,  0.0148, -0.0422, -0.0164,  0.0314,  0.0295,\n",
      "        -0.0069, -0.0368,  0.0230,  0.0617, -0.0041, -0.0234, -0.0443, -0.0369,\n",
      "         0.0187, -0.0608, -0.0087, -0.0421,  0.0446,  0.0054, -0.0188,  0.0119,\n",
      "         0.0420, -0.0353,  0.0385, -0.0012,  0.0157,  0.0067,  0.0024,  0.0148,\n",
      "         0.0344, -0.0485, -0.0403,  0.0094,  0.0388,  0.0245, -0.0293, -0.0023,\n",
      "        -0.0239,  0.0180,  0.0285,  0.0310, -0.0392,  0.0171,  0.0473,  0.0579,\n",
      "        -0.0565,  0.0509, -0.0552,  0.0042,  0.0138, -0.0617, -0.0133,  0.0125,\n",
      "         0.0037, -0.0082,  0.0173,  0.0087,  0.0113, -0.0251,  0.0070,  0.0474,\n",
      "        -0.0448,  0.0146, -0.0064,  0.0318, -0.0004,  0.0192, -0.0269,  0.0553,\n",
      "        -0.0272, -0.0013, -0.0118, -0.0346,  0.0317, -0.0586, -0.0057,  0.0252,\n",
      "        -0.0180, -0.0271, -0.0090,  0.0460, -0.0236,  0.0552, -0.0278,  0.0473,\n",
      "         0.0201,  0.0594, -0.0057, -0.0588, -0.0531,  0.0256, -0.0324,  0.0260,\n",
      "         0.0220, -0.0174,  0.0238,  0.0490, -0.0131,  0.0432,  0.0073, -0.0411,\n",
      "         0.0336,  0.0261,  0.0177, -0.0178,  0.0124, -0.0269, -0.0139,  0.0525],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.10.theta.weight Parameter containing:\n",
      "tensor([[-0.0410, -0.0214,  0.0352,  ..., -0.0105, -0.0297, -0.0059],\n",
      "        [ 0.0362,  0.0194,  0.0106,  ..., -0.0176,  0.0018,  0.0098],\n",
      "        [ 0.0325,  0.0025, -0.0294,  ...,  0.0432,  0.0226, -0.0155],\n",
      "        ...,\n",
      "        [-0.0359,  0.0221,  0.0001,  ..., -0.0209,  0.0399,  0.0216],\n",
      "        [ 0.0140,  0.0146,  0.0205,  ...,  0.0334,  0.0314,  0.0015],\n",
      "        [ 0.0095, -0.0377,  0.0230,  ...,  0.0345, -0.0306,  0.0170]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.0.layers.10.theta.bias Parameter containing:\n",
      "tensor([ 2.2792e-02,  7.7774e-04, -8.5727e-05,  ..., -3.0523e-02,\n",
      "         6.4755e-04, -2.1639e-02], device='cuda:0', requires_grad=True)\n",
      "layers.1.weight Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n",
      "layers.1.bias Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "layers.4.weight Parameter containing:\n",
      "tensor([[-0.0042, -0.0117, -0.0070,  ..., -0.0058,  0.0213, -0.0097],\n",
      "        [-0.0053,  0.0004,  0.0141,  ..., -0.0054, -0.0141,  0.0012],\n",
      "        [-0.0126, -0.0029,  0.0139,  ...,  0.0124, -0.0071, -0.0055],\n",
      "        ...,\n",
      "        [-0.0155,  0.0005, -0.0155,  ..., -0.0009,  0.0211, -0.0127],\n",
      "        [ 0.0147, -0.0205,  0.0013,  ...,  0.0133, -0.0162, -0.0073],\n",
      "        [-0.0194,  0.0154,  0.0090,  ..., -0.0196, -0.0119, -0.0155]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.4.bias Parameter containing:\n",
      "tensor([-5.3809e-03, -1.8634e-02,  2.0592e-02, -1.6726e-02, -1.1297e-02,\n",
      "        -1.1047e-02, -1.0965e-02,  1.5022e-03,  2.5574e-03,  1.9243e-02,\n",
      "         9.2509e-03, -2.1951e-02,  6.7942e-03, -1.1527e-02, -1.9847e-03,\n",
      "        -1.1531e-02, -7.6161e-04, -1.5148e-02,  2.0970e-02, -1.6822e-02,\n",
      "         6.0066e-03, -1.4902e-02,  1.1457e-02,  7.4085e-04, -8.9537e-03,\n",
      "        -6.8574e-03, -7.3064e-03,  2.6790e-03,  8.2267e-04,  4.9027e-03,\n",
      "         1.1303e-02, -1.3188e-02,  5.6874e-03,  1.6609e-03, -9.1553e-03,\n",
      "        -1.9517e-02, -1.6755e-02,  1.7024e-02,  5.5464e-04,  7.9648e-03,\n",
      "        -1.3760e-02,  3.6060e-03,  1.6237e-02,  6.4190e-03,  1.0551e-02,\n",
      "        -7.5126e-03,  2.5478e-03, -2.3614e-03, -2.7808e-03, -2.1904e-02,\n",
      "        -1.8136e-02,  1.3635e-02, -2.2301e-03, -3.7081e-03, -1.3289e-02,\n",
      "         3.5989e-03,  7.5954e-04,  2.2057e-02,  9.6744e-03,  1.4123e-02,\n",
      "        -1.3831e-02,  1.7666e-02, -1.3536e-02, -4.3177e-03, -8.2929e-03,\n",
      "         1.2185e-02,  6.1971e-03,  2.2348e-03,  3.8599e-03,  1.9843e-02,\n",
      "        -8.0012e-04, -2.8795e-03,  8.0850e-03,  1.9352e-02,  1.1815e-02,\n",
      "         4.9605e-03,  2.0921e-02,  2.1426e-02, -1.2227e-02, -3.6584e-03,\n",
      "        -1.3925e-02, -1.2447e-02,  1.7937e-02,  1.7216e-02, -1.0194e-02,\n",
      "         1.6951e-02,  4.0586e-03, -2.6579e-03,  1.4381e-02,  9.6379e-03,\n",
      "         6.3041e-03, -4.4478e-04, -1.8979e-02,  1.5157e-02, -6.0369e-03,\n",
      "        -1.2046e-02,  1.2815e-02,  1.0245e-02, -1.0807e-03, -4.4811e-03,\n",
      "         1.5604e-02, -9.9825e-03, -2.0896e-02, -2.1757e-02,  1.3820e-04,\n",
      "        -1.6339e-02,  1.9864e-02,  1.5467e-02,  3.8378e-03,  1.0958e-02,\n",
      "         1.4053e-04,  5.2233e-03,  1.8798e-02,  8.1231e-03, -1.5345e-02,\n",
      "         7.8122e-03,  1.2621e-02,  1.9490e-02,  3.1347e-03, -2.1036e-02,\n",
      "         2.9916e-03,  3.4708e-03,  2.1116e-02, -1.7716e-02, -1.0895e-02,\n",
      "         1.1522e-02, -1.5636e-02,  1.4225e-02,  1.4533e-02,  1.9570e-02,\n",
      "        -1.2832e-02, -1.8035e-02, -1.7430e-02,  7.9903e-03, -1.3628e-02,\n",
      "        -1.5353e-02,  6.0572e-03,  1.0638e-02,  1.5517e-02,  8.7462e-03,\n",
      "        -3.2961e-03, -1.8602e-02, -6.5057e-03,  1.9104e-03, -4.1371e-03,\n",
      "         1.9569e-02, -1.1939e-02, -9.4030e-03,  2.7968e-03,  1.1023e-02,\n",
      "         2.1990e-02,  7.3906e-03, -7.0420e-03, -1.7643e-02,  2.1164e-02,\n",
      "        -9.1428e-03, -1.9057e-02,  7.4200e-03,  1.5160e-03, -2.1796e-02,\n",
      "        -1.0483e-02,  2.0414e-02,  2.9900e-03, -2.0953e-02, -1.7895e-02,\n",
      "        -3.5973e-03, -1.4073e-02,  1.9791e-02,  1.8550e-02, -8.6853e-03,\n",
      "         9.3742e-03,  1.3097e-02, -1.1861e-02,  5.4693e-03,  1.9126e-02,\n",
      "         3.1724e-03,  3.0057e-03,  1.3185e-02, -1.7181e-02,  1.4840e-02,\n",
      "         1.7007e-02, -1.9982e-02, -1.9857e-02, -9.4740e-03,  9.0350e-03,\n",
      "         1.5081e-02, -8.3049e-03,  1.6671e-02,  1.6142e-02, -8.1544e-03,\n",
      "        -1.7106e-04, -1.8136e-02,  1.0339e-02,  1.3577e-02,  1.9460e-03,\n",
      "         1.7922e-02,  4.0180e-03, -3.1859e-03,  1.5055e-02,  5.3371e-03,\n",
      "        -6.3524e-03, -1.9184e-02, -1.0822e-02,  1.9563e-02, -3.0184e-03,\n",
      "         2.0528e-02,  1.0952e-02, -1.2641e-02,  7.3499e-03,  1.7002e-02,\n",
      "        -2.1830e-02, -1.2780e-03,  7.0782e-03, -1.9845e-02, -7.8626e-04,\n",
      "        -1.6602e-02,  1.4203e-02, -2.1895e-02, -1.5202e-03, -8.0437e-03,\n",
      "         1.1890e-03, -1.7113e-02,  3.1437e-03,  2.0915e-02, -1.6995e-04,\n",
      "        -9.0310e-03, -1.2802e-02,  1.9761e-02, -4.5965e-03,  3.6638e-03,\n",
      "        -8.2078e-03, -9.6073e-04,  5.2253e-03, -4.5026e-03, -8.8442e-03,\n",
      "        -5.9693e-03,  1.3242e-02,  8.8306e-03, -3.6297e-03,  1.9001e-02,\n",
      "         7.3701e-03, -1.9172e-02,  1.7581e-02,  2.0068e-02,  2.2378e-04,\n",
      "         5.0029e-03, -5.1561e-03, -5.8473e-03, -1.4281e-02, -1.0061e-02,\n",
      "        -2.5099e-04,  1.1977e-02,  1.4063e-02, -1.7895e-02, -7.5808e-03,\n",
      "         2.1599e-02, -1.9363e-02,  9.9593e-03,  1.5438e-02, -1.0084e-02,\n",
      "        -4.2262e-03,  1.0584e-03, -1.6685e-02, -9.7544e-03,  1.5133e-02,\n",
      "         1.7870e-02,  1.7574e-02, -2.0155e-02, -4.4721e-03, -1.3158e-02,\n",
      "         3.6911e-03,  1.2513e-02,  1.2991e-02, -6.7255e-03,  6.4530e-03,\n",
      "        -1.8455e-02, -6.2677e-03,  1.6737e-02, -1.6414e-02,  1.8750e-02,\n",
      "         7.8792e-03, -7.4133e-03, -2.1188e-02, -4.8345e-03,  8.4293e-03,\n",
      "         1.9341e-02, -5.7390e-03,  5.7200e-03, -1.7199e-02, -6.8730e-05,\n",
      "        -1.1402e-02,  6.5141e-03, -1.0043e-03, -5.6824e-03,  2.8220e-03,\n",
      "        -1.1083e-02,  3.8500e-03,  8.4247e-03,  4.1727e-04,  1.2400e-03,\n",
      "        -4.4836e-03,  1.4399e-02, -1.2052e-02, -1.9940e-02, -1.1465e-02,\n",
      "        -1.8614e-03, -5.8682e-03, -1.6464e-02, -1.4664e-02, -1.1426e-02,\n",
      "         1.1876e-02, -8.2583e-03,  1.3459e-02, -5.8393e-03, -6.3556e-03,\n",
      "         2.0697e-02, -9.3462e-03,  1.2706e-02,  2.1109e-02, -3.5613e-03,\n",
      "         1.4030e-02, -1.0875e-02, -8.6011e-03,  1.0278e-02,  7.5019e-03,\n",
      "         1.3548e-02, -2.1844e-02, -1.7896e-03,  2.1642e-02, -1.8271e-02,\n",
      "        -1.5941e-02, -4.0715e-03, -8.1900e-03,  1.7393e-02, -3.6627e-03,\n",
      "         3.1991e-03, -1.5930e-02, -1.7352e-02, -1.2998e-02,  3.5073e-03,\n",
      "        -1.6180e-02,  1.0942e-02, -6.2022e-03,  1.4014e-02, -3.3072e-04,\n",
      "         1.2456e-02,  6.2060e-03,  3.4089e-03,  1.2131e-02,  3.3154e-03,\n",
      "        -5.6353e-03, -1.3614e-02, -1.7305e-02,  1.8407e-02, -9.2276e-04,\n",
      "         1.0023e-02, -1.9343e-02,  1.3227e-02, -8.8989e-03, -1.7119e-02,\n",
      "         9.0047e-05, -1.2098e-02, -1.5147e-02,  4.3459e-03, -2.6252e-03,\n",
      "         3.5958e-03,  7.3664e-03,  1.6466e-02,  4.1714e-03,  8.6614e-03,\n",
      "        -6.6007e-03, -1.0025e-02,  1.9385e-02, -1.8032e-02, -1.4509e-02,\n",
      "         8.7051e-03, -1.3656e-02, -7.9521e-03, -1.4103e-02, -2.0842e-02,\n",
      "        -2.0077e-02,  8.0217e-03,  1.5472e-02,  1.9243e-02,  1.7915e-02,\n",
      "        -2.4218e-03, -1.0791e-02, -2.6870e-03,  1.3946e-02, -2.5951e-03,\n",
      "        -4.4660e-03, -1.6328e-02,  3.8531e-04,  8.7063e-03,  3.9201e-03,\n",
      "        -1.2240e-02,  5.0637e-03, -2.1410e-02, -1.0948e-02,  2.8638e-03,\n",
      "        -2.0643e-02, -9.2262e-03, -1.1847e-02,  7.5706e-03,  1.8243e-02,\n",
      "        -1.2721e-03,  6.7516e-03,  9.7917e-03,  2.6658e-03, -7.2301e-03,\n",
      "        -1.0711e-02, -3.2048e-03,  6.9484e-03,  9.1818e-03, -1.9892e-02,\n",
      "         1.2536e-02, -4.0260e-03, -1.9093e-03, -9.5718e-03, -1.7412e-02,\n",
      "         1.1016e-02, -1.0505e-02,  1.3242e-02, -1.5709e-02,  1.9890e-02,\n",
      "         1.3431e-02, -1.7207e-02, -1.9348e-02,  1.1982e-02, -1.2552e-03,\n",
      "        -9.5849e-03,  2.0744e-02, -7.6239e-03, -1.7451e-02,  1.5700e-02,\n",
      "         1.5216e-02,  1.0313e-02,  4.4104e-03, -2.1714e-02,  1.2644e-02,\n",
      "        -1.3448e-02,  1.6470e-02,  1.1883e-02,  1.3956e-02,  2.1638e-02,\n",
      "         2.2064e-02, -2.0057e-02,  1.2744e-02, -1.0133e-02,  5.1606e-03,\n",
      "         1.2394e-02, -2.8252e-03,  2.0801e-02, -9.2182e-03, -1.4610e-02,\n",
      "        -1.3252e-02,  7.8690e-03, -1.9378e-02,  2.5429e-03,  1.5774e-02,\n",
      "         7.6052e-03, -1.8089e-02,  1.3586e-02,  4.1410e-03,  9.9579e-03,\n",
      "        -8.6793e-03, -2.8499e-03, -1.7316e-02, -1.3415e-02,  1.2114e-02,\n",
      "        -8.4771e-03,  1.0170e-02,  4.9921e-04, -4.2011e-03, -2.1844e-02,\n",
      "        -1.3998e-02, -4.0600e-03,  2.1784e-03,  2.0209e-02,  7.8901e-03,\n",
      "         7.7814e-03,  2.1400e-02,  4.3881e-03, -2.8144e-03,  2.0521e-02,\n",
      "        -2.0327e-02, -9.4975e-04,  5.3194e-03,  7.0079e-03,  1.1196e-02,\n",
      "        -9.8053e-03,  7.1607e-03,  1.0939e-02,  1.1976e-02, -5.2811e-03,\n",
      "         7.5211e-03,  1.4685e-02, -1.1208e-02,  1.5737e-02, -1.2438e-02,\n",
      "        -6.8431e-03, -7.6760e-03, -3.6513e-03,  8.6684e-03, -1.0294e-02,\n",
      "         1.3868e-02,  1.7770e-03,  9.1030e-03, -1.7485e-02, -1.8753e-02,\n",
      "         1.9978e-02,  1.0309e-02], device='cuda:0', requires_grad=True)\n",
      "layers.5.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n",
      "layers.5.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "layers.8.weight Parameter containing:\n",
      "tensor([[-0.0127, -0.0176, -0.0313,  ..., -0.0175,  0.0374,  0.0365],\n",
      "        [ 0.0236, -0.0338,  0.0138,  ...,  0.0388,  0.0120,  0.0376],\n",
      "        [-0.0335, -0.0048,  0.0004,  ..., -0.0058, -0.0109,  0.0287],\n",
      "        ...,\n",
      "        [-0.0425, -0.0155, -0.0237,  ..., -0.0024,  0.0131,  0.0404],\n",
      "        [-0.0189,  0.0057,  0.0403,  ...,  0.0130, -0.0422, -0.0432],\n",
      "        [-0.0418, -0.0095,  0.0240,  ...,  0.0043,  0.0386, -0.0191]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.8.bias Parameter containing:\n",
      "tensor([-2.4719e-02,  3.2164e-02, -4.1985e-03,  2.4701e-02,  1.9504e-03,\n",
      "        -2.7321e-02, -2.7026e-02,  5.6303e-03, -2.3737e-02,  2.5816e-02,\n",
      "        -9.1037e-03, -2.9741e-02, -3.8422e-02,  5.2702e-03,  3.8579e-02,\n",
      "         4.0155e-02,  3.6923e-02, -1.3319e-02, -4.2175e-02,  1.1353e-02,\n",
      "        -3.3067e-02, -1.5998e-02, -8.3495e-03,  2.5899e-02, -2.9043e-02,\n",
      "         2.5490e-02,  3.2142e-02, -6.7848e-03,  2.2486e-02,  5.5711e-04,\n",
      "        -1.2019e-02, -7.1396e-03,  4.2307e-02, -4.0074e-02,  9.6279e-04,\n",
      "         3.4803e-03, -1.2303e-02,  1.8403e-02,  3.8274e-02,  3.2552e-02,\n",
      "         2.2137e-02, -4.1801e-02,  1.9942e-02, -1.7689e-04,  1.8383e-02,\n",
      "         2.2542e-02, -3.0696e-02,  4.0863e-02, -8.4124e-03, -1.6971e-02,\n",
      "        -1.9293e-02, -4.0733e-02, -1.2585e-02,  4.4260e-03, -3.4532e-02,\n",
      "        -2.2709e-02, -1.9757e-03, -3.9710e-02, -4.1619e-03, -1.9583e-02,\n",
      "        -2.6734e-02,  1.3454e-02,  2.0695e-02, -3.2996e-02,  4.1113e-02,\n",
      "        -1.2031e-02,  1.4819e-02, -2.2869e-02, -3.4006e-02,  7.0956e-03,\n",
      "        -2.7030e-02,  2.5584e-02, -1.1319e-02,  2.9984e-02,  3.9009e-02,\n",
      "         4.0009e-02, -3.0774e-02, -8.5410e-03, -3.4550e-02,  4.3438e-02,\n",
      "        -4.3937e-02, -1.7534e-02, -2.6995e-02, -3.0372e-02, -1.8777e-02,\n",
      "         1.5721e-02,  1.9984e-02, -2.0838e-02, -2.8838e-02,  2.9918e-02,\n",
      "         3.9560e-02, -4.4085e-02, -2.5438e-02,  3.6311e-02,  4.1341e-03,\n",
      "         1.8785e-02, -2.2160e-02,  3.5811e-02,  4.2935e-02, -5.7678e-03,\n",
      "        -4.1929e-02, -2.5396e-03, -2.2929e-02, -1.1901e-02,  3.6820e-02,\n",
      "        -1.3364e-02, -1.9507e-02, -2.0878e-02,  2.2926e-02,  1.7392e-02,\n",
      "        -1.1599e-02,  1.4311e-02,  4.3267e-02,  7.5638e-03, -2.3256e-04,\n",
      "        -2.3820e-02,  4.4616e-03, -2.1313e-02, -2.8663e-02, -1.7444e-02,\n",
      "         1.6269e-02, -2.9225e-02, -4.3028e-02,  1.1682e-02,  2.2559e-03,\n",
      "         9.7644e-03, -1.5045e-02,  1.2798e-02,  5.2653e-03, -3.9389e-02,\n",
      "         3.6215e-02,  3.2980e-02, -1.2986e-02,  1.1631e-02, -7.4032e-03,\n",
      "        -2.6025e-02,  1.0175e-02,  1.0646e-02,  8.6881e-03,  4.2961e-03,\n",
      "         4.0443e-02, -2.1306e-02, -3.1630e-02,  1.8509e-02,  3.5127e-02,\n",
      "         3.8631e-02, -4.1761e-03,  6.4023e-03, -1.0621e-02, -1.8806e-03,\n",
      "         7.8434e-03,  3.9709e-02,  1.2886e-02, -3.8713e-02,  2.3106e-02,\n",
      "         1.9612e-02,  3.3741e-03,  9.0309e-03, -4.2468e-02,  1.6257e-03,\n",
      "         3.5331e-02, -2.8716e-02, -3.4992e-02,  4.2849e-02, -2.4336e-02,\n",
      "        -2.8236e-02, -3.3622e-02,  8.4547e-05,  3.9874e-02, -2.8475e-02,\n",
      "         2.2597e-02,  4.0857e-02, -1.7990e-02, -3.6573e-02,  5.2654e-03,\n",
      "        -2.0891e-03,  2.2345e-02, -2.3797e-02, -2.6605e-03,  1.6444e-02,\n",
      "        -3.7490e-02,  8.0104e-03,  2.3051e-02, -3.0851e-02, -4.4036e-02,\n",
      "        -1.7186e-03, -3.1972e-02, -5.9873e-04, -3.2106e-03,  3.2253e-02,\n",
      "         2.5327e-02,  6.3568e-03, -2.0625e-02, -3.3964e-03,  3.8528e-02,\n",
      "        -8.4906e-03, -1.5334e-05, -1.8669e-02,  7.6524e-03,  3.9781e-02,\n",
      "         2.3787e-02, -8.9246e-03, -1.4950e-02,  3.0982e-03,  8.5296e-03,\n",
      "        -3.5486e-02,  2.1848e-02,  3.8285e-02, -3.1793e-02,  2.3359e-02,\n",
      "        -8.3988e-03, -1.2185e-02, -2.9213e-02, -1.8309e-02,  3.0882e-02,\n",
      "         4.0372e-02, -2.1294e-02,  1.1919e-02, -2.5590e-02,  3.3964e-02,\n",
      "         7.2264e-03, -1.5612e-02,  1.6981e-02,  3.4701e-02,  3.9011e-02,\n",
      "        -1.3747e-02, -7.8906e-03, -4.9682e-03,  1.4769e-02,  2.5648e-02,\n",
      "         3.2219e-02,  2.9903e-02,  4.3902e-02,  2.3625e-02,  1.4701e-02,\n",
      "         1.2273e-02,  2.6680e-02, -3.4606e-03,  1.6249e-02,  4.2534e-02,\n",
      "        -1.6547e-02, -3.4494e-02, -1.3362e-02, -2.5327e-02,  1.7818e-02,\n",
      "        -3.9594e-02, -4.2798e-02, -2.9795e-02, -2.3021e-02, -2.9920e-02,\n",
      "         2.2918e-02,  1.6579e-02, -2.7330e-02, -3.8965e-02, -6.3115e-03,\n",
      "         3.9071e-03], device='cuda:0', requires_grad=True)\n",
      "layers.9.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n",
      "layers.9.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.12.weight Parameter containing:\n",
      "tensor([[-0.0402,  0.0342, -0.0526,  ...,  0.0573,  0.0011, -0.0569],\n",
      "        [-0.0452,  0.0557, -0.0063,  ...,  0.0153, -0.0138, -0.0123],\n",
      "        [-0.0316,  0.0556, -0.0263,  ...,  0.0148, -0.0536, -0.0385],\n",
      "        ...,\n",
      "        [-0.0450, -0.0253, -0.0289,  ..., -0.0270,  0.0536,  0.0125],\n",
      "        [ 0.0370,  0.0077,  0.0189,  ..., -0.0488, -0.0336,  0.0272],\n",
      "        [-0.0353,  0.0468,  0.0297,  ..., -0.0597,  0.0338,  0.0624]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.12.bias Parameter containing:\n",
      "tensor([-0.0395, -0.0230,  0.0065, -0.0095, -0.0487,  0.0037, -0.0103, -0.0029,\n",
      "        -0.0070,  0.0377,  0.0570, -0.0124,  0.0190,  0.0347,  0.0041,  0.0440,\n",
      "         0.0010, -0.0298, -0.0400, -0.0339,  0.0277, -0.0360, -0.0573, -0.0389,\n",
      "         0.0368, -0.0425, -0.0101,  0.0122,  0.0441,  0.0475, -0.0015, -0.0036,\n",
      "        -0.0551, -0.0392,  0.0389,  0.0179,  0.0166, -0.0237, -0.0528,  0.0239,\n",
      "         0.0075, -0.0470,  0.0612,  0.0619, -0.0491, -0.0034, -0.0263,  0.0152,\n",
      "         0.0367, -0.0426,  0.0356,  0.0108,  0.0091, -0.0024,  0.0375,  0.0082,\n",
      "        -0.0262, -0.0482, -0.0175,  0.0024, -0.0242,  0.0207,  0.0485, -0.0570,\n",
      "        -0.0330,  0.0605, -0.0070, -0.0437,  0.0241,  0.0149,  0.0527,  0.0196,\n",
      "        -0.0220, -0.0506,  0.0497, -0.0445,  0.0455, -0.0033, -0.0607, -0.0464,\n",
      "         0.0110, -0.0396, -0.0624, -0.0029, -0.0532,  0.0263,  0.0268, -0.0303,\n",
      "        -0.0562,  0.0329,  0.0140, -0.0191, -0.0111,  0.0091,  0.0124,  0.0432,\n",
      "        -0.0067,  0.0397, -0.0149,  0.0392, -0.0321, -0.0544,  0.0113,  0.0078,\n",
      "        -0.0230, -0.0251, -0.0303, -0.0089, -0.0387, -0.0024,  0.0028, -0.0031,\n",
      "        -0.0265, -0.0590, -0.0242, -0.0542,  0.0233, -0.0595,  0.0087,  0.0336,\n",
      "        -0.0118, -0.0018, -0.0566,  0.0526, -0.0502,  0.0545, -0.0535,  0.0271],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.13.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', requires_grad=True)\n",
      "layers.13.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "layers.16.weight Parameter containing:\n",
      "tensor([[ 0.0262, -0.0198, -0.0284,  ...,  0.0389,  0.0005,  0.0256],\n",
      "        [ 0.0602,  0.0228,  0.0322,  ...,  0.0638,  0.0467, -0.0261],\n",
      "        [ 0.0307, -0.0585,  0.0248,  ...,  0.0594, -0.0103,  0.0458],\n",
      "        ...,\n",
      "        [ 0.0465,  0.0466,  0.0665,  ..., -0.0314,  0.0687, -0.0150],\n",
      "        [-0.0592,  0.0566,  0.0494,  ...,  0.0661, -0.0244, -0.0791],\n",
      "        [ 0.0872,  0.0853,  0.0643,  ...,  0.0818,  0.0664,  0.0645]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.16.bias Parameter containing:\n",
      "tensor([-0.0150,  0.0642, -0.0557, -0.0273, -0.0501,  0.0765, -0.0528, -0.0130,\n",
      "        -0.0244, -0.0352,  0.0676, -0.0215, -0.0692, -0.0664, -0.0539,  0.0498,\n",
      "         0.0277, -0.0719,  0.0527, -0.0700, -0.0092, -0.0641,  0.0755, -0.0415,\n",
      "        -0.0365,  0.0342, -0.0697, -0.0350, -0.0632, -0.0393,  0.0440,  0.0523,\n",
      "         0.0151, -0.0320, -0.0134,  0.0426, -0.0349, -0.0158, -0.0495, -0.0580,\n",
      "        -0.0628, -0.0500,  0.0145,  0.0121,  0.0756, -0.0451, -0.0179,  0.0257,\n",
      "        -0.0837, -0.0728,  0.0170,  0.0600,  0.0051,  0.0417, -0.0577, -0.0047,\n",
      "         0.0455, -0.0318, -0.0101, -0.0669, -0.0572,  0.0815,  0.0816, -0.0080],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.19.weight Parameter containing:\n",
      "tensor([[-0.0781, -0.0652, -0.0008,  ..., -0.0260,  0.0145, -0.0721],\n",
      "        [ 0.0212,  0.1086,  0.0876,  ..., -0.1003, -0.1221, -0.0333],\n",
      "        [ 0.0150, -0.0335,  0.0731,  ...,  0.0365, -0.0027, -0.0924],\n",
      "        ...,\n",
      "        [-0.0479, -0.0920, -0.0190,  ...,  0.1022, -0.1218, -0.0713],\n",
      "        [-0.0081,  0.1129, -0.1173,  ...,  0.1143,  0.0099, -0.1032],\n",
      "        [-0.0823, -0.1015,  0.0656,  ..., -0.0226, -0.0112,  0.0715]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.19.bias Parameter containing:\n",
      "tensor([-0.0380,  0.0114,  0.0776,  0.0049,  0.0956, -0.0597,  0.0131, -0.1120,\n",
      "         0.0191, -0.1127,  0.1035, -0.0480, -0.0248,  0.0589, -0.0495, -0.1164,\n",
      "         0.0388,  0.0975,  0.0513,  0.0984,  0.1246, -0.0322,  0.1152,  0.0070,\n",
      "        -0.0081,  0.0231, -0.0233,  0.0601, -0.0612, -0.0809,  0.0929, -0.0618],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.22.weight Parameter containing:\n",
      "tensor([[-1.0505e-01,  7.0464e-02,  1.1191e-01,  1.4913e-01,  1.4929e-01,\n",
      "         -1.9807e-02, -4.7705e-02,  3.7597e-02, -1.1318e-01, -1.0267e-01,\n",
      "          1.5379e-02,  5.0202e-03, -1.0393e-01,  1.1869e-03, -7.7955e-02,\n",
      "         -6.3774e-02, -3.8782e-02, -9.0236e-02,  9.0917e-02,  1.5885e-02,\n",
      "         -6.2486e-03,  1.4550e-01, -1.9615e-02, -9.0247e-02,  1.6362e-01,\n",
      "          1.2632e-01,  5.0373e-02, -3.5736e-02,  6.6478e-02, -8.8039e-02,\n",
      "         -1.2021e-01, -3.0869e-02],\n",
      "        [ 1.5774e-01, -8.9681e-03,  9.7012e-02,  5.3702e-02,  1.5742e-01,\n",
      "          1.5129e-01, -1.5819e-01, -1.3229e-01, -1.1476e-01, -1.4905e-01,\n",
      "         -1.4471e-01,  1.3928e-01, -1.2001e-01,  1.7120e-01, -1.0916e-01,\n",
      "          4.4008e-03,  1.5377e-01, -1.2771e-01, -4.8830e-02, -1.1410e-01,\n",
      "          1.5135e-01, -4.6404e-02, -7.3341e-02, -9.1884e-02, -9.4744e-02,\n",
      "          1.5045e-01, -1.1406e-01, -1.3089e-02,  1.3152e-01, -6.8359e-02,\n",
      "          1.3766e-01,  1.4140e-01],\n",
      "        [ 1.6576e-01,  1.0981e-01, -9.3383e-02, -2.7483e-02,  1.9371e-02,\n",
      "          3.2793e-02,  1.0147e-01,  1.5898e-01,  7.0685e-02, -8.8177e-02,\n",
      "          1.5199e-01,  1.1953e-01, -1.6450e-01,  3.8594e-02, -1.5525e-01,\n",
      "          1.7112e-01,  1.2776e-02,  8.9748e-02, -1.3118e-04, -8.3687e-02,\n",
      "         -4.0524e-02, -1.1774e-01,  3.0522e-02, -2.2505e-02, -3.0670e-02,\n",
      "         -2.6911e-02, -1.2140e-01, -1.0738e-01,  1.4777e-01,  1.4907e-01,\n",
      "          2.5319e-02,  1.6333e-01],\n",
      "        [-1.7032e-01, -1.5112e-01,  6.5882e-02, -1.4958e-01,  7.9224e-02,\n",
      "         -3.4044e-02,  1.1808e-03,  1.2728e-01, -6.2950e-03,  1.0533e-01,\n",
      "          1.1805e-01, -1.3056e-01, -1.5252e-01,  3.5848e-02,  1.2706e-01,\n",
      "         -5.9186e-02,  1.5420e-01, -1.1310e-02, -9.5156e-02, -1.2604e-01,\n",
      "          6.2517e-02, -1.4999e-01,  2.7944e-02, -7.7702e-02, -4.8547e-02,\n",
      "         -1.0905e-01,  1.4641e-01, -6.4458e-02, -1.1289e-01,  1.4307e-01,\n",
      "         -1.5732e-01,  4.7500e-03],\n",
      "        [ 1.7115e-01,  6.6774e-02,  4.0907e-02,  1.0281e-02, -1.4110e-01,\n",
      "          1.7220e-01,  5.8060e-02, -6.5485e-02, -1.0340e-01, -8.0742e-02,\n",
      "          1.3534e-01, -1.5069e-01, -1.6172e-01,  4.5176e-03,  6.1648e-02,\n",
      "          4.6866e-02,  1.1026e-01,  7.6855e-02, -1.1492e-02,  6.7744e-02,\n",
      "         -1.3530e-01,  1.4007e-01,  1.0293e-01, -1.1611e-02, -9.0442e-02,\n",
      "         -1.6702e-01,  8.5583e-02,  1.1459e-01,  3.3961e-02,  7.8234e-02,\n",
      "         -1.5822e-02,  1.2899e-01],\n",
      "        [-1.6286e-03,  7.0270e-02, -9.6467e-02, -1.2859e-01,  1.0488e-01,\n",
      "         -6.6696e-02, -9.8286e-02, -5.4821e-02,  5.5601e-02,  1.5957e-01,\n",
      "          1.4654e-01,  4.1240e-02,  1.6991e-01,  1.1911e-01,  1.2312e-01,\n",
      "          1.5105e-01,  2.0223e-02, -1.3274e-01, -6.4894e-02,  5.2546e-02,\n",
      "          1.1591e-01, -6.1321e-02, -1.2535e-02, -1.4744e-01, -8.8313e-02,\n",
      "          1.3019e-01,  1.2807e-01,  3.0500e-02, -8.5916e-02, -4.3927e-03,\n",
      "         -7.4120e-02, -1.3278e-02],\n",
      "        [ 1.6127e-01,  1.3592e-01,  9.3133e-02,  1.3341e-01, -1.3126e-01,\n",
      "          1.3754e-01, -1.0252e-02,  1.5136e-01, -5.5735e-02, -7.5869e-02,\n",
      "         -8.1357e-02, -5.8436e-02, -7.4684e-02,  1.7199e-01, -3.0592e-02,\n",
      "          3.6852e-02, -1.3847e-01,  7.6754e-02, -1.2345e-01,  1.5948e-01,\n",
      "         -6.9938e-02, -1.0161e-01, -7.9425e-02,  4.7603e-02,  7.6860e-02,\n",
      "         -4.7813e-02,  4.5036e-03,  2.5927e-02, -1.1312e-01,  1.0243e-01,\n",
      "         -1.6753e-01,  5.1427e-02],\n",
      "        [ 3.8815e-02,  1.0773e-01, -1.2224e-01,  1.6564e-01, -1.4674e-01,\n",
      "          1.5624e-01, -1.5069e-01,  1.0312e-01,  7.0495e-03,  1.3174e-01,\n",
      "         -8.9622e-02,  8.9920e-03, -1.5886e-01,  3.0133e-02,  3.6729e-02,\n",
      "         -5.4990e-02,  3.0360e-02, -5.8219e-02, -1.6206e-01, -1.4307e-01,\n",
      "          1.2453e-01,  4.1283e-02,  9.0516e-02, -3.6627e-02, -2.9779e-02,\n",
      "         -1.0280e-01,  2.9810e-02, -1.2514e-01, -5.0511e-02, -6.4590e-02,\n",
      "         -4.4339e-02,  1.6965e-01],\n",
      "        [-9.4619e-02,  1.0254e-01, -1.3050e-02, -1.0779e-01,  9.1721e-03,\n",
      "          1.5669e-01,  1.2650e-01, -6.9696e-02,  1.4701e-01, -6.7536e-02,\n",
      "         -1.4260e-01,  2.2778e-04,  1.2236e-01, -1.3436e-01, -1.3963e-01,\n",
      "         -7.1815e-02, -1.1188e-01, -1.4966e-01,  1.6173e-01, -1.0913e-01,\n",
      "         -1.5507e-01,  1.2015e-01,  2.5775e-03, -2.6871e-02,  4.2021e-02,\n",
      "         -7.8296e-02, -1.2794e-01, -9.4846e-02,  9.2755e-02,  5.3255e-02,\n",
      "          1.1106e-01,  1.6497e-01],\n",
      "        [ 1.3195e-01, -5.5417e-02, -1.5022e-01, -2.6811e-03,  3.7045e-02,\n",
      "          1.1423e-01,  1.3509e-01,  6.5990e-02,  9.5027e-02,  6.5559e-02,\n",
      "         -1.1336e-01, -9.1763e-02,  1.1828e-01,  7.2280e-02,  1.1947e-01,\n",
      "          5.5212e-02,  7.7630e-02, -8.4367e-02, -1.2045e-01,  1.7008e-01,\n",
      "          1.5040e-01,  9.1846e-02, -1.5810e-01,  3.1675e-03, -9.5629e-02,\n",
      "         -1.5221e-01, -6.6998e-02,  1.6890e-01,  5.6623e-02, -7.7678e-02,\n",
      "          5.9953e-02, -6.5577e-02],\n",
      "        [-7.3243e-02, -7.9129e-02, -4.7627e-02,  8.5953e-02, -1.2333e-01,\n",
      "         -1.6005e-01, -1.5458e-01, -7.5106e-02,  9.8647e-02,  1.6997e-01,\n",
      "         -9.9673e-02,  5.7904e-02, -6.1662e-02, -1.1421e-01,  5.8878e-02,\n",
      "         -2.7201e-03,  1.2739e-01,  1.3236e-01, -5.0771e-02,  1.7562e-01,\n",
      "         -1.3416e-02, -1.6875e-01, -1.1955e-01, -8.4403e-02, -4.2469e-03,\n",
      "         -1.2199e-01, -5.6310e-02,  2.2704e-02,  1.1145e-01, -9.4233e-02,\n",
      "          7.2022e-02,  1.1785e-01],\n",
      "        [-1.1786e-01,  7.5243e-02,  7.4256e-02, -1.0956e-01,  7.0412e-02,\n",
      "         -7.9909e-02,  8.2097e-02,  1.0019e-01,  1.7377e-01, -1.0545e-01,\n",
      "         -1.2815e-01,  7.8198e-02,  1.4489e-01,  8.6504e-03,  1.2595e-02,\n",
      "         -1.3932e-01, -3.4182e-02,  3.0996e-02,  1.7606e-01, -8.3284e-02,\n",
      "         -1.4112e-02, -2.7448e-02,  1.1127e-01,  9.0099e-02, -9.4699e-02,\n",
      "          5.5302e-02, -4.9572e-02, -1.0286e-01, -3.9172e-02, -1.6417e-01,\n",
      "          1.7281e-01,  1.4503e-01],\n",
      "        [ 3.6033e-02,  1.4952e-01, -3.5969e-02, -1.1287e-01,  9.9362e-02,\n",
      "         -6.7499e-02,  3.4678e-02, -6.3362e-02, -5.9485e-02, -1.3830e-01,\n",
      "          2.0264e-02,  3.1800e-02,  5.9287e-02,  4.8787e-02,  1.6994e-02,\n",
      "          1.1566e-01,  5.5261e-02,  8.7872e-02, -5.1275e-02,  1.5663e-01,\n",
      "          3.7802e-02, -3.3253e-02, -7.1930e-02,  3.5442e-02,  1.2998e-01,\n",
      "         -9.0104e-02,  7.6205e-02,  6.2477e-02,  5.1014e-02,  1.2980e-01,\n",
      "          5.1769e-02,  3.0414e-02],\n",
      "        [-8.0015e-03, -1.3626e-01,  3.0391e-02, -1.7293e-01, -4.8023e-02,\n",
      "         -2.0009e-02, -7.8092e-02,  3.4175e-02, -1.6907e-01, -1.3228e-01,\n",
      "         -5.6830e-02,  1.7529e-01,  3.9253e-02, -4.0202e-02, -1.4951e-01,\n",
      "         -6.8065e-02, -1.5331e-01, -9.6641e-02, -8.0883e-03,  6.8232e-03,\n",
      "          1.4404e-01, -3.2297e-02, -6.7121e-03,  6.1712e-02, -1.5464e-01,\n",
      "          6.8651e-02,  4.7966e-02,  1.5640e-01, -6.7317e-02, -1.0621e-01,\n",
      "         -7.7267e-02,  1.2184e-01],\n",
      "        [-6.5435e-02, -1.6463e-01, -1.4727e-01, -1.1809e-01, -1.1466e-01,\n",
      "         -9.6875e-05,  2.5401e-02, -1.2767e-01, -1.3716e-01,  6.6957e-02,\n",
      "          6.0005e-02, -1.7472e-01,  1.0719e-01,  1.1703e-01, -9.7504e-02,\n",
      "         -4.8840e-02,  1.4464e-01, -5.8682e-02,  6.2775e-02,  2.1427e-02,\n",
      "          1.2982e-01, -2.4608e-03,  1.1708e-01, -2.9725e-02,  6.8132e-02,\n",
      "          5.4331e-02, -6.3419e-02,  7.4148e-02,  8.1995e-02,  3.5324e-02,\n",
      "          3.4400e-02, -9.4073e-02],\n",
      "        [-1.5151e-01,  9.5976e-02,  1.3480e-01,  1.7420e-01, -4.0332e-02,\n",
      "         -1.7168e-01,  1.6915e-01,  1.4156e-01,  1.3962e-01, -1.0217e-01,\n",
      "         -1.5285e-01, -1.0420e-01,  8.2676e-03,  4.9197e-02, -3.2407e-02,\n",
      "          1.5594e-01,  1.2600e-01,  8.8343e-02,  4.5856e-02, -8.8322e-02,\n",
      "         -1.1097e-01,  1.1530e-01,  3.5619e-02,  4.2783e-02,  1.3783e-01,\n",
      "         -1.7378e-01, -2.2575e-02, -3.9927e-02, -3.2408e-02, -7.5776e-02,\n",
      "         -1.5625e-01,  6.4264e-02]], device='cuda:0', requires_grad=True)\n",
      "layers.22.bias Parameter containing:\n",
      "tensor([-0.1366,  0.1086,  0.1586,  0.0062, -0.0195,  0.0018,  0.1588,  0.0591,\n",
      "         0.0674, -0.0914, -0.1437, -0.1640, -0.0224, -0.0450, -0.0144, -0.0650],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.25.weight Parameter containing:\n",
      "tensor([[ 0.0048, -0.1709,  0.0872,  0.0170, -0.1474, -0.1556,  0.1964,  0.1094,\n",
      "          0.0395, -0.0556,  0.0920,  0.1701,  0.1336, -0.0229,  0.1613,  0.2434],\n",
      "        [-0.0768, -0.0966,  0.0792, -0.1325, -0.0654,  0.0439, -0.0476, -0.0562,\n",
      "          0.1767,  0.0705,  0.0232, -0.2113, -0.1061, -0.0985, -0.1139,  0.2139],\n",
      "        [ 0.1227,  0.0167, -0.0262, -0.0433, -0.2391, -0.2333,  0.1139, -0.0872,\n",
      "         -0.1028, -0.1027, -0.0624, -0.0036, -0.1973, -0.2171,  0.0911, -0.1357],\n",
      "        [-0.0078, -0.0673,  0.1007,  0.1145,  0.2395,  0.0970, -0.0216,  0.0897,\n",
      "          0.2457, -0.1250, -0.1085,  0.1306,  0.1219, -0.1421, -0.1897, -0.1503],\n",
      "        [-0.1076,  0.2001, -0.0411,  0.0203,  0.0837, -0.1830,  0.2118, -0.0981,\n",
      "         -0.0365,  0.0828, -0.1221,  0.1008, -0.1311,  0.1760,  0.2088,  0.1547]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "layers.25.bias Parameter containing:\n",
      "tensor([-0.0226, -0.0643,  0.1774, -0.0234, -0.0284], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "hgnn_trainer.layers\n",
    "for n,p in hgnn_trainer.named_parameters():\n",
    "    print(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 epoch, average loss: 305.98505859375\n",
      "                , loss1: -14.122993469238281\n",
      "                , loss2: 447.214990234375\n",
      "=================================\n",
      "in 10 epoch, average loss: 2635.956640625\n",
      "                , loss1: -141.0812255859375\n",
      "                , loss2: 4046.76875\n",
      "=================================\n",
      "in 20 epoch, average loss: 1864.5361328125\n",
      "                , loss1: -140.83189697265624\n",
      "                , loss2: 3272.855078125\n",
      "=================================\n",
      "in 30 epoch, average loss: 1171.2701171875\n",
      "                , loss1: -140.62142333984374\n",
      "                , loss2: 2577.483984375\n",
      "=================================\n",
      "in 40 epoch, average loss: 569.842578125\n",
      "                , loss1: -140.458642578125\n",
      "                , loss2: 1974.4291015625\n",
      "=================================\n",
      "in 50 epoch, average loss: 50.6989501953125\n",
      "                , loss1: -140.329345703125\n",
      "                , loss2: 1453.9923828125\n",
      "=================================\n",
      "in 60 epoch, average loss: -346.6156982421875\n",
      "                , loss1: -140.2354248046875\n",
      "                , loss2: 1055.73857421875\n",
      "=================================\n",
      "in 70 epoch, average loss: -672.5283203125\n",
      "                , loss1: -140.15537109375\n",
      "                , loss2: 729.025390625\n",
      "=================================\n",
      "in 80 epoch, average loss: -916.86943359375\n",
      "                , loss1: -140.114453125\n",
      "                , loss2: 484.275146484375\n",
      "=================================\n",
      "in 90 epoch, average loss: -1104.03037109375\n",
      "                , loss1: -140.09593505859374\n",
      "                , loss2: 296.92900390625\n",
      "=================================\n",
      "in 100 epoch, average loss: -1227.8775390625\n",
      "                , loss1: -140.09532470703124\n",
      "                , loss2: 173.07584228515626\n",
      "=================================\n",
      "in 110 epoch, average loss: -1310.17021484375\n",
      "                , loss1: -140.10562744140626\n",
      "                , loss2: 90.88587646484375\n",
      "=================================\n",
      "in 120 epoch, average loss: -1358.425\n",
      "                , loss1: -140.117822265625\n",
      "                , loss2: 42.753396606445314\n",
      "=================================\n",
      "in 130 epoch, average loss: -1383.2544921875\n",
      "                , loss1: -140.1474853515625\n",
      "                , loss2: 18.220401000976562\n",
      "=================================\n",
      "in 140 epoch, average loss: -1395.66748046875\n",
      "                , loss1: -140.1597900390625\n",
      "                , loss2: 5.930357360839844\n",
      "=================================\n",
      "in 150 epoch, average loss: -1399.62373046875\n",
      "                , loss1: -140.15562744140624\n",
      "                , loss2: 1.932480812072754\n",
      "=================================\n",
      "in 160 epoch, average loss: -1401.56455078125\n",
      "                , loss1: -140.1920166015625\n",
      "                , loss2: 0.3555110216140747\n",
      "=================================\n",
      "in 170 epoch, average loss: -1401.74609375\n",
      "                , loss1: -140.20556640625\n",
      "                , loss2: 0.30981504917144775\n",
      "=================================\n",
      "in 180 epoch, average loss: -1402.14375\n",
      "                , loss1: -140.23363037109374\n",
      "                , loss2: 0.19255590438842773\n",
      "=================================\n",
      "in 190 epoch, average loss: -1402.29013671875\n",
      "                , loss1: -140.2551025390625\n",
      "                , loss2: 0.2608360528945923\n",
      "=================================\n",
      "in 200 epoch, average loss: -1402.48974609375\n",
      "                , loss1: -140.284228515625\n",
      "                , loss2: 0.3527300596237183\n",
      "=================================\n",
      "in 210 epoch, average loss: -1402.75263671875\n",
      "                , loss1: -140.2990966796875\n",
      "                , loss2: 0.23832056522369385\n",
      "=================================\n",
      "in 220 epoch, average loss: -1403.01376953125\n",
      "                , loss1: -140.32576904296874\n",
      "                , loss2: 0.2439725399017334\n",
      "=================================\n",
      "in 230 epoch, average loss: -1403.43544921875\n",
      "                , loss1: -140.37314453125\n",
      "                , loss2: 0.29596376419067383\n",
      "=================================\n",
      "in 240 epoch, average loss: -1403.74833984375\n",
      "                , loss1: -140.414599609375\n",
      "                , loss2: 0.3977251768112183\n",
      "=================================\n",
      "in 250 epoch, average loss: -1404.7001953125\n",
      "                , loss1: -140.49373779296874\n",
      "                , loss2: 0.23720898628234863\n",
      "=================================\n",
      "in 260 epoch, average loss: -1405.83623046875\n",
      "                , loss1: -140.61634521484376\n",
      "                , loss2: 0.3272878646850586\n",
      "=================================\n",
      "in 270 epoch, average loss: -1407.53447265625\n",
      "                , loss1: -140.795947265625\n",
      "                , loss2: 0.42506823539733884\n",
      "=================================\n",
      "in 280 epoch, average loss: -1410.22802734375\n",
      "                , loss1: -141.07430419921874\n",
      "                , loss2: 0.5149943828582764\n",
      "=================================\n",
      "in 290 epoch, average loss: -1412.18525390625\n",
      "                , loss1: -141.2592529296875\n",
      "                , loss2: 0.4073601722717285\n",
      "=================================\n",
      "in 300 epoch, average loss: -1412.67421875\n",
      "                , loss1: -141.33572998046876\n",
      "                , loss2: 0.6830060958862305\n",
      "=================================\n",
      "in 310 epoch, average loss: -1414.056640625\n",
      "                , loss1: -141.4307861328125\n",
      "                , loss2: 0.2510091781616211\n",
      "=================================\n",
      "in 320 epoch, average loss: -1414.98349609375\n",
      "                , loss1: -141.5427978515625\n",
      "                , loss2: 0.44461879730224607\n",
      "=================================\n",
      "in 330 epoch, average loss: -1416.06318359375\n",
      "                , loss1: -141.64747314453126\n",
      "                , loss2: 0.41149511337280276\n",
      "=================================\n",
      "in 340 epoch, average loss: -1417.62236328125\n",
      "                , loss1: -141.81680908203126\n",
      "                , loss2: 0.5457083225250244\n",
      "=================================\n",
      "in 350 epoch, average loss: -1419.7470703125\n",
      "                , loss1: -142.01627197265626\n",
      "                , loss2: 0.4156669616699219\n",
      "=================================\n",
      "in 360 epoch, average loss: -1422.9126953125\n",
      "                , loss1: -142.3430908203125\n",
      "                , loss2: 0.5181379795074463\n",
      "=================================\n",
      "in 370 epoch, average loss: -1424.7701171875\n",
      "                , loss1: -142.5352783203125\n",
      "                , loss2: 0.5826035499572754\n",
      "=================================\n",
      "in 380 epoch, average loss: -1428.015234375\n",
      "                , loss1: -142.86689453125\n",
      "                , loss2: 0.6537633895874023\n",
      "=================================\n",
      "in 390 epoch, average loss: -1430.6080078125\n",
      "                , loss1: -143.1142822265625\n",
      "                , loss2: 0.5348741054534912\n",
      "=================================\n",
      "in 400 epoch, average loss: -1433.13154296875\n",
      "                , loss1: -143.37620849609374\n",
      "                , loss2: 0.6306778907775878\n",
      "=================================\n",
      "in 410 epoch, average loss: -1435.9330078125\n",
      "                , loss1: -143.6367919921875\n",
      "                , loss2: 0.4348434925079346\n",
      "=================================\n",
      "in 420 epoch, average loss: -1438.7322265625\n",
      "                , loss1: -143.8960693359375\n",
      "                , loss2: 0.22853333950042726\n",
      "=================================\n",
      "in 430 epoch, average loss: -1441.1064453125\n",
      "                , loss1: -144.13665771484375\n",
      "                , loss2: 0.26031415462493895\n",
      "=================================\n",
      "in 440 epoch, average loss: -1443.8193359375\n",
      "                , loss1: -144.4206787109375\n",
      "                , loss2: 0.3874751806259155\n",
      "=================================\n",
      "in 450 epoch, average loss: -1446.29853515625\n",
      "                , loss1: -144.6856201171875\n",
      "                , loss2: 0.557777214050293\n",
      "=================================\n",
      "in 460 epoch, average loss: -1449.0181640625\n",
      "                , loss1: -144.96331787109375\n",
      "                , loss2: 0.6150454044342041\n",
      "=================================\n",
      "in 470 epoch, average loss: -1450.930859375\n",
      "                , loss1: -145.14459228515625\n",
      "                , loss2: 0.5150290966033936\n",
      "=================================\n",
      "in 480 epoch, average loss: -1453.783203125\n",
      "                , loss1: -145.4376953125\n",
      "                , loss2: 0.5937527179718017\n",
      "=================================\n",
      "in 490 epoch, average loss: -1456.07705078125\n",
      "                , loss1: -145.65172119140624\n",
      "                , loss2: 0.4401486873626709\n",
      "=================================\n",
      "in 500 epoch, average loss: -1457.39912109375\n",
      "                , loss1: -145.79525146484374\n",
      "                , loss2: 0.5533142566680909\n",
      "=================================\n",
      "in 510 epoch, average loss: -1460.354296875\n",
      "                , loss1: -146.088916015625\n",
      "                , loss2: 0.5350675106048584\n",
      "=================================\n",
      "in 520 epoch, average loss: -1463.155859375\n",
      "                , loss1: -146.36201171875\n",
      "                , loss2: 0.4642949104309082\n",
      "=================================\n",
      "in 530 epoch, average loss: -1464.58388671875\n",
      "                , loss1: -146.49892578125\n",
      "                , loss2: 0.4055351257324219\n",
      "=================================\n",
      "in 540 epoch, average loss: -1466.694921875\n",
      "                , loss1: -146.7575439453125\n",
      "                , loss2: 0.8805133819580078\n",
      "=================================\n",
      "in 550 epoch, average loss: -1468.13896484375\n",
      "                , loss1: -146.9267822265625\n",
      "                , loss2: 1.1289754867553712\n",
      "=================================\n",
      "in 560 epoch, average loss: -1471.591015625\n",
      "                , loss1: -147.22073974609376\n",
      "                , loss2: 0.6164646625518799\n",
      "=================================\n",
      "in 570 epoch, average loss: -1474.694140625\n",
      "                , loss1: -147.51800537109375\n",
      "                , loss2: 0.48577113151550294\n",
      "=================================\n",
      "in 580 epoch, average loss: -1477.80205078125\n",
      "                , loss1: -147.8147705078125\n",
      "                , loss2: 0.3454880714416504\n",
      "=================================\n",
      "in 590 epoch, average loss: -1480.95546875\n",
      "                , loss1: -148.17252197265626\n",
      "                , loss2: 0.7699415683746338\n",
      "=================================\n",
      "in 600 epoch, average loss: -1483.7849609375\n",
      "                , loss1: -148.43502197265624\n",
      "                , loss2: 0.5653155326843262\n",
      "=================================\n",
      "in 610 epoch, average loss: -1486.78701171875\n",
      "                , loss1: -148.75078125\n",
      "                , loss2: 0.7209012031555175\n",
      "=================================\n",
      "in 620 epoch, average loss: -1489.53017578125\n",
      "                , loss1: -149.09935302734374\n",
      "                , loss2: 1.4634787559509277\n",
      "=================================\n",
      "in 630 epoch, average loss: -1493.9984375\n",
      "                , loss1: -149.53302001953125\n",
      "                , loss2: 1.3317904472351074\n",
      "=================================\n",
      "in 640 epoch, average loss: -1497.3041015625\n",
      "                , loss1: -149.85218505859376\n",
      "                , loss2: 1.218040370941162\n",
      "=================================\n",
      "in 650 epoch, average loss: -1502.89580078125\n",
      "                , loss1: -150.40477294921874\n",
      "                , loss2: 1.1518793106079102\n",
      "=================================\n",
      "in 660 epoch, average loss: -1508.399609375\n",
      "                , loss1: -150.97099609375\n",
      "                , loss2: 1.3105245590209962\n",
      "=================================\n",
      "in 670 epoch, average loss: -1512.94111328125\n",
      "                , loss1: -151.542041015625\n",
      "                , loss2: 2.4793529510498047\n",
      "=================================\n",
      "in 680 epoch, average loss: -1518.1474609375\n",
      "                , loss1: -152.0941650390625\n",
      "                , loss2: 2.7940700531005858\n",
      "=================================\n",
      "in 690 epoch, average loss: -1528.29921875\n",
      "                , loss1: -153.02244873046874\n",
      "                , loss2: 1.925440216064453\n",
      "=================================\n",
      "in 700 epoch, average loss: -1538.71337890625\n",
      "                , loss1: -154.0098388671875\n",
      "                , loss2: 1.3850478172302245\n",
      "=================================\n",
      "in 710 epoch, average loss: -1542.273828125\n",
      "                , loss1: -154.6845458984375\n",
      "                , loss2: 4.571468734741211\n",
      "=================================\n",
      "in 720 epoch, average loss: -1549.8193359375\n",
      "                , loss1: -155.66578369140626\n",
      "                , loss2: 6.838446807861328\n",
      "=================================\n",
      "in 730 epoch, average loss: -1569.4873046875\n",
      "                , loss1: -157.49140625\n",
      "                , loss2: 5.426708984375\n",
      "=================================\n",
      "in 740 epoch, average loss: -1594.31806640625\n",
      "                , loss1: -159.84176025390624\n",
      "                , loss2: 4.09957275390625\n",
      "=================================\n",
      "in 750 epoch, average loss: -1605.0615234375\n",
      "                , loss1: -161.6061279296875\n",
      "                , loss2: 10.999878692626954\n",
      "=================================\n",
      "in 760 epoch, average loss: -1603.4541015625\n",
      "                , loss1: -162.92958984375\n",
      "                , loss2: 25.84168395996094\n",
      "=================================\n",
      "in 770 epoch, average loss: -1661.876953125\n",
      "                , loss1: -166.96136474609375\n",
      "                , loss2: 7.736763763427734\n",
      "=================================\n",
      "in 780 epoch, average loss: -1726.894140625\n",
      "                , loss1: -174.41904296875\n",
      "                , loss2: 17.296157836914062\n",
      "=================================\n",
      "in 790 epoch, average loss: -1774.07734375\n",
      "                , loss1: -178.8468017578125\n",
      "                , loss2: 14.390702819824218\n",
      "=================================\n",
      "in 800 epoch, average loss: -1871.5724609375\n",
      "                , loss1: -189.2810791015625\n",
      "                , loss2: 21.238275146484376\n",
      "=================================\n",
      "in 810 epoch, average loss: -1943.984765625\n",
      "                , loss1: -197.41805419921874\n",
      "                , loss2: 30.19586181640625\n",
      "=================================\n",
      "in 820 epoch, average loss: -1978.6662109375\n",
      "                , loss1: -202.7142822265625\n",
      "                , loss2: 48.47642211914062\n",
      "=================================\n",
      "in 830 epoch, average loss: -2161.4640625\n",
      "                , loss1: -220.197412109375\n",
      "                , loss2: 40.509970092773436\n",
      "=================================\n",
      "in 840 epoch, average loss: -2285.2916015625\n",
      "                , loss1: -233.78720703125\n",
      "                , loss2: 52.580377197265626\n",
      "=================================\n",
      "in 850 epoch, average loss: -2268.2365234375\n",
      "                , loss1: -232.0863037109375\n",
      "                , loss2: 52.626519775390626\n",
      "=================================\n",
      "in 860 epoch, average loss: -2554.5625\n",
      "                , loss1: -260.7449462890625\n",
      "                , loss2: 52.88671875\n",
      "=================================\n",
      "in 870 epoch, average loss: -2660.2736328125\n",
      "                , loss1: -280.441748046875\n",
      "                , loss2: 144.14365234375\n",
      "=================================\n",
      "in 880 epoch, average loss: -2136.410546875\n",
      "                , loss1: -241.8088134765625\n",
      "                , loss2: 281.677587890625\n",
      "=================================\n",
      "in 890 epoch, average loss: -2723.1328125\n",
      "                , loss1: -283.740283203125\n",
      "                , loss2: 114.27001953125\n",
      "=================================\n",
      "in 900 epoch, average loss: -2723.0107421875\n",
      "                , loss1: -287.3163818359375\n",
      "                , loss2: 150.15299072265626\n",
      "=================================\n",
      "in 910 epoch, average loss: -2884.223046875\n",
      "                , loss1: -301.857763671875\n",
      "                , loss2: 134.35469970703124\n",
      "=================================\n",
      "in 920 epoch, average loss: -3238.9416015625\n",
      "                , loss1: -343.7601806640625\n",
      "                , loss2: 198.659814453125\n",
      "=================================\n",
      "in 930 epoch, average loss: -3523.33203125\n",
      "                , loss1: -371.33095703125\n",
      "                , loss2: 189.97735595703125\n",
      "=================================\n",
      "in 940 epoch, average loss: -3780.685546875\n",
      "                , loss1: -396.0382568359375\n",
      "                , loss2: 179.69696044921875\n",
      "=================================\n",
      "in 950 epoch, average loss: -3862.1328125\n",
      "                , loss1: -409.700830078125\n",
      "                , loss2: 234.8757080078125\n",
      "=================================\n",
      "in 960 epoch, average loss: -4080.843359375\n",
      "                , loss1: -434.918359375\n",
      "                , loss2: 268.339794921875\n",
      "=================================\n",
      "in 970 epoch, average loss: -4347.9234375\n",
      "                , loss1: -457.381787109375\n",
      "                , loss2: 225.8947265625\n",
      "=================================\n",
      "in 980 epoch, average loss: -4529.451171875\n",
      "                , loss1: -476.898779296875\n",
      "                , loss2: 239.5367919921875\n",
      "=================================\n",
      "in 990 epoch, average loss: -4743.844140625\n",
      "                , loss1: -502.45732421875\n",
      "                , loss2: 280.7287109375\n",
      "=================================\n",
      "in 1000 epoch, average loss: -4960.496875\n",
      "                , loss1: -524.2359375\n",
      "                , loss2: 281.86298828125\n",
      "=================================\n",
      "in 1010 epoch, average loss: -5138.0703125\n",
      "                , loss1: -542.006201171875\n",
      "                , loss2: 281.991845703125\n",
      "=================================\n",
      "in 1020 epoch, average loss: -5315.321875\n",
      "                , loss1: -563.151953125\n",
      "                , loss2: 316.1974853515625\n",
      "=================================\n",
      "in 1030 epoch, average loss: -5468.494140625\n",
      "                , loss1: -585.03095703125\n",
      "                , loss2: 381.815087890625\n",
      "=================================\n",
      "in 1040 epoch, average loss: -5003.6515625\n",
      "                , loss1: -566.25693359375\n",
      "                , loss2: 658.918310546875\n",
      "=================================\n",
      "in 1050 epoch, average loss: -5649.746875\n",
      "                , loss1: -582.617919921875\n",
      "                , loss2: 176.43294677734374\n",
      "=================================\n",
      "in 1060 epoch, average loss: -5885.0890625\n",
      "                , loss1: -619.42568359375\n",
      "                , loss2: 309.1677734375\n",
      "=================================\n",
      "in 1070 epoch, average loss: -6072.6765625\n",
      "                , loss1: -636.9162109375\n",
      "                , loss2: 296.4855224609375\n",
      "=================================\n",
      "in 1080 epoch, average loss: -6263.37890625\n",
      "                , loss1: -661.748095703125\n",
      "                , loss2: 354.1013671875\n",
      "=================================\n",
      "in 1090 epoch, average loss: -6472.870703125\n",
      "                , loss1: -691.73994140625\n",
      "                , loss2: 444.5287109375\n",
      "=================================\n",
      "in 1100 epoch, average loss: -6457.48125\n",
      "                , loss1: -705.71044921875\n",
      "                , loss2: 599.623486328125\n",
      "=================================\n",
      "in 1110 epoch, average loss: -6753.43046875\n",
      "                , loss1: -722.277783203125\n",
      "                , loss2: 469.347314453125\n",
      "=================================\n",
      "in 1120 epoch, average loss: -7168.1140625\n",
      "                , loss1: -759.749267578125\n",
      "                , loss2: 429.37978515625\n",
      "=================================\n",
      "in 1130 epoch, average loss: -7454.928125\n",
      "                , loss1: -794.125830078125\n",
      "                , loss2: 486.329345703125\n",
      "=================================\n",
      "in 1140 epoch, average loss: -7849.178125\n",
      "                , loss1: -833.116015625\n",
      "                , loss2: 481.983447265625\n",
      "=================================\n",
      "in 1150 epoch, average loss: -8208.81875\n",
      "                , loss1: -881.49658203125\n",
      "                , loss2: 606.146875\n",
      "=================================\n",
      "in 1160 epoch, average loss: -8557.890625\n",
      "                , loss1: -923.63310546875\n",
      "                , loss2: 678.438818359375\n",
      "=================================\n",
      "in 1170 epoch, average loss: -8561.22109375\n",
      "                , loss1: -942.5625\n",
      "                , loss2: 864.40322265625\n",
      "=================================\n",
      "in 1180 epoch, average loss: -9233.1578125\n",
      "                , loss1: -982.79814453125\n",
      "                , loss2: 594.823486328125\n",
      "=================================\n",
      "in 1190 epoch, average loss: -9798.55546875\n",
      "                , loss1: -1024.44765625\n",
      "                , loss2: 445.920361328125\n",
      "=================================\n",
      "in 1200 epoch, average loss: -10160.734375\n",
      "                , loss1: -1076.94453125\n",
      "                , loss2: 608.7119140625\n",
      "=================================\n",
      "in 1210 epoch, average loss: -10622.775\n",
      "                , loss1: -1116.6880859375\n",
      "                , loss2: 544.105126953125\n",
      "=================================\n",
      "in 1220 epoch, average loss: -10770.0046875\n",
      "                , loss1: -1133.557421875\n",
      "                , loss2: 565.5671875\n",
      "=================================\n",
      "in 1230 epoch, average loss: -10988.975\n",
      "                , loss1: -1170.43828125\n",
      "                , loss2: 715.4076171875\n",
      "=================================\n",
      "in 1240 epoch, average loss: -11426.0921875\n",
      "                , loss1: -1226.65234375\n",
      "                , loss2: 840.4306640625\n",
      "=================================\n",
      "in 1250 epoch, average loss: -11866.45234375\n",
      "                , loss1: -1225.133984375\n",
      "                , loss2: 384.8860595703125\n",
      "=================================\n",
      "in 1260 epoch, average loss: -12360.478125\n",
      "                , loss1: -1287.35595703125\n",
      "                , loss2: 513.081689453125\n",
      "=================================\n",
      "in 1270 epoch, average loss: -12894.87734375\n",
      "                , loss1: -1329.24423828125\n",
      "                , loss2: 397.564794921875\n",
      "=================================\n",
      "in 1280 epoch, average loss: -13246.70625\n",
      "                , loss1: -1362.246875\n",
      "                , loss2: 375.763232421875\n",
      "=================================\n",
      "in 1290 epoch, average loss: -13641.0171875\n",
      "                , loss1: -1414.32607421875\n",
      "                , loss2: 502.241943359375\n",
      "=================================\n",
      "in 1300 epoch, average loss: -13875.4953125\n",
      "                , loss1: -1444.80244140625\n",
      "                , loss2: 572.530078125\n",
      "=================================\n",
      "in 1310 epoch, average loss: -14281.7203125\n",
      "                , loss1: -1462.5578125\n",
      "                , loss2: 343.85732421875\n",
      "=================================\n",
      "in 1320 epoch, average loss: -14649.5\n",
      "                , loss1: -1502.96953125\n",
      "                , loss2: 380.1960693359375\n",
      "=================================\n",
      "in 1330 epoch, average loss: -14926.8046875\n",
      "                , loss1: -1540.9697265625\n",
      "                , loss2: 482.89296875\n",
      "=================================\n",
      "in 1340 epoch, average loss: -15164.7359375\n",
      "                , loss1: -1553.9421875\n",
      "                , loss2: 374.684765625\n",
      "=================================\n",
      "in 1350 epoch, average loss: -15348.465625\n",
      "                , loss1: -1562.487890625\n",
      "                , loss2: 276.412109375\n",
      "=================================\n",
      "in 1360 epoch, average loss: -15413.21875\n",
      "                , loss1: -1582.99404296875\n",
      "                , loss2: 416.722265625\n",
      "=================================\n",
      "in 1370 epoch, average loss: -15686.3390625\n",
      "                , loss1: -1601.9423828125\n",
      "                , loss2: 333.086279296875\n",
      "=================================\n",
      "in 1380 epoch, average loss: -15815.15625\n",
      "                , loss1: -1612.06796875\n",
      "                , loss2: 305.5234619140625\n",
      "=================================\n",
      "in 1390 epoch, average loss: -15946.1609375\n",
      "                , loss1: -1619.8927734375\n",
      "                , loss2: 252.768994140625\n",
      "=================================\n",
      "in 1400 epoch, average loss: -16070.03125\n",
      "                , loss1: -1634.5609375\n",
      "                , loss2: 275.578173828125\n",
      "=================================\n",
      "in 1410 epoch, average loss: -16180.6546875\n",
      "                , loss1: -1637.69609375\n",
      "                , loss2: 196.3051025390625\n",
      "=================================\n",
      "in 1420 epoch, average loss: -16207.35\n",
      "                , loss1: -1641.63828125\n",
      "                , loss2: 209.0322998046875\n",
      "=================================\n",
      "in 1430 epoch, average loss: -16295.359375\n",
      "                , loss1: -1648.7583984375\n",
      "                , loss2: 192.2253173828125\n",
      "=================================\n",
      "in 1440 epoch, average loss: -16267.2421875\n",
      "                , loss1: -1653.8583984375\n",
      "                , loss2: 271.343017578125\n",
      "=================================\n",
      "in 1450 epoch, average loss: -16239.740625\n",
      "                , loss1: -1680.6658203125\n",
      "                , loss2: 566.9173828125\n",
      "=================================\n",
      "in 1460 epoch, average loss: -16167.6734375\n",
      "                , loss1: -1680.816015625\n",
      "                , loss2: 640.48681640625\n",
      "=================================\n",
      "in 1470 epoch, average loss: -16533.3546875\n",
      "                , loss1: -1701.659375\n",
      "                , loss2: 483.2373046875\n",
      "=================================\n",
      "in 1480 epoch, average loss: -16662.459375\n",
      "                , loss1: -1696.9833984375\n",
      "                , loss2: 307.373974609375\n",
      "=================================\n",
      "in 1490 epoch, average loss: -16761.6359375\n",
      "                , loss1: -1714.57578125\n",
      "                , loss2: 384.1185302734375\n",
      "=================================\n",
      "in 1500 epoch, average loss: -16749.334375\n",
      "                , loss1: -1720.921484375\n",
      "                , loss2: 459.883203125\n",
      "=================================\n",
      "in 1510 epoch, average loss: -16831.365625\n",
      "                , loss1: -1716.42109375\n",
      "                , loss2: 332.847265625\n",
      "=================================\n",
      "in 1520 epoch, average loss: -16934.234375\n",
      "                , loss1: -1725.16640625\n",
      "                , loss2: 317.430908203125\n",
      "=================================\n",
      "in 1530 epoch, average loss: -16995.2515625\n",
      "                , loss1: -1730.2255859375\n",
      "                , loss2: 307.0068603515625\n",
      "=================================\n",
      "in 1540 epoch, average loss: -17014.178125\n",
      "                , loss1: -1735.5626953125\n",
      "                , loss2: 341.4494384765625\n",
      "=================================\n",
      "in 1550 epoch, average loss: -17043.93125\n",
      "                , loss1: -1735.53203125\n",
      "                , loss2: 311.3890869140625\n",
      "=================================\n",
      "in 1560 epoch, average loss: -17073.7015625\n",
      "                , loss1: -1745.4486328125\n",
      "                , loss2: 380.78662109375\n",
      "=================================\n",
      "in 1570 epoch, average loss: -17152.8453125\n",
      "                , loss1: -1738.2333984375\n",
      "                , loss2: 229.4922607421875\n",
      "=================================\n",
      "in 1580 epoch, average loss: -17174.86875\n",
      "                , loss1: -1745.2724609375\n",
      "                , loss2: 277.853271484375\n",
      "=================================\n",
      "in 1590 epoch, average loss: -17179.93125\n",
      "                , loss1: -1742.2892578125\n",
      "                , loss2: 242.960693359375\n",
      "=================================\n",
      "in 1600 epoch, average loss: -17208.3375\n",
      "                , loss1: -1746.56875\n",
      "                , loss2: 257.35146484375\n",
      "=================================\n",
      "in 1610 epoch, average loss: -17229.528125\n",
      "                , loss1: -1746.909765625\n",
      "                , loss2: 239.569580078125\n",
      "=================================\n",
      "in 1620 epoch, average loss: -17264.3921875\n",
      "                , loss1: -1752.1453125\n",
      "                , loss2: 257.0591552734375\n",
      "=================================\n",
      "in 1630 epoch, average loss: -17284.034375\n",
      "                , loss1: -1754.5708984375\n",
      "                , loss2: 261.671728515625\n",
      "=================================\n",
      "in 1640 epoch, average loss: -17324.9875\n",
      "                , loss1: -1756.724609375\n",
      "                , loss2: 242.256396484375\n",
      "=================================\n",
      "in 1650 epoch, average loss: -17337.996875\n",
      "                , loss1: -1759.476953125\n",
      "                , loss2: 256.7716552734375\n",
      "=================================\n",
      "in 1660 epoch, average loss: -17362.4375\n",
      "                , loss1: -1760.2767578125\n",
      "                , loss2: 240.3308837890625\n",
      "=================================\n",
      "in 1670 epoch, average loss: -17380.015625\n",
      "                , loss1: -1763.564453125\n",
      "                , loss2: 255.6294677734375\n",
      "=================================\n",
      "in 1680 epoch, average loss: -17373.4046875\n",
      "                , loss1: -1762.6509765625\n",
      "                , loss2: 253.106201171875\n",
      "=================================\n",
      "in 1690 epoch, average loss: -17408.390625\n",
      "                , loss1: -1766.877734375\n",
      "                , loss2: 260.3874755859375\n",
      "=================================\n",
      "in 1700 epoch, average loss: -17432.0609375\n",
      "                , loss1: -1770.74453125\n",
      "                , loss2: 275.381396484375\n",
      "=================================\n",
      "in 1710 epoch, average loss: -17422.6765625\n",
      "                , loss1: -1770.0458984375\n",
      "                , loss2: 277.781396484375\n",
      "=================================\n",
      "in 1720 epoch, average loss: -17396.928125\n",
      "                , loss1: -1769.880859375\n",
      "                , loss2: 301.878955078125\n",
      "=================================\n",
      "in 1730 epoch, average loss: -17404.1640625\n",
      "                , loss1: -1767.504296875\n",
      "                , loss2: 270.879296875\n",
      "=================================\n",
      "in 1740 epoch, average loss: -17455.153125\n",
      "                , loss1: -1778.9806640625\n",
      "                , loss2: 334.6507080078125\n",
      "=================================\n",
      "in 1750 epoch, average loss: -17492.3609375\n",
      "                , loss1: -1777.0615234375\n",
      "                , loss2: 278.2541748046875\n",
      "=================================\n",
      "in 1760 epoch, average loss: -17514.0421875\n",
      "                , loss1: -1783.89921875\n",
      "                , loss2: 324.9505615234375\n",
      "=================================\n",
      "in 1770 epoch, average loss: -17528.103125\n",
      "                , loss1: -1782.93046875\n",
      "                , loss2: 301.2026611328125\n",
      "=================================\n",
      "in 1780 epoch, average loss: -17581.0875\n",
      "                , loss1: -1783.9330078125\n",
      "                , loss2: 258.24169921875\n",
      "=================================\n",
      "in 1790 epoch, average loss: -17541.709375\n",
      "                , loss1: -1787.4607421875\n",
      "                , loss2: 332.8962646484375\n",
      "=================================\n",
      "in 1800 epoch, average loss: -17477.446875\n",
      "                , loss1: -1783.503515625\n",
      "                , loss2: 357.5876953125\n",
      "=================================\n",
      "in 1810 epoch, average loss: -17510.6171875\n",
      "                , loss1: -1782.2841796875\n",
      "                , loss2: 312.22646484375\n",
      "=================================\n",
      "in 1820 epoch, average loss: -17567.7859375\n",
      "                , loss1: -1778.812109375\n",
      "                , loss2: 220.3347412109375\n",
      "=================================\n",
      "in 1830 epoch, average loss: -17597.93125\n",
      "                , loss1: -1785.2203125\n",
      "                , loss2: 254.2715087890625\n",
      "=================================\n",
      "in 1840 epoch, average loss: -17621.0625\n",
      "                , loss1: -1799.2564453125\n",
      "                , loss2: 371.50322265625\n",
      "=================================\n",
      "in 1850 epoch, average loss: -17665.3421875\n",
      "                , loss1: -1810.0630859375\n",
      "                , loss2: 435.289208984375\n",
      "=================================\n",
      "in 1860 epoch, average loss: -17700.4546875\n",
      "                , loss1: -1809.360546875\n",
      "                , loss2: 393.1508056640625\n",
      "=================================\n",
      "in 1870 epoch, average loss: -17721.14375\n",
      "                , loss1: -1804.787890625\n",
      "                , loss2: 326.732177734375\n",
      "=================================\n",
      "in 1880 epoch, average loss: -17743.7984375\n",
      "                , loss1: -1807.1095703125\n",
      "                , loss2: 327.294580078125\n",
      "=================================\n",
      "in 1890 epoch, average loss: -17789.8765625\n",
      "                , loss1: -1808.687890625\n",
      "                , loss2: 297.001953125\n",
      "=================================\n",
      "in 1900 epoch, average loss: -17785.9\n",
      "                , loss1: -1810.60859375\n",
      "                , loss2: 320.1847900390625\n",
      "=================================\n",
      "in 1910 epoch, average loss: -17783.86875\n",
      "                , loss1: -1816.37578125\n",
      "                , loss2: 379.8908935546875\n",
      "=================================\n",
      "in 1920 epoch, average loss: -17820.3578125\n",
      "                , loss1: -1814.937109375\n",
      "                , loss2: 329.0120361328125\n",
      "=================================\n",
      "in 1930 epoch, average loss: -17823.9421875\n",
      "                , loss1: -1815.6197265625\n",
      "                , loss2: 332.2552978515625\n",
      "=================================\n",
      "in 1940 epoch, average loss: -17867.9984375\n",
      "                , loss1: -1812.558203125\n",
      "                , loss2: 257.583984375\n",
      "=================================\n",
      "in 1950 epoch, average loss: -17838.7296875\n",
      "                , loss1: -1814.5841796875\n",
      "                , loss2: 307.1116943359375\n",
      "=================================\n",
      "in 1960 epoch, average loss: -17860.69375\n",
      "                , loss1: -1808.605078125\n",
      "                , loss2: 225.3565185546875\n",
      "=================================\n",
      "in 1970 epoch, average loss: -17867.5\n",
      "                , loss1: -1818.2048828125\n",
      "                , loss2: 314.5496826171875\n",
      "=================================\n",
      "in 1980 epoch, average loss: -17858.10625\n",
      "                , loss1: -1814.7103515625\n",
      "                , loss2: 288.997705078125\n",
      "=================================\n",
      "in 1990 epoch, average loss: -17830.5078125\n",
      "                , loss1: -1820.641015625\n",
      "                , loss2: 375.905615234375\n",
      "=================================\n",
      "in 2000 epoch, average loss: -17895.0296875\n",
      "                , loss1: -1816.0908203125\n",
      "                , loss2: 265.878515625\n",
      "=================================\n",
      "in 2010 epoch, average loss: -17854.25\n",
      "                , loss1: -1823.555078125\n",
      "                , loss2: 381.300634765625\n",
      "=================================\n",
      "in 2020 epoch, average loss: -17795.78125\n",
      "                , loss1: -1823.9802734375\n",
      "                , loss2: 444.0212890625\n",
      "=================================\n",
      "in 2030 epoch, average loss: -17935.8484375\n",
      "                , loss1: -1817.809375\n",
      "                , loss2: 242.2449951171875\n",
      "=================================\n",
      "in 2040 epoch, average loss: -17897.7109375\n",
      "                , loss1: -1817.639453125\n",
      "                , loss2: 278.6837890625\n",
      "=================================\n",
      "in 2050 epoch, average loss: -17931.0015625\n",
      "                , loss1: -1826.3111328125\n",
      "                , loss2: 332.1099365234375\n",
      "=================================\n",
      "in 2060 epoch, average loss: -17957.6796875\n",
      "                , loss1: -1824.859375\n",
      "                , loss2: 290.911865234375\n",
      "=================================\n",
      "in 2070 epoch, average loss: -17933.5890625\n",
      "                , loss1: -1828.67734375\n",
      "                , loss2: 353.1843994140625\n",
      "=================================\n",
      "in 2080 epoch, average loss: -17939.5703125\n",
      "                , loss1: -1818.5109375\n",
      "                , loss2: 245.539599609375\n",
      "=================================\n",
      "in 2090 epoch, average loss: -17954.6359375\n",
      "                , loss1: -1826.077734375\n",
      "                , loss2: 306.1402099609375\n",
      "=================================\n",
      "in 2100 epoch, average loss: -17943.709375\n",
      "                , loss1: -1825.230859375\n",
      "                , loss2: 308.5986572265625\n",
      "=================================\n",
      "in 2110 epoch, average loss: -17969.0078125\n",
      "                , loss1: -1826.72109375\n",
      "                , loss2: 298.2026123046875\n",
      "=================================\n",
      "in 2120 epoch, average loss: -18025.86875\n",
      "                , loss1: -1829.767578125\n",
      "                , loss2: 271.8074951171875\n",
      "=================================\n",
      "in 2130 epoch, average loss: -18032.00625\n",
      "                , loss1: -1830.9193359375\n",
      "                , loss2: 277.1857177734375\n",
      "=================================\n",
      "in 2140 epoch, average loss: -18042.4640625\n",
      "                , loss1: -1831.9123046875\n",
      "                , loss2: 276.657763671875\n",
      "=================================\n",
      "in 2150 epoch, average loss: -18057.23125\n",
      "                , loss1: -1835.2931640625\n",
      "                , loss2: 295.701220703125\n",
      "=================================\n",
      "in 2160 epoch, average loss: -18011.2578125\n",
      "                , loss1: -1839.948828125\n",
      "                , loss2: 388.2285400390625\n",
      "=================================\n",
      "in 2170 epoch, average loss: -18057.4578125\n",
      "                , loss1: -1826.831640625\n",
      "                , loss2: 210.8604736328125\n",
      "=================================\n",
      "in 2180 epoch, average loss: -18066.9265625\n",
      "                , loss1: -1835.0005859375\n",
      "                , loss2: 283.0780517578125\n",
      "=================================\n",
      "in 2190 epoch, average loss: -18049.440625\n",
      "                , loss1: -1833.343359375\n",
      "                , loss2: 283.9920654296875\n",
      "=================================\n",
      "in 2200 epoch, average loss: -18055.746875\n",
      "                , loss1: -1844.7521484375\n",
      "                , loss2: 391.7767822265625\n",
      "=================================\n",
      "in 2210 epoch, average loss: -18046.5390625\n",
      "                , loss1: -1837.701171875\n",
      "                , loss2: 330.472607421875\n",
      "=================================\n",
      "in 2220 epoch, average loss: -18069.546875\n",
      "                , loss1: -1848.24765625\n",
      "                , loss2: 412.93232421875\n",
      "=================================\n",
      "in 2230 epoch, average loss: -18099.6125\n",
      "                , loss1: -1842.0890625\n",
      "                , loss2: 321.2797119140625\n",
      "=================================\n",
      "in 2240 epoch, average loss: -18147.346875\n",
      "                , loss1: -1844.7103515625\n",
      "                , loss2: 299.754833984375\n",
      "=================================\n",
      "in 2250 epoch, average loss: -18198.1328125\n",
      "                , loss1: -1845.8921875\n",
      "                , loss2: 260.790234375\n",
      "=================================\n",
      "in 2260 epoch, average loss: -18196.278125\n",
      "                , loss1: -1854.715234375\n",
      "                , loss2: 350.874658203125\n",
      "=================================\n",
      "in 2270 epoch, average loss: -18171.796875\n",
      "                , loss1: -1846.36015625\n",
      "                , loss2: 291.805810546875\n",
      "=================================\n",
      "in 2280 epoch, average loss: -18198.625\n",
      "                , loss1: -1856.0158203125\n",
      "                , loss2: 361.53740234375\n",
      "=================================\n",
      "in 2290 epoch, average loss: -18212.8703125\n",
      "                , loss1: -1856.9859375\n",
      "                , loss2: 356.987939453125\n",
      "=================================\n",
      "in 2300 epoch, average loss: -18214.371875\n",
      "                , loss1: -1855.7771484375\n",
      "                , loss2: 343.39921875\n",
      "=================================\n",
      "in 2310 epoch, average loss: -18270.975\n",
      "                , loss1: -1857.36796875\n",
      "                , loss2: 302.7055419921875\n",
      "=================================\n",
      "in 2320 epoch, average loss: -18264.525\n",
      "                , loss1: -1856.501171875\n",
      "                , loss2: 300.4865966796875\n",
      "=================================\n",
      "in 2330 epoch, average loss: -18320.8890625\n",
      "                , loss1: -1859.1017578125\n",
      "                , loss2: 270.1295654296875\n",
      "=================================\n",
      "in 2340 epoch, average loss: -18338.371875\n",
      "                , loss1: -1865.768359375\n",
      "                , loss2: 319.310205078125\n",
      "=================================\n",
      "in 2350 epoch, average loss: -18328.5609375\n",
      "                , loss1: -1862.4544921875\n",
      "                , loss2: 295.98193359375\n",
      "=================================\n",
      "in 2360 epoch, average loss: -18364.6625\n",
      "                , loss1: -1865.124609375\n",
      "                , loss2: 286.58486328125\n",
      "=================================\n",
      "in 2370 epoch, average loss: -18326.24375\n",
      "                , loss1: -1868.921484375\n",
      "                , loss2: 362.970556640625\n",
      "=================================\n",
      "in 2380 epoch, average loss: -18355.63125\n",
      "                , loss1: -1868.6712890625\n",
      "                , loss2: 331.082861328125\n",
      "=================================\n",
      "in 2390 epoch, average loss: -18266.8046875\n",
      "                , loss1: -1869.449609375\n",
      "                , loss2: 427.692626953125\n",
      "=================================\n",
      "in 2400 epoch, average loss: -18429.68125\n",
      "                , loss1: -1883.4845703125\n",
      "                , loss2: 405.16337890625\n",
      "=================================\n",
      "in 2410 epoch, average loss: -18495.63125\n",
      "                , loss1: -1883.58046875\n",
      "                , loss2: 340.176611328125\n",
      "=================================\n",
      "in 2420 epoch, average loss: -18527.915625\n",
      "                , loss1: -1881.2751953125\n",
      "                , loss2: 284.8379150390625\n",
      "=================================\n",
      "in 2430 epoch, average loss: -18629.2359375\n",
      "                , loss1: -1889.6978515625\n",
      "                , loss2: 267.7428955078125\n",
      "=================================\n",
      "in 2440 epoch, average loss: -18654.2796875\n",
      "                , loss1: -1894.9701171875\n",
      "                , loss2: 295.42314453125\n",
      "=================================\n",
      "in 2450 epoch, average loss: -18701.9109375\n",
      "                , loss1: -1901.3931640625\n",
      "                , loss2: 312.01923828125\n",
      "=================================\n",
      "in 2460 epoch, average loss: -18771.5453125\n",
      "                , loss1: -1904.7515625\n",
      "                , loss2: 275.970654296875\n",
      "=================================\n",
      "in 2470 epoch, average loss: -18801.99375\n",
      "                , loss1: -1918.225\n",
      "                , loss2: 380.2543212890625\n",
      "=================================\n",
      "in 2480 epoch, average loss: -18817.4609375\n",
      "                , loss1: -1920.408203125\n",
      "                , loss2: 386.6210693359375\n",
      "=================================\n",
      "in 2490 epoch, average loss: -18958.328125\n",
      "                , loss1: -1933.4931640625\n",
      "                , loss2: 376.6023681640625\n",
      "=================================\n",
      "in 2500 epoch, average loss: -19100.9375\n",
      "                , loss1: -1943.4736328125\n",
      "                , loss2: 333.7991943359375\n",
      "=================================\n",
      "in 2510 epoch, average loss: -19245.890625\n",
      "                , loss1: -1968.9537109375\n",
      "                , loss2: 443.64443359375\n",
      "=================================\n",
      "in 2520 epoch, average loss: -19449.0015625\n",
      "                , loss1: -1978.17265625\n",
      "                , loss2: 332.7241943359375\n",
      "=================================\n",
      "in 2530 epoch, average loss: -19724.703125\n",
      "                , loss1: -2009.4328125\n",
      "                , loss2: 369.6244140625\n",
      "=================================\n",
      "in 2540 epoch, average loss: -19894.6453125\n",
      "                , loss1: -2032.053515625\n",
      "                , loss2: 425.8904296875\n",
      "=================================\n",
      "in 2550 epoch, average loss: -20153.8703125\n",
      "                , loss1: -2061.3560546875\n",
      "                , loss2: 459.688134765625\n",
      "=================================\n",
      "in 2560 epoch, average loss: -20395.409375\n",
      "                , loss1: -2098.41640625\n",
      "                , loss2: 588.75302734375\n",
      "=================================\n",
      "in 2570 epoch, average loss: -20720.2265625\n",
      "                , loss1: -2122.4423828125\n",
      "                , loss2: 504.1978515625\n",
      "=================================\n",
      "in 2580 epoch, average loss: -21198.815625\n",
      "                , loss1: -2172.9513671875\n",
      "                , loss2: 530.696044921875\n",
      "=================================\n",
      "in 2590 epoch, average loss: -21553.1015625\n",
      "                , loss1: -2209.3390625\n",
      "                , loss2: 540.288818359375\n",
      "=================================\n",
      "in 2600 epoch, average loss: -21761.9328125\n",
      "                , loss1: -2238.365625\n",
      "                , loss2: 621.723583984375\n",
      "=================================\n",
      "in 2610 epoch, average loss: -22265.334375\n",
      "                , loss1: -2276.4015625\n",
      "                , loss2: 498.6833984375\n",
      "=================================\n",
      "in 2620 epoch, average loss: -22684.46875\n",
      "                , loss1: -2325.7654296875\n",
      "                , loss2: 573.18486328125\n",
      "=================================\n",
      "in 2630 epoch, average loss: -23032.296875\n",
      "                , loss1: -2354.0453125\n",
      "                , loss2: 508.156591796875\n",
      "=================================\n",
      "in 2640 epoch, average loss: -23576.8328125\n",
      "                , loss1: -2413.4779296875\n",
      "                , loss2: 557.94853515625\n",
      "=================================\n",
      "in 2650 epoch, average loss: -23835.5484375\n",
      "                , loss1: -2430.809765625\n",
      "                , loss2: 472.5455078125\n",
      "=================================\n",
      "in 2660 epoch, average loss: -24406.35625\n",
      "                , loss1: -2495.148828125\n",
      "                , loss2: 545.13212890625\n",
      "=================================\n",
      "in 2670 epoch, average loss: -24839.228125\n",
      "                , loss1: -2530.46015625\n",
      "                , loss2: 465.37314453125\n",
      "=================================\n",
      "in 2680 epoch, average loss: -25097.696875\n",
      "                , loss1: -2555.0548828125\n",
      "                , loss2: 452.85224609375\n",
      "=================================\n",
      "in 2690 epoch, average loss: -25361.4453125\n",
      "                , loss1: -2596.4337890625\n",
      "                , loss2: 602.88994140625\n",
      "=================================\n",
      "in 2700 epoch, average loss: -25776.1109375\n",
      "                , loss1: -2621.8447265625\n",
      "                , loss2: 442.334814453125\n",
      "=================================\n",
      "in 2710 epoch, average loss: -25876.246875\n",
      "                , loss1: -2662.3693359375\n",
      "                , loss2: 747.448095703125\n",
      "=================================\n",
      "in 2720 epoch, average loss: -26408.5625\n",
      "                , loss1: -2708.316015625\n",
      "                , loss2: 674.597509765625\n",
      "=================================\n",
      "in 2730 epoch, average loss: -26578.8625\n",
      "                , loss1: -2721.11875\n",
      "                , loss2: 632.327734375\n",
      "=================================\n",
      "in 2740 epoch, average loss: -26920.2\n",
      "                , loss1: -2754.6599609375\n",
      "                , loss2: 626.3994140625\n",
      "=================================\n",
      "in 2750 epoch, average loss: -27084.45625\n",
      "                , loss1: -2759.253515625\n",
      "                , loss2: 508.078466796875\n",
      "=================================\n",
      "in 2760 epoch, average loss: -27365.428125\n",
      "                , loss1: -2782.877734375\n",
      "                , loss2: 463.350048828125\n",
      "=================================\n",
      "in 2770 epoch, average loss: -27785.74375\n",
      "                , loss1: -2824.63828125\n",
      "                , loss2: 460.636083984375\n",
      "=================================\n",
      "in 2780 epoch, average loss: -27953.4875\n",
      "                , loss1: -2838.0595703125\n",
      "                , loss2: 427.11103515625\n",
      "=================================\n",
      "in 2790 epoch, average loss: -28225.9625\n",
      "                , loss1: -2874.51015625\n",
      "                , loss2: 519.141455078125\n",
      "=================================\n",
      "in 2800 epoch, average loss: -28285.878125\n",
      "                , loss1: -2882.0263671875\n",
      "                , loss2: 534.38466796875\n",
      "=================================\n",
      "in 2810 epoch, average loss: -28161.603125\n",
      "                , loss1: -2867.13671875\n",
      "                , loss2: 509.763427734375\n",
      "=================================\n",
      "in 2820 epoch, average loss: -28523.6375\n",
      "                , loss1: -2893.2337890625\n",
      "                , loss2: 408.69912109375\n",
      "=================================\n",
      "in 2830 epoch, average loss: -28692.2625\n",
      "                , loss1: -2908.4052734375\n",
      "                , loss2: 391.78759765625\n",
      "=================================\n",
      "in 2840 epoch, average loss: -28536.13125\n",
      "                , loss1: -2908.6015625\n",
      "                , loss2: 549.880712890625\n",
      "=================================\n",
      "in 2850 epoch, average loss: -28638.2875\n",
      "                , loss1: -2914.01015625\n",
      "                , loss2: 501.815478515625\n",
      "=================================\n",
      "in 2860 epoch, average loss: -28813.953125\n",
      "                , loss1: -2929.9318359375\n",
      "                , loss2: 485.363720703125\n",
      "=================================\n",
      "in 2870 epoch, average loss: -28864.68125\n",
      "                , loss1: -2931.636328125\n",
      "                , loss2: 451.682958984375\n",
      "=================================\n",
      "in 2880 epoch, average loss: -28938.146875\n",
      "                , loss1: -2939.81328125\n",
      "                , loss2: 459.987060546875\n",
      "=================================\n",
      "in 2890 epoch, average loss: -29037.05\n",
      "                , loss1: -2947.785546875\n",
      "                , loss2: 440.806982421875\n",
      "=================================\n",
      "in 2900 epoch, average loss: -29288.571875\n",
      "                , loss1: -2967.153515625\n",
      "                , loss2: 382.9641357421875\n",
      "=================================\n",
      "in 2910 epoch, average loss: -29299.60625\n",
      "                , loss1: -2975.460546875\n",
      "                , loss2: 454.995849609375\n",
      "=================================\n",
      "in 2920 epoch, average loss: -29389.825\n",
      "                , loss1: -2977.255859375\n",
      "                , loss2: 382.73525390625\n",
      "=================================\n",
      "in 2930 epoch, average loss: -29372.875\n",
      "                , loss1: -2978.1361328125\n",
      "                , loss2: 408.48505859375\n",
      "=================================\n",
      "in 2940 epoch, average loss: -29390.48125\n",
      "                , loss1: -2981.0919921875\n",
      "                , loss2: 420.435498046875\n",
      "=================================\n",
      "in 2950 epoch, average loss: -29376.31875\n",
      "                , loss1: -2982.23671875\n",
      "                , loss2: 446.0513671875\n",
      "=================================\n",
      "in 2960 epoch, average loss: -29418.359375\n",
      "                , loss1: -2981.20625\n",
      "                , loss2: 393.703369140625\n",
      "=================================\n",
      "in 2970 epoch, average loss: -29573.790625\n",
      "                , loss1: -3002.939453125\n",
      "                , loss2: 455.60166015625\n",
      "=================================\n",
      "in 2980 epoch, average loss: -29495.00625\n",
      "                , loss1: -2989.1724609375\n",
      "                , loss2: 396.720849609375\n",
      "=================================\n",
      "in 2990 epoch, average loss: -29521.184375\n",
      "                , loss1: -2999.650390625\n",
      "                , loss2: 475.322021484375\n",
      "=================================\n",
      "in 3000 epoch, average loss: -29700.54375\n",
      "                , loss1: -3016.815625\n",
      "                , loss2: 467.61416015625\n",
      "=================================\n",
      "in 3010 epoch, average loss: -29626.175\n",
      "                , loss1: -3005.1857421875\n",
      "                , loss2: 425.68095703125\n",
      "=================================\n",
      "in 3020 epoch, average loss: -29747.171875\n",
      "                , loss1: -3017.4771484375\n",
      "                , loss2: 427.599951171875\n",
      "=================================\n",
      "in 3030 epoch, average loss: -29853.265625\n",
      "                , loss1: -3025.19375\n",
      "                , loss2: 398.668359375\n",
      "=================================\n",
      "in 3040 epoch, average loss: -29930.128125\n",
      "                , loss1: -3033.8146484375\n",
      "                , loss2: 408.0185546875\n",
      "=================================\n",
      "in 3050 epoch, average loss: -29779.459375\n",
      "                , loss1: -3017.926171875\n",
      "                , loss2: 399.8027587890625\n",
      "=================================\n",
      "in 3060 epoch, average loss: -29922.95\n",
      "                , loss1: -3034.6421875\n",
      "                , loss2: 423.47392578125\n",
      "=================================\n",
      "in 3070 epoch, average loss: -29854.771875\n",
      "                , loss1: -3033.55546875\n",
      "                , loss2: 480.7830078125\n",
      "=================================\n",
      "in 3080 epoch, average loss: -29996.215625\n",
      "                , loss1: -3046.8044921875\n",
      "                , loss2: 471.82822265625\n",
      "=================================\n",
      "in 3090 epoch, average loss: -29962.234375\n",
      "                , loss1: -3033.9521484375\n",
      "                , loss2: 377.28759765625\n",
      "=================================\n",
      "in 3100 epoch, average loss: -29909.465625\n",
      "                , loss1: -3034.1060546875\n",
      "                , loss2: 431.5962890625\n",
      "=================================\n",
      "in 3110 epoch, average loss: -29876.8\n",
      "                , loss1: -3029.39296875\n",
      "                , loss2: 417.132958984375\n",
      "=================================\n",
      "in 3120 epoch, average loss: -29975.3\n",
      "                , loss1: -3042.3447265625\n",
      "                , loss2: 448.14658203125\n",
      "=================================\n",
      "in 3130 epoch, average loss: -29945.771875\n",
      "                , loss1: -3045.5166015625\n",
      "                , loss2: 509.39599609375\n",
      "=================================\n",
      "in 3140 epoch, average loss: -29957.8\n",
      "                , loss1: -3031.7998046875\n",
      "                , loss2: 360.197314453125\n",
      "=================================\n",
      "in 3150 epoch, average loss: -30074.990625\n",
      "                , loss1: -3053.046484375\n",
      "                , loss2: 455.47548828125\n",
      "=================================\n",
      "in 3160 epoch, average loss: -30090.9\n",
      "                , loss1: -3050.82890625\n",
      "                , loss2: 417.38955078125\n",
      "=================================\n",
      "in 3170 epoch, average loss: -30105.653125\n",
      "                , loss1: -3052.8435546875\n",
      "                , loss2: 422.77607421875\n",
      "=================================\n",
      "in 3180 epoch, average loss: -30121.621875\n",
      "                , loss1: -3055.3599609375\n",
      "                , loss2: 431.9794921875\n",
      "=================================\n",
      "in 3190 epoch, average loss: -30128.58125\n",
      "                , loss1: -3052.26328125\n",
      "                , loss2: 394.0495361328125\n",
      "=================================\n",
      "in 3200 epoch, average loss: -30273.584375\n",
      "                , loss1: -3059.909765625\n",
      "                , loss2: 325.5127197265625\n",
      "=================================\n",
      "in 3210 epoch, average loss: -29989.19375\n",
      "                , loss1: -3041.48203125\n",
      "                , loss2: 425.629443359375\n",
      "=================================\n",
      "in 3220 epoch, average loss: -30058.940625\n",
      "                , loss1: -3039.890234375\n",
      "                , loss2: 339.966064453125\n",
      "=================================\n",
      "in 3230 epoch, average loss: -30242.74375\n",
      "                , loss1: -3070.9798828125\n",
      "                , loss2: 467.0544921875\n",
      "=================================\n",
      "in 3240 epoch, average loss: -30280.578125\n",
      "                , loss1: -3065.863671875\n",
      "                , loss2: 378.059765625\n",
      "=================================\n",
      "in 3250 epoch, average loss: -30342.375\n",
      "                , loss1: -3069.7181640625\n",
      "                , loss2: 354.804833984375\n",
      "=================================\n",
      "in 3260 epoch, average loss: -30379.728125\n",
      "                , loss1: -3077.376953125\n",
      "                , loss2: 394.042333984375\n",
      "=================================\n",
      "in 3270 epoch, average loss: -30257.525\n",
      "                , loss1: -3078.775390625\n",
      "                , loss2: 530.2296875\n",
      "=================================\n",
      "in 3280 epoch, average loss: -30394.8875\n",
      "                , loss1: -3080.8462890625\n",
      "                , loss2: 413.574951171875\n",
      "=================================\n",
      "in 3290 epoch, average loss: -30379.0625\n",
      "                , loss1: -3084.637109375\n",
      "                , loss2: 467.308984375\n",
      "=================================\n",
      "in 3300 epoch, average loss: -30410.878125\n",
      "                , loss1: -3082.45859375\n",
      "                , loss2: 413.707373046875\n",
      "=================================\n",
      "in 3310 epoch, average loss: -30395.73125\n",
      "                , loss1: -3078.03828125\n",
      "                , loss2: 384.6490478515625\n",
      "=================================\n",
      "in 3320 epoch, average loss: -30392.659375\n",
      "                , loss1: -3077.228515625\n",
      "                , loss2: 379.6269775390625\n",
      "=================================\n",
      "in 3330 epoch, average loss: -30401.7\n",
      "                , loss1: -3084.5890625\n",
      "                , loss2: 444.190087890625\n",
      "=================================\n",
      "in 3340 epoch, average loss: -30489.69375\n",
      "                , loss1: -3082.72109375\n",
      "                , loss2: 337.51865234375\n",
      "=================================\n",
      "in 3350 epoch, average loss: -30530.978125\n",
      "                , loss1: -3090.862109375\n",
      "                , loss2: 377.6444580078125\n",
      "=================================\n",
      "in 3360 epoch, average loss: -30607.503125\n",
      "                , loss1: -3092.036328125\n",
      "                , loss2: 312.863037109375\n",
      "=================================\n",
      "in 3370 epoch, average loss: -30542.421875\n",
      "                , loss1: -3090.2701171875\n",
      "                , loss2: 360.2799560546875\n",
      "=================================\n",
      "in 3380 epoch, average loss: -30554.18125\n",
      "                , loss1: -3101.3791015625\n",
      "                , loss2: 459.611376953125\n",
      "=================================\n",
      "in 3390 epoch, average loss: -30527.375\n",
      "                , loss1: -3082.5779296875\n",
      "                , loss2: 298.4063720703125\n",
      "=================================\n",
      "in 3400 epoch, average loss: -30433.01875\n",
      "                , loss1: -3083.2771484375\n",
      "                , loss2: 399.753466796875\n",
      "=================================\n",
      "in 3410 epoch, average loss: -30391.728125\n",
      "                , loss1: -3085.2173828125\n",
      "                , loss2: 460.447802734375\n",
      "=================================\n",
      "in 3420 epoch, average loss: -30526.80625\n",
      "                , loss1: -3092.698828125\n",
      "                , loss2: 400.178076171875\n",
      "=================================\n",
      "in 3430 epoch, average loss: -30563.39375\n",
      "                , loss1: -3090.45234375\n",
      "                , loss2: 341.1334716796875\n",
      "=================================\n",
      "in 3440 epoch, average loss: -30625.2625\n",
      "                , loss1: -3094.8931640625\n",
      "                , loss2: 323.6730712890625\n",
      "=================================\n",
      "in 3450 epoch, average loss: -30628.28125\n",
      "                , loss1: -3099.6921875\n",
      "                , loss2: 368.64248046875\n",
      "=================================\n",
      "in 3460 epoch, average loss: -30553.765625\n",
      "                , loss1: -3097.56953125\n",
      "                , loss2: 421.927490234375\n",
      "=================================\n",
      "in 3470 epoch, average loss: -30515.00625\n",
      "                , loss1: -3098.9078125\n",
      "                , loss2: 474.072265625\n",
      "=================================\n",
      "in 3480 epoch, average loss: -30612.65625\n",
      "                , loss1: -3101.65859375\n",
      "                , loss2: 403.9316162109375\n",
      "=================================\n",
      "in 3490 epoch, average loss: -30645.03125\n",
      "                , loss1: -3104.519140625\n",
      "                , loss2: 400.1583984375\n",
      "=================================\n",
      "in 3500 epoch, average loss: -30655.25\n",
      "                , loss1: -3105.3703125\n",
      "                , loss2: 398.4529052734375\n",
      "=================================\n",
      "in 3510 epoch, average loss: -30621.15625\n",
      "                , loss1: -3108.867578125\n",
      "                , loss2: 467.5185546875\n",
      "=================================\n",
      "in 3520 epoch, average loss: -30663.475\n",
      "                , loss1: -3110.014453125\n",
      "                , loss2: 436.670703125\n",
      "=================================\n",
      "in 3530 epoch, average loss: -30626.80625\n",
      "                , loss1: -3114.465625\n",
      "                , loss2: 517.848876953125\n",
      "=================================\n",
      "in 3540 epoch, average loss: -30690.26875\n",
      "                , loss1: -3105.756640625\n",
      "                , loss2: 367.3018310546875\n",
      "=================================\n",
      "in 3550 epoch, average loss: -30671.853125\n",
      "                , loss1: -3118.074609375\n",
      "                , loss2: 508.894140625\n",
      "=================================\n",
      "in 3560 epoch, average loss: -30780.6875\n",
      "                , loss1: -3117.371484375\n",
      "                , loss2: 393.026953125\n",
      "=================================\n",
      "in 3570 epoch, average loss: -30763.31875\n",
      "                , loss1: -3113.8166015625\n",
      "                , loss2: 374.8467529296875\n",
      "=================================\n",
      "in 3580 epoch, average loss: -30744.36875\n",
      "                , loss1: -3116.1326171875\n",
      "                , loss2: 416.95458984375\n",
      "=================================\n",
      "in 3590 epoch, average loss: -30622.06875\n",
      "                , loss1: -3113.5529296875\n",
      "                , loss2: 513.4595703125\n",
      "=================================\n",
      "in 3600 epoch, average loss: -30721.90625\n",
      "                , loss1: -3133.9119140625\n",
      "                , loss2: 617.213623046875\n",
      "=================================\n",
      "in 3610 epoch, average loss: -30649.115625\n",
      "                , loss1: -3113.769921875\n",
      "                , loss2: 488.581591796875\n",
      "=================================\n",
      "in 3620 epoch, average loss: -30857.21875\n",
      "                , loss1: -3123.0271484375\n",
      "                , loss2: 373.0532958984375\n",
      "=================================\n",
      "in 3630 epoch, average loss: -30942.7375\n",
      "                , loss1: -3130.810546875\n",
      "                , loss2: 365.368310546875\n",
      "=================================\n",
      "in 3640 epoch, average loss: -30806.39375\n",
      "                , loss1: -3118.4791015625\n",
      "                , loss2: 378.3955810546875\n",
      "=================================\n",
      "in 3650 epoch, average loss: -30900.409375\n",
      "                , loss1: -3133.5919921875\n",
      "                , loss2: 435.5119140625\n",
      "=================================\n",
      "in 3660 epoch, average loss: -30911.765625\n",
      "                , loss1: -3136.0619140625\n",
      "                , loss2: 448.85458984375\n",
      "=================================\n",
      "in 3670 epoch, average loss: -30906.746875\n",
      "                , loss1: -3127.125\n",
      "                , loss2: 364.5017578125\n",
      "=================================\n",
      "in 3680 epoch, average loss: -30925.875\n",
      "                , loss1: -3132.6052734375\n",
      "                , loss2: 400.1741943359375\n",
      "=================================\n",
      "in 3690 epoch, average loss: -30755.165625\n",
      "                , loss1: -3118.301953125\n",
      "                , loss2: 427.85322265625\n",
      "=================================\n",
      "in 3700 epoch, average loss: -30787.56875\n",
      "                , loss1: -3125.7298828125\n",
      "                , loss2: 469.730419921875\n",
      "=================================\n",
      "in 3710 epoch, average loss: -30622.025\n",
      "                , loss1: -3111.38828125\n",
      "                , loss2: 491.855615234375\n",
      "=================================\n",
      "in 3720 epoch, average loss: -30718.253125\n",
      "                , loss1: -3144.426171875\n",
      "                , loss2: 726.009765625\n",
      "=================================\n",
      "in 3730 epoch, average loss: -30770.7375\n",
      "                , loss1: -3133.846875\n",
      "                , loss2: 567.727734375\n",
      "=================================\n",
      "in 3740 epoch, average loss: -30832.73125\n",
      "                , loss1: -3137.5787109375\n",
      "                , loss2: 543.055712890625\n",
      "=================================\n",
      "in 3750 epoch, average loss: -30862.584375\n",
      "                , loss1: -3140.1556640625\n",
      "                , loss2: 538.97294921875\n",
      "=================================\n",
      "in 3760 epoch, average loss: -31026.271875\n",
      "                , loss1: -3145.015625\n",
      "                , loss2: 423.8822265625\n",
      "=================================\n",
      "in 3770 epoch, average loss: -31175.190625\n",
      "                , loss1: -3158.9333984375\n",
      "                , loss2: 414.143701171875\n",
      "=================================\n",
      "in 3780 epoch, average loss: -31052.865625\n",
      "                , loss1: -3161.2978515625\n",
      "                , loss2: 560.113037109375\n",
      "=================================\n",
      "in 3790 epoch, average loss: -31194.634375\n",
      "                , loss1: -3164.3005859375\n",
      "                , loss2: 448.372021484375\n",
      "=================================\n",
      "in 3800 epoch, average loss: -31141.15\n",
      "                , loss1: -3163.3142578125\n",
      "                , loss2: 491.995361328125\n",
      "=================================\n",
      "in 3810 epoch, average loss: -31185.7125\n",
      "                , loss1: -3163.758984375\n",
      "                , loss2: 451.87509765625\n",
      "=================================\n",
      "in 3820 epoch, average loss: -31321.696875\n",
      "                , loss1: -3177.009765625\n",
      "                , loss2: 448.4025390625\n",
      "=================================\n",
      "in 3830 epoch, average loss: -31298.859375\n",
      "                , loss1: -3171.1671875\n",
      "                , loss2: 412.81171875\n",
      "=================================\n",
      "in 3840 epoch, average loss: -31375.1\n",
      "                , loss1: -3174.3998046875\n",
      "                , loss2: 368.897705078125\n",
      "=================================\n",
      "in 3850 epoch, average loss: -31448.709375\n",
      "                , loss1: -3178.42421875\n",
      "                , loss2: 335.5307861328125\n",
      "=================================\n",
      "in 3860 epoch, average loss: -31463.16875\n",
      "                , loss1: -3193.7509765625\n",
      "                , loss2: 474.34501953125\n",
      "=================================\n",
      "in 3870 epoch, average loss: -31501.08125\n",
      "                , loss1: -3189.65703125\n",
      "                , loss2: 395.4889892578125\n",
      "=================================\n",
      "in 3880 epoch, average loss: -31511.33125\n",
      "                , loss1: -3194.6841796875\n",
      "                , loss2: 435.510595703125\n",
      "=================================\n",
      "in 3890 epoch, average loss: -31610.934375\n",
      "                , loss1: -3214.759765625\n",
      "                , loss2: 536.66484375\n",
      "=================================\n",
      "in 3900 epoch, average loss: -31577.31875\n",
      "                , loss1: -3203.6279296875\n",
      "                , loss2: 458.959228515625\n",
      "=================================\n",
      "in 3910 epoch, average loss: -31632.546875\n",
      "                , loss1: -3201.37578125\n",
      "                , loss2: 381.209375\n",
      "=================================\n",
      "in 3920 epoch, average loss: -31651.2375\n",
      "                , loss1: -3217.4220703125\n",
      "                , loss2: 522.98427734375\n",
      "=================================\n",
      "in 3930 epoch, average loss: -31758.28125\n",
      "                , loss1: -3222.0431640625\n",
      "                , loss2: 462.148974609375\n",
      "=================================\n",
      "in 3940 epoch, average loss: -31879.33125\n",
      "                , loss1: -3235.942578125\n",
      "                , loss2: 480.0943359375\n",
      "=================================\n",
      "in 3950 epoch, average loss: -31909.865625\n",
      "                , loss1: -3237.585546875\n",
      "                , loss2: 465.9888671875\n",
      "=================================\n",
      "in 3960 epoch, average loss: -32022.35625\n",
      "                , loss1: -3248.264453125\n",
      "                , loss2: 460.28896484375\n",
      "=================================\n",
      "in 3970 epoch, average loss: -32080.1875\n",
      "                , loss1: -3257.23984375\n",
      "                , loss2: 492.210400390625\n",
      "=================================\n",
      "in 3980 epoch, average loss: -32168.184375\n",
      "                , loss1: -3260.2208984375\n",
      "                , loss2: 434.0234375\n",
      "=================================\n",
      "in 3990 epoch, average loss: -32174.1125\n",
      "                , loss1: -3269.57265625\n",
      "                , loss2: 521.612353515625\n",
      "=================================\n",
      "in 4000 epoch, average loss: -32173.740625\n",
      "                , loss1: -3269.383203125\n",
      "                , loss2: 520.089501953125\n",
      "=================================\n",
      "in 4010 epoch, average loss: -32117.275\n",
      "                , loss1: -3271.780078125\n",
      "                , loss2: 600.525390625\n",
      "=================================\n",
      "in 4020 epoch, average loss: -32343.459375\n",
      "                , loss1: -3291.590625\n",
      "                , loss2: 572.44794921875\n",
      "=================================\n",
      "in 4030 epoch, average loss: -32661.521875\n",
      "                , loss1: -3323.38671875\n",
      "                , loss2: 572.343505859375\n",
      "=================================\n",
      "in 4040 epoch, average loss: -32831.828125\n",
      "                , loss1: -3323.175\n",
      "                , loss2: 399.9189453125\n",
      "=================================\n",
      "in 4050 epoch, average loss: -32998.56875\n",
      "                , loss1: -3349.88125\n",
      "                , loss2: 500.24560546875\n",
      "=================================\n",
      "in 4060 epoch, average loss: -33058.15\n",
      "                , loss1: -3360.594140625\n",
      "                , loss2: 547.78740234375\n",
      "=================================\n",
      "in 4070 epoch, average loss: -33355.49375\n",
      "                , loss1: -3382.0375\n",
      "                , loss2: 464.87646484375\n",
      "=================================\n",
      "in 4080 epoch, average loss: -33552.709375\n",
      "                , loss1: -3400.751953125\n",
      "                , loss2: 454.8046875\n",
      "=================================\n",
      "in 4090 epoch, average loss: -33915.371875\n",
      "                , loss1: -3443.99296875\n",
      "                , loss2: 524.563037109375\n",
      "=================================\n",
      "in 4100 epoch, average loss: -34236.746875\n",
      "                , loss1: -3475.751953125\n",
      "                , loss2: 520.775048828125\n",
      "=================================\n",
      "in 4110 epoch, average loss: -34507.76875\n",
      "                , loss1: -3520.18671875\n",
      "                , loss2: 694.09853515625\n",
      "=================================\n",
      "in 4120 epoch, average loss: -35102.2875\n",
      "                , loss1: -3564.08828125\n",
      "                , loss2: 538.5958984375\n",
      "=================================\n",
      "in 4130 epoch, average loss: -35541.55\n",
      "                , loss1: -3614.941796875\n",
      "                , loss2: 607.8666015625\n",
      "=================================\n",
      "in 4140 epoch, average loss: -35569.025\n",
      "                , loss1: -3656.526953125\n",
      "                , loss2: 996.2458984375\n",
      "=================================\n",
      "in 4150 epoch, average loss: -36074.30625\n",
      "                , loss1: -3679.288671875\n",
      "                , loss2: 718.579541015625\n",
      "=================================\n",
      "in 4160 epoch, average loss: -36216.375\n",
      "                , loss1: -3735.243359375\n",
      "                , loss2: 1136.0595703125\n",
      "=================================\n",
      "in 4170 epoch, average loss: -36751.93125\n",
      "                , loss1: -3753.955859375\n",
      "                , loss2: 787.627001953125\n",
      "=================================\n",
      "in 4180 epoch, average loss: -37450.8875\n",
      "                , loss1: -3807.670703125\n",
      "                , loss2: 625.822705078125\n",
      "=================================\n",
      "in 4190 epoch, average loss: -37658.03125\n",
      "                , loss1: -3822.679296875\n",
      "                , loss2: 568.765478515625\n",
      "=================================\n",
      "in 4200 epoch, average loss: -38084.975\n",
      "                , loss1: -3859.604296875\n",
      "                , loss2: 511.064990234375\n",
      "=================================\n",
      "in 4210 epoch, average loss: -38329.11875\n",
      "                , loss1: -3884.47578125\n",
      "                , loss2: 515.641943359375\n",
      "=================================\n",
      "in 4220 epoch, average loss: -38483.6875\n",
      "                , loss1: -3900.231640625\n",
      "                , loss2: 518.625048828125\n",
      "=================================\n",
      "in 4230 epoch, average loss: -38646.9125\n",
      "                , loss1: -3910.3671875\n",
      "                , loss2: 456.762158203125\n",
      "=================================\n",
      "in 4240 epoch, average loss: -38905.0875\n",
      "                , loss1: -3937.41484375\n",
      "                , loss2: 469.06142578125\n",
      "=================================\n",
      "in 4250 epoch, average loss: -39082.765625\n",
      "                , loss1: -3961.28984375\n",
      "                , loss2: 530.13017578125\n",
      "=================================\n",
      "in 4260 epoch, average loss: -38902.225\n",
      "                , loss1: -3954.817578125\n",
      "                , loss2: 645.95341796875\n",
      "=================================\n",
      "in 4270 epoch, average loss: -39322.725\n",
      "                , loss1: -3989.79140625\n",
      "                , loss2: 575.191259765625\n",
      "=================================\n",
      "in 4280 epoch, average loss: -39235.284375\n",
      "                , loss1: -3979.071484375\n",
      "                , loss2: 555.429931640625\n",
      "=================================\n",
      "in 4290 epoch, average loss: -39139.990625\n",
      "                , loss1: -3969.5484375\n",
      "                , loss2: 555.49384765625\n",
      "=================================\n",
      "in 4300 epoch, average loss: -39581.246875\n",
      "                , loss1: -4013.078125\n",
      "                , loss2: 549.529052734375\n",
      "=================================\n",
      "in 4310 epoch, average loss: -39625.68125\n",
      "                , loss1: -4020.803515625\n",
      "                , loss2: 582.354541015625\n",
      "=================================\n",
      "in 4320 epoch, average loss: -39718.871875\n",
      "                , loss1: -4028.837109375\n",
      "                , loss2: 569.50380859375\n",
      "=================================\n",
      "in 4330 epoch, average loss: -39859.965625\n",
      "                , loss1: -4032.250390625\n",
      "                , loss2: 462.5412109375\n",
      "=================================\n",
      "in 4340 epoch, average loss: -39790.95\n",
      "                , loss1: -4037.404296875\n",
      "                , loss2: 583.095361328125\n",
      "=================================\n",
      "in 4350 epoch, average loss: -39967.190625\n",
      "                , loss1: -4048.290625\n",
      "                , loss2: 515.71259765625\n",
      "=================================\n",
      "in 4360 epoch, average loss: -40224.428125\n",
      "                , loss1: -4080.27890625\n",
      "                , loss2: 578.3580078125\n",
      "=================================\n",
      "in 4370 epoch, average loss: -40103.696875\n",
      "                , loss1: -4064.908203125\n",
      "                , loss2: 545.381591796875\n",
      "=================================\n",
      "in 4380 epoch, average loss: -40402.43125\n",
      "                , loss1: -4091.589453125\n",
      "                , loss2: 513.465087890625\n",
      "=================================\n",
      "in 4390 epoch, average loss: -40388.525\n",
      "                , loss1: -4106.585546875\n",
      "                , loss2: 677.334716796875\n",
      "=================================\n",
      "in 4400 epoch, average loss: -40302.621875\n",
      "                , loss1: -4081.540625\n",
      "                , loss2: 512.78564453125\n",
      "=================================\n",
      "in 4410 epoch, average loss: -39643.909375\n",
      "                , loss1: -4082.862109375\n",
      "                , loss2: 1184.7134765625\n",
      "=================================\n",
      "in 4420 epoch, average loss: -40332.365625\n",
      "                , loss1: -4082.67421875\n",
      "                , loss2: 494.37734375\n",
      "=================================\n",
      "in 4430 epoch, average loss: -40673.80625\n",
      "                , loss1: -4115.8890625\n",
      "                , loss2: 485.084912109375\n",
      "=================================\n",
      "in 4440 epoch, average loss: -40625.484375\n",
      "                , loss1: -4113.81171875\n",
      "                , loss2: 512.6375\n",
      "=================================\n",
      "in 4450 epoch, average loss: -40778.565625\n",
      "                , loss1: -4135.01640625\n",
      "                , loss2: 571.601318359375\n",
      "=================================\n",
      "in 4460 epoch, average loss: -40871.9875\n",
      "                , loss1: -4129.282421875\n",
      "                , loss2: 420.838671875\n",
      "=================================\n",
      "in 4470 epoch, average loss: -41160.1625\n",
      "                , loss1: -4169.479296875\n",
      "                , loss2: 534.62998046875\n",
      "=================================\n",
      "in 4480 epoch, average loss: -41095.24375\n",
      "                , loss1: -4147.497265625\n",
      "                , loss2: 379.7245849609375\n",
      "=================================\n",
      "in 4490 epoch, average loss: -41362.321875\n",
      "                , loss1: -4184.046875\n",
      "                , loss2: 478.143310546875\n",
      "=================================\n",
      "in 4500 epoch, average loss: -41236.0\n",
      "                , loss1: -4184.21953125\n",
      "                , loss2: 606.19794921875\n",
      "=================================\n",
      "in 4510 epoch, average loss: -41129.525\n",
      "                , loss1: -4187.772265625\n",
      "                , loss2: 748.191650390625\n",
      "=================================\n",
      "in 4520 epoch, average loss: -41377.125\n",
      "                , loss1: -4182.594140625\n",
      "                , loss2: 448.818896484375\n",
      "=================================\n",
      "in 4530 epoch, average loss: -41680.75625\n",
      "                , loss1: -4207.006640625\n",
      "                , loss2: 389.3066650390625\n",
      "=================================\n",
      "in 4540 epoch, average loss: -41505.765625\n",
      "                , loss1: -4203.66328125\n",
      "                , loss2: 530.871630859375\n",
      "=================================\n",
      "in 4550 epoch, average loss: -41726.709375\n",
      "                , loss1: -4206.163671875\n",
      "                , loss2: 334.9288818359375\n",
      "=================================\n",
      "in 4560 epoch, average loss: -41734.25625\n",
      "                , loss1: -4217.89765625\n",
      "                , loss2: 444.719482421875\n",
      "=================================\n",
      "in 4570 epoch, average loss: -41788.790625\n",
      "                , loss1: -4235.2828125\n",
      "                , loss2: 564.040478515625\n",
      "=================================\n",
      "in 4580 epoch, average loss: -41733.709375\n",
      "                , loss1: -4228.0171875\n",
      "                , loss2: 546.465625\n",
      "=================================\n",
      "in 4590 epoch, average loss: -41639.796875\n",
      "                , loss1: -4227.5140625\n",
      "                , loss2: 635.348779296875\n",
      "=================================\n",
      "in 4600 epoch, average loss: -41744.559375\n",
      "                , loss1: -4231.53125\n",
      "                , loss2: 570.75341796875\n",
      "=================================\n",
      "in 4610 epoch, average loss: -42228.928125\n",
      "                , loss1: -4279.518359375\n",
      "                , loss2: 566.253173828125\n",
      "=================================\n",
      "in 4620 epoch, average loss: -42289.2625\n",
      "                , loss1: -4277.61171875\n",
      "                , loss2: 486.85302734375\n",
      "=================================\n",
      "in 4630 epoch, average loss: -42349.15625\n",
      "                , loss1: -4276.727734375\n",
      "                , loss2: 418.119970703125\n",
      "=================================\n",
      "in 4640 epoch, average loss: -42458.678125\n",
      "                , loss1: -4289.469921875\n",
      "                , loss2: 436.020068359375\n",
      "=================================\n",
      "in 4650 epoch, average loss: -42450.634375\n",
      "                , loss1: -4293.9609375\n",
      "                , loss2: 488.975\n",
      "=================================\n",
      "in 4660 epoch, average loss: -42318.290625\n",
      "                , loss1: -4283.009375\n",
      "                , loss2: 511.80283203125\n",
      "=================================\n",
      "in 4670 epoch, average loss: -42387.771875\n",
      "                , loss1: -4300.396484375\n",
      "                , loss2: 616.19140625\n",
      "=================================\n",
      "in 4680 epoch, average loss: -42575.975\n",
      "                , loss1: -4308.21015625\n",
      "                , loss2: 506.12900390625\n",
      "=================================\n",
      "in 4690 epoch, average loss: -42634.784375\n",
      "                , loss1: -4324.455078125\n",
      "                , loss2: 609.763330078125\n",
      "=================================\n",
      "in 4700 epoch, average loss: -42689.51875\n",
      "                , loss1: -4315.19296875\n",
      "                , loss2: 462.407568359375\n",
      "=================================\n",
      "in 4710 epoch, average loss: -42862.1125\n",
      "                , loss1: -4326.372265625\n",
      "                , loss2: 401.610791015625\n",
      "=================================\n",
      "in 4720 epoch, average loss: -42850.071875\n",
      "                , loss1: -4327.1\n",
      "                , loss2: 420.924169921875\n",
      "=================================\n",
      "in 4730 epoch, average loss: -42994.921875\n",
      "                , loss1: -4343.843359375\n",
      "                , loss2: 443.513916015625\n",
      "=================================\n",
      "in 4740 epoch, average loss: -42970.209375\n",
      "                , loss1: -4339.50625\n",
      "                , loss2: 424.85458984375\n",
      "=================================\n",
      "in 4750 epoch, average loss: -43075.459375\n",
      "                , loss1: -4350.806640625\n",
      "                , loss2: 432.60849609375\n",
      "=================================\n",
      "in 4760 epoch, average loss: -43201.778125\n",
      "                , loss1: -4359.7453125\n",
      "                , loss2: 395.6808349609375\n",
      "=================================\n",
      "in 4770 epoch, average loss: -43041.921875\n",
      "                , loss1: -4357.697265625\n",
      "                , loss2: 535.05859375\n",
      "=================================\n",
      "in 4780 epoch, average loss: -43192.75\n",
      "                , loss1: -4359.61328125\n",
      "                , loss2: 403.3865234375\n",
      "=================================\n",
      "in 4790 epoch, average loss: -43281.140625\n",
      "                , loss1: -4377.76953125\n",
      "                , loss2: 496.54853515625\n",
      "=================================\n",
      "in 4800 epoch, average loss: -43241.56875\n",
      "                , loss1: -4369.753515625\n",
      "                , loss2: 455.96728515625\n",
      "=================================\n",
      "in 4810 epoch, average loss: -43097.50625\n",
      "                , loss1: -4379.128125\n",
      "                , loss2: 693.781201171875\n",
      "=================================\n",
      "in 4820 epoch, average loss: -43276.296875\n",
      "                , loss1: -4380.555078125\n",
      "                , loss2: 529.249072265625\n",
      "=================================\n",
      "in 4830 epoch, average loss: -42926.21875\n",
      "                , loss1: -4342.3609375\n",
      "                , loss2: 497.386376953125\n",
      "=================================\n",
      "in 4840 epoch, average loss: -43109.65\n",
      "                , loss1: -4354.39140625\n",
      "                , loss2: 434.262109375\n",
      "=================================\n",
      "in 4850 epoch, average loss: -43199.5\n",
      "                , loss1: -4381.4765625\n",
      "                , loss2: 615.264990234375\n",
      "=================================\n",
      "in 4860 epoch, average loss: -43431.1375\n",
      "                , loss1: -4409.3421875\n",
      "                , loss2: 662.28388671875\n",
      "=================================\n",
      "in 4870 epoch, average loss: -43121.69375\n",
      "                , loss1: -4374.816015625\n",
      "                , loss2: 626.46328125\n",
      "=================================\n",
      "in 4880 epoch, average loss: -43472.5625\n",
      "                , loss1: -4399.189453125\n",
      "                , loss2: 519.328369140625\n",
      "=================================\n",
      "in 4890 epoch, average loss: -43518.453125\n",
      "                , loss1: -4392.884375\n",
      "                , loss2: 410.387939453125\n",
      "=================================\n",
      "in 4900 epoch, average loss: -43557.1375\n",
      "                , loss1: -4409.199609375\n",
      "                , loss2: 534.85302734375\n",
      "=================================\n",
      "in 4910 epoch, average loss: -43697.1625\n",
      "                , loss1: -4413.353515625\n",
      "                , loss2: 436.371630859375\n",
      "=================================\n",
      "in 4920 epoch, average loss: -43575.878125\n",
      "                , loss1: -4401.623046875\n",
      "                , loss2: 440.347900390625\n",
      "=================================\n",
      "in 4930 epoch, average loss: -43816.36875\n",
      "                , loss1: -4431.80078125\n",
      "                , loss2: 501.6369140625\n",
      "=================================\n",
      "in 4940 epoch, average loss: -43800.325\n",
      "                , loss1: -4416.23203125\n",
      "                , loss2: 362.000732421875\n",
      "=================================\n",
      "in 4950 epoch, average loss: -43941.359375\n",
      "                , loss1: -4444.5109375\n",
      "                , loss2: 503.749951171875\n",
      "=================================\n",
      "in 4960 epoch, average loss: -43670.2625\n",
      "                , loss1: -4412.855859375\n",
      "                , loss2: 458.2921875\n",
      "=================================\n",
      "in 4970 epoch, average loss: -43705.98125\n",
      "                , loss1: -4433.246875\n",
      "                , loss2: 626.48994140625\n",
      "=================================\n",
      "in 4980 epoch, average loss: -43701.51875\n",
      "                , loss1: -4410.234375\n",
      "                , loss2: 400.822509765625\n",
      "=================================\n",
      "in 4990 epoch, average loss: -43949.89375\n",
      "                , loss1: -4460.538671875\n",
      "                , loss2: 655.494970703125\n",
      "=================================\n",
      "in 5000 epoch, average loss: -44093.565625\n",
      "                , loss1: -4448.888671875\n",
      "                , loss2: 395.323291015625\n",
      "=================================\n",
      "in 5010 epoch, average loss: -44017.765625\n",
      "                , loss1: -4458.618359375\n",
      "                , loss2: 568.421630859375\n",
      "=================================\n",
      "in 5020 epoch, average loss: -44176.06875\n",
      "                , loss1: -4465.85859375\n",
      "                , loss2: 482.515478515625\n",
      "=================================\n",
      "in 5030 epoch, average loss: -44191.771875\n",
      "                , loss1: -4470.267578125\n",
      "                , loss2: 510.903076171875\n",
      "=================================\n",
      "in 5040 epoch, average loss: -44209.365625\n",
      "                , loss1: -4481.58671875\n",
      "                , loss2: 606.500146484375\n",
      "=================================\n",
      "in 5050 epoch, average loss: -44458.028125\n",
      "                , loss1: -4487.82265625\n",
      "                , loss2: 420.199365234375\n",
      "=================================\n",
      "in 5060 epoch, average loss: -44506.0\n",
      "                , loss1: -4501.673046875\n",
      "                , loss2: 510.730859375\n",
      "=================================\n",
      "in 5070 epoch, average loss: -44391.703125\n",
      "                , loss1: -4494.88359375\n",
      "                , loss2: 557.13232421875\n",
      "=================================\n",
      "in 5080 epoch, average loss: -44635.39375\n",
      "                , loss1: -4512.646484375\n",
      "                , loss2: 491.070703125\n",
      "=================================\n",
      "in 5090 epoch, average loss: -44861.003125\n",
      "                , loss1: -4533.518359375\n",
      "                , loss2: 474.17861328125\n",
      "=================================\n",
      "in 5100 epoch, average loss: -44999.559375\n",
      "                , loss1: -4538.346875\n",
      "                , loss2: 383.9090087890625\n",
      "=================================\n",
      "in 5110 epoch, average loss: -45203.7125\n",
      "                , loss1: -4564.484375\n",
      "                , loss2: 441.137060546875\n",
      "=================================\n",
      "in 5120 epoch, average loss: -45494.565625\n",
      "                , loss1: -4590.904296875\n",
      "                , loss2: 414.48056640625\n",
      "=================================\n",
      "in 5130 epoch, average loss: -45447.76875\n",
      "                , loss1: -4591.3046875\n",
      "                , loss2: 465.277392578125\n",
      "=================================\n",
      "in 5140 epoch, average loss: -45481.13125\n",
      "                , loss1: -4608.586328125\n",
      "                , loss2: 604.73505859375\n",
      "=================================\n",
      "in 5150 epoch, average loss: -45724.196875\n",
      "                , loss1: -4623.551171875\n",
      "                , loss2: 511.306982421875\n",
      "=================================\n",
      "in 5160 epoch, average loss: -46005.775\n",
      "                , loss1: -4642.77421875\n",
      "                , loss2: 421.964697265625\n",
      "=================================\n",
      "in 5170 epoch, average loss: -46074.428125\n",
      "                , loss1: -4654.089453125\n",
      "                , loss2: 466.464697265625\n",
      "=================================\n",
      "in 5180 epoch, average loss: -46455.559375\n",
      "                , loss1: -4683.76015625\n",
      "                , loss2: 382.0430419921875\n",
      "=================================\n",
      "in 5190 epoch, average loss: -46714.425\n",
      "                , loss1: -4710.6109375\n",
      "                , loss2: 391.68232421875\n",
      "=================================\n",
      "in 5200 epoch, average loss: -46780.653125\n",
      "                , loss1: -4721.95546875\n",
      "                , loss2: 438.8998046875\n",
      "=================================\n",
      "in 5210 epoch, average loss: -47193.83125\n",
      "                , loss1: -4761.4578125\n",
      "                , loss2: 420.740673828125\n",
      "=================================\n",
      "in 5220 epoch, average loss: -47277.403125\n",
      "                , loss1: -4766.810546875\n",
      "                , loss2: 390.701220703125\n",
      "=================================\n",
      "in 5230 epoch, average loss: -47408.1875\n",
      "                , loss1: -4798.866015625\n",
      "                , loss2: 580.47490234375\n",
      "=================================\n",
      "in 5240 epoch, average loss: -47936.35\n",
      "                , loss1: -4834.34375\n",
      "                , loss2: 407.083642578125\n",
      "=================================\n",
      "in 5250 epoch, average loss: -48435.415625\n",
      "                , loss1: -4889.60546875\n",
      "                , loss2: 460.635107421875\n",
      "=================================\n",
      "in 5260 epoch, average loss: -48751.33125\n",
      "                , loss1: -4907.908984375\n",
      "                , loss2: 327.759521484375\n",
      "=================================\n",
      "in 5270 epoch, average loss: -48874.378125\n",
      "                , loss1: -4932.104296875\n",
      "                , loss2: 446.665478515625\n",
      "=================================\n",
      "in 5280 epoch, average loss: -49048.1\n",
      "                , loss1: -4939.5109375\n",
      "                , loss2: 347.0109619140625\n",
      "=================================\n",
      "in 5290 epoch, average loss: -49297.0\n",
      "                , loss1: -4975.418359375\n",
      "                , loss2: 457.18505859375\n",
      "=================================\n",
      "in 5300 epoch, average loss: -49379.171875\n",
      "                , loss1: -4984.33671875\n",
      "                , loss2: 464.193310546875\n",
      "=================================\n",
      "in 5310 epoch, average loss: -49655.86875\n",
      "                , loss1: -5006.007421875\n",
      "                , loss2: 404.2069091796875\n",
      "=================================\n",
      "in 5320 epoch, average loss: -49862.66875\n",
      "                , loss1: -5019.034375\n",
      "                , loss2: 327.6741455078125\n",
      "=================================\n",
      "in 5330 epoch, average loss: -50181.446875\n",
      "                , loss1: -5054.940625\n",
      "                , loss2: 367.9571533203125\n",
      "=================================\n",
      "in 5340 epoch, average loss: -50234.321875\n",
      "                , loss1: -5057.293359375\n",
      "                , loss2: 338.609619140625\n",
      "=================================\n",
      "in 5350 epoch, average loss: -50517.45625\n",
      "                , loss1: -5086.148828125\n",
      "                , loss2: 344.023681640625\n",
      "=================================\n",
      "in 5360 epoch, average loss: -50637.146875\n",
      "                , loss1: -5098.66875\n",
      "                , loss2: 349.541357421875\n",
      "=================================\n",
      "in 5370 epoch, average loss: -50935.8125\n",
      "                , loss1: -5134.430859375\n",
      "                , loss2: 408.4910888671875\n",
      "=================================\n",
      "in 5380 epoch, average loss: -50990.81875\n",
      "                , loss1: -5144.210546875\n",
      "                , loss2: 451.283447265625\n",
      "=================================\n",
      "in 5390 epoch, average loss: -51106.1875\n",
      "                , loss1: -5141.64921875\n",
      "                , loss2: 310.299072265625\n",
      "=================================\n",
      "in 5400 epoch, average loss: -50956.89375\n",
      "                , loss1: -5141.8875\n",
      "                , loss2: 461.986572265625\n",
      "=================================\n",
      "in 5410 epoch, average loss: -51378.946875\n",
      "                , loss1: -5172.97109375\n",
      "                , loss2: 350.7690185546875\n",
      "=================================\n",
      "in 5420 epoch, average loss: -50487.025\n",
      "                , loss1: -5120.89765625\n",
      "                , loss2: 721.952490234375\n",
      "=================================\n",
      "in 5430 epoch, average loss: -50615.165625\n",
      "                , loss1: -5122.412890625\n",
      "                , loss2: 608.9646484375\n",
      "=================================\n",
      "in 5440 epoch, average loss: -51435.646875\n",
      "                , loss1: -5183.757421875\n",
      "                , loss2: 401.924951171875\n",
      "=================================\n",
      "in 5450 epoch, average loss: -51768.2375\n",
      "                , loss1: -5227.443359375\n",
      "                , loss2: 506.2001953125\n",
      "=================================\n",
      "in 5460 epoch, average loss: -52149.728125\n",
      "                , loss1: -5258.39296875\n",
      "                , loss2: 434.197216796875\n",
      "=================================\n",
      "in 5470 epoch, average loss: -52067.75625\n",
      "                , loss1: -5244.300390625\n",
      "                , loss2: 375.248681640625\n",
      "=================================\n",
      "in 5480 epoch, average loss: -52245.115625\n",
      "                , loss1: -5254.83359375\n",
      "                , loss2: 303.2201904296875\n",
      "=================================\n",
      "in 5490 epoch, average loss: -52370.33125\n",
      "                , loss1: -5283.309375\n",
      "                , loss2: 462.765087890625\n",
      "=================================\n",
      "in 5500 epoch, average loss: -52442.94375\n",
      "                , loss1: -5270.823828125\n",
      "                , loss2: 265.2893310546875\n",
      "=================================\n",
      "in 5510 epoch, average loss: -52557.86875\n",
      "                , loss1: -5287.07578125\n",
      "                , loss2: 312.8826171875\n",
      "=================================\n",
      "in 5520 epoch, average loss: -52805.05\n",
      "                , loss1: -5313.8265625\n",
      "                , loss2: 333.213818359375\n",
      "=================================\n",
      "in 5530 epoch, average loss: -52639.75\n",
      "                , loss1: -5297.0578125\n",
      "                , loss2: 330.8419921875\n",
      "=================================\n",
      "in 5540 epoch, average loss: -53065.80625\n",
      "                , loss1: -5331.540234375\n",
      "                , loss2: 249.598779296875\n",
      "=================================\n",
      "in 5550 epoch, average loss: -53175.5375\n",
      "                , loss1: -5336.48203125\n",
      "                , loss2: 189.28350830078125\n",
      "=================================\n",
      "in 5560 epoch, average loss: -53157.38125\n",
      "                , loss1: -5338.926171875\n",
      "                , loss2: 231.88603515625\n",
      "=================================\n",
      "in 5570 epoch, average loss: -53335.35\n",
      "                , loss1: -5353.650390625\n",
      "                , loss2: 201.15582275390625\n",
      "=================================\n",
      "in 5580 epoch, average loss: -53436.05\n",
      "                , loss1: -5367.5609375\n",
      "                , loss2: 239.56494140625\n",
      "=================================\n",
      "in 5590 epoch, average loss: -53423.29375\n",
      "                , loss1: -5360.78515625\n",
      "                , loss2: 184.56220703125\n",
      "=================================\n",
      "in 5600 epoch, average loss: -53318.2375\n",
      "                , loss1: -5353.76484375\n",
      "                , loss2: 219.4143798828125\n",
      "=================================\n",
      "in 5610 epoch, average loss: -53581.775\n",
      "                , loss1: -5375.915234375\n",
      "                , loss2: 177.3758056640625\n",
      "=================================\n",
      "in 5620 epoch, average loss: -53696.325\n",
      "                , loss1: -5391.205078125\n",
      "                , loss2: 215.7299560546875\n",
      "=================================\n",
      "in 5630 epoch, average loss: -53558.35\n",
      "                , loss1: -5380.86015625\n",
      "                , loss2: 250.2506591796875\n",
      "=================================\n",
      "in 5640 epoch, average loss: -53699.28125\n",
      "                , loss1: -5402.055078125\n",
      "                , loss2: 321.26640625\n",
      "=================================\n",
      "in 5650 epoch, average loss: -53602.30625\n",
      "                , loss1: -5378.21640625\n",
      "                , loss2: 179.85478515625\n",
      "=================================\n",
      "in 5660 epoch, average loss: -53011.49375\n",
      "                , loss1: -5347.6015625\n",
      "                , loss2: 464.5251953125\n",
      "=================================\n",
      "in 5670 epoch, average loss: -53399.23125\n",
      "                , loss1: -5374.537109375\n",
      "                , loss2: 346.1371826171875\n",
      "=================================\n",
      "in 5680 epoch, average loss: -53866.11875\n",
      "                , loss1: -5411.633203125\n",
      "                , loss2: 250.2037109375\n",
      "=================================\n",
      "in 5690 epoch, average loss: -53963.96875\n",
      "                , loss1: -5411.55078125\n",
      "                , loss2: 151.53804931640624\n",
      "=================================\n",
      "in 5700 epoch, average loss: -54162.05\n",
      "                , loss1: -5437.526171875\n",
      "                , loss2: 213.2135009765625\n",
      "=================================\n",
      "in 5710 epoch, average loss: -54004.8625\n",
      "                , loss1: -5417.5296875\n",
      "                , loss2: 170.4339599609375\n",
      "=================================\n",
      "in 5720 epoch, average loss: -53941.13125\n",
      "                , loss1: -5416.262890625\n",
      "                , loss2: 221.4967041015625\n",
      "=================================\n",
      "in 5730 epoch, average loss: -54147.38125\n",
      "                , loss1: -5429.9171875\n",
      "                , loss2: 151.789111328125\n",
      "=================================\n",
      "in 5740 epoch, average loss: -54064.15\n",
      "                , loss1: -5431.5546875\n",
      "                , loss2: 251.3937744140625\n",
      "=================================\n",
      "in 5750 epoch, average loss: -51613.675\n",
      "                , loss1: -5347.88125\n",
      "                , loss2: 1865.1322265625\n",
      "=================================\n",
      "in 5760 epoch, average loss: -51993.54375\n",
      "                , loss1: -5305.6734375\n",
      "                , loss2: 1063.18388671875\n",
      "=================================\n",
      "in 5770 epoch, average loss: -52862.01875\n",
      "                , loss1: -5351.8609375\n",
      "                , loss2: 656.601318359375\n",
      "=================================\n",
      "in 5780 epoch, average loss: -53880.71875\n",
      "                , loss1: -5411.76953125\n",
      "                , loss2: 236.97890625\n",
      "=================================\n",
      "in 5790 epoch, average loss: -54126.225\n",
      "                , loss1: -5435.372265625\n",
      "                , loss2: 227.4941162109375\n",
      "=================================\n",
      "in 5800 epoch, average loss: -54268.1625\n",
      "                , loss1: -5446.4171875\n",
      "                , loss2: 196.00113525390626\n",
      "=================================\n",
      "in 5810 epoch, average loss: -54352.1375\n",
      "                , loss1: -5454.990625\n",
      "                , loss2: 197.7740966796875\n",
      "=================================\n",
      "in 5820 epoch, average loss: -54187.675\n",
      "                , loss1: -5445.2875\n",
      "                , loss2: 265.1951171875\n",
      "=================================\n",
      "in 5830 epoch, average loss: -54294.78125\n",
      "                , loss1: -5456.009375\n",
      "                , loss2: 265.305615234375\n",
      "=================================\n",
      "in 5840 epoch, average loss: -54264.625\n",
      "                , loss1: -5455.66015625\n",
      "                , loss2: 291.9744873046875\n",
      "=================================\n",
      "in 5850 epoch, average loss: -54157.725\n",
      "                , loss1: -5444.155078125\n",
      "                , loss2: 283.822705078125\n",
      "=================================\n",
      "in 5860 epoch, average loss: -54331.15\n",
      "                , loss1: -5455.0953125\n",
      "                , loss2: 219.8001220703125\n",
      "=================================\n",
      "in 5870 epoch, average loss: -54171.83125\n",
      "                , loss1: -5448.22734375\n",
      "                , loss2: 310.443310546875\n",
      "=================================\n",
      "in 5880 epoch, average loss: -54608.5875\n",
      "                , loss1: -5477.570703125\n",
      "                , loss2: 167.11710205078126\n",
      "=================================\n",
      "in 5890 epoch, average loss: -54336.3625\n",
      "                , loss1: -5448.45078125\n",
      "                , loss2: 148.145703125\n",
      "=================================\n",
      "in 5900 epoch, average loss: -54604.68125\n",
      "                , loss1: -5477.94296875\n",
      "                , loss2: 174.7476806640625\n",
      "=================================\n",
      "in 5910 epoch, average loss: -54197.2375\n",
      "                , loss1: -5446.087109375\n",
      "                , loss2: 263.6356689453125\n",
      "=================================\n",
      "in 5920 epoch, average loss: -54159.84375\n",
      "                , loss1: -5454.073046875\n",
      "                , loss2: 380.8806640625\n",
      "=================================\n",
      "in 5930 epoch, average loss: -54412.4875\n",
      "                , loss1: -5465.575390625\n",
      "                , loss2: 243.2693603515625\n",
      "=================================\n",
      "in 5940 epoch, average loss: -54831.3875\n",
      "                , loss1: -5500.803125\n",
      "                , loss2: 176.64970703125\n",
      "=================================\n",
      "in 5950 epoch, average loss: -54644.69375\n",
      "                , loss1: -5484.075\n",
      "                , loss2: 196.060595703125\n",
      "=================================\n",
      "in 5960 epoch, average loss: -54672.39375\n",
      "                , loss1: -5489.51953125\n",
      "                , loss2: 222.802978515625\n",
      "=================================\n",
      "in 5970 epoch, average loss: -54863.45625\n",
      "                , loss1: -5502.0609375\n",
      "                , loss2: 157.16085205078124\n",
      "=================================\n",
      "in 5980 epoch, average loss: -54964.7\n",
      "                , loss1: -5531.689453125\n",
      "                , loss2: 352.1964111328125\n",
      "=================================\n",
      "in 5990 epoch, average loss: -54819.775\n",
      "                , loss1: -5494.6671875\n",
      "                , loss2: 126.8979248046875\n",
      "=================================\n",
      "in 6000 epoch, average loss: -54775.5125\n",
      "                , loss1: -5497.66875\n",
      "                , loss2: 201.17366943359374\n",
      "=================================\n",
      "in 6010 epoch, average loss: -54734.11875\n",
      "                , loss1: -5495.427734375\n",
      "                , loss2: 220.15771484375\n",
      "=================================\n",
      "in 6020 epoch, average loss: -54797.78125\n",
      "                , loss1: -5505.479296875\n",
      "                , loss2: 257.0166015625\n",
      "=================================\n",
      "in 6030 epoch, average loss: -54946.1625\n",
      "                , loss1: -5518.774609375\n",
      "                , loss2: 241.5832763671875\n",
      "=================================\n",
      "in 6040 epoch, average loss: -55005.7875\n",
      "                , loss1: -5527.91875\n",
      "                , loss2: 273.403955078125\n",
      "=================================\n",
      "in 6050 epoch, average loss: -55034.3125\n",
      "                , loss1: -5521.1640625\n",
      "                , loss2: 177.32447509765626\n",
      "=================================\n",
      "in 6060 epoch, average loss: -55078.09375\n",
      "                , loss1: -5522.702734375\n",
      "                , loss2: 148.93800048828126\n",
      "=================================\n",
      "in 6070 epoch, average loss: -54889.88125\n",
      "                , loss1: -5500.078125\n",
      "                , loss2: 110.89754638671874\n",
      "=================================\n",
      "in 6080 epoch, average loss: -55094.525\n",
      "                , loss1: -5524.423046875\n",
      "                , loss2: 149.70218505859376\n",
      "=================================\n",
      "in 6090 epoch, average loss: -55121.2375\n",
      "                , loss1: -5520.24921875\n",
      "                , loss2: 81.25503540039062\n",
      "=================================\n",
      "in 6100 epoch, average loss: -54882.79375\n",
      "                , loss1: -5511.53203125\n",
      "                , loss2: 232.5269775390625\n",
      "=================================\n",
      "in 6110 epoch, average loss: -55070.5625\n",
      "                , loss1: -5517.675\n",
      "                , loss2: 106.18531494140625\n",
      "=================================\n",
      "in 6120 epoch, average loss: -55120.425\n",
      "                , loss1: -5528.81015625\n",
      "                , loss2: 167.682861328125\n",
      "=================================\n",
      "in 6130 epoch, average loss: -55189.3875\n",
      "                , loss1: -5533.8921875\n",
      "                , loss2: 149.5310302734375\n",
      "=================================\n",
      "in 6140 epoch, average loss: -54921.64375\n",
      "                , loss1: -5514.70859375\n",
      "                , loss2: 225.438623046875\n",
      "=================================\n",
      "in 6150 epoch, average loss: -55149.1625\n",
      "                , loss1: -5541.2625\n",
      "                , loss2: 263.4639892578125\n",
      "=================================\n",
      "in 6160 epoch, average loss: -54442.64375\n",
      "                , loss1: -5496.45703125\n",
      "                , loss2: 521.92587890625\n",
      "=================================\n",
      "in 6170 epoch, average loss: -55024.6625\n",
      "                , loss1: -5518.081640625\n",
      "                , loss2: 156.15523681640624\n",
      "=================================\n",
      "in 6180 epoch, average loss: -55003.23125\n",
      "                , loss1: -5508.77421875\n",
      "                , loss2: 84.51621704101562\n",
      "=================================\n",
      "in 6190 epoch, average loss: -55130.29375\n",
      "                , loss1: -5534.801953125\n",
      "                , loss2: 217.718408203125\n",
      "=================================\n",
      "in 6200 epoch, average loss: -55006.325\n",
      "                , loss1: -5527.315234375\n",
      "                , loss2: 266.82451171875\n",
      "=================================\n",
      "in 6210 epoch, average loss: -55626.11875\n",
      "                , loss1: -5576.947265625\n",
      "                , loss2: 143.347216796875\n",
      "=================================\n",
      "in 6220 epoch, average loss: -55302.9875\n",
      "                , loss1: -5546.281640625\n",
      "                , loss2: 159.82655029296876\n",
      "=================================\n",
      "in 6230 epoch, average loss: -55188.2125\n",
      "                , loss1: -5535.04375\n",
      "                , loss2: 162.2221435546875\n",
      "=================================\n",
      "in 6240 epoch, average loss: -55416.64375\n",
      "                , loss1: -5554.675\n",
      "                , loss2: 130.1034912109375\n",
      "=================================\n",
      "in 6250 epoch, average loss: -55260.84375\n",
      "                , loss1: -5537.5109375\n",
      "                , loss2: 114.2656982421875\n",
      "=================================\n",
      "in 6260 epoch, average loss: -55465.1375\n",
      "                , loss1: -5559.6578125\n",
      "                , loss2: 131.43782958984374\n",
      "=================================\n",
      "in 6270 epoch, average loss: -55609.60625\n",
      "                , loss1: -5573.864453125\n",
      "                , loss2: 129.031494140625\n",
      "=================================\n",
      "in 6280 epoch, average loss: -55367.35625\n",
      "                , loss1: -5546.57421875\n",
      "                , loss2: 98.3806884765625\n",
      "=================================\n",
      "in 6290 epoch, average loss: -55452.9625\n",
      "                , loss1: -5568.848046875\n",
      "                , loss2: 235.5220703125\n",
      "=================================\n",
      "in 6300 epoch, average loss: -55513.4375\n",
      "                , loss1: -5558.9546875\n",
      "                , loss2: 76.11371459960938\n",
      "=================================\n",
      "in 6310 epoch, average loss: -55376.04375\n",
      "                , loss1: -5555.3984375\n",
      "                , loss2: 177.93927001953125\n",
      "=================================\n",
      "in 6320 epoch, average loss: -55340.7125\n",
      "                , loss1: -5544.4734375\n",
      "                , loss2: 104.01785888671876\n",
      "=================================\n",
      "in 6330 epoch, average loss: -55565.11875\n",
      "                , loss1: -5561.33125\n",
      "                , loss2: 48.18948059082031\n",
      "=================================\n",
      "in 6340 epoch, average loss: -55545.4375\n",
      "                , loss1: -5564.58671875\n",
      "                , loss2: 100.42693481445312\n",
      "=================================\n",
      "in 6350 epoch, average loss: -55606.95\n",
      "                , loss1: -5571.666015625\n",
      "                , loss2: 109.71778564453125\n",
      "=================================\n",
      "in 6360 epoch, average loss: -55766.225\n",
      "                , loss1: -5583.87890625\n",
      "                , loss2: 72.56205444335937\n",
      "=================================\n",
      "in 6370 epoch, average loss: -55758.55625\n",
      "                , loss1: -5583.247265625\n",
      "                , loss2: 73.92117919921876\n",
      "=================================\n",
      "in 6380 epoch, average loss: -55593.68125\n",
      "                , loss1: -5576.203125\n",
      "                , loss2: 168.34571533203126\n",
      "=================================\n",
      "in 6390 epoch, average loss: -55468.875\n",
      "                , loss1: -5559.163671875\n",
      "                , loss2: 122.7679443359375\n",
      "=================================\n",
      "in 6400 epoch, average loss: -55733.65\n",
      "                , loss1: -5581.627734375\n",
      "                , loss2: 82.6252197265625\n",
      "=================================\n",
      "in 6410 epoch, average loss: -55296.725\n",
      "                , loss1: -5552.9765625\n",
      "                , loss2: 233.0358642578125\n",
      "=================================\n",
      "in 6420 epoch, average loss: -55315.0875\n",
      "                , loss1: -5548.414453125\n",
      "                , loss2: 169.054443359375\n",
      "=================================\n",
      "in 6430 epoch, average loss: -55175.90625\n",
      "                , loss1: -5543.261328125\n",
      "                , loss2: 256.712451171875\n",
      "=================================\n",
      "in 6440 epoch, average loss: -55536.1625\n",
      "                , loss1: -5574.2046875\n",
      "                , loss2: 205.8878662109375\n",
      "=================================\n",
      "in 6450 epoch, average loss: -55392.3625\n",
      "                , loss1: -5567.538671875\n",
      "                , loss2: 283.03076171875\n",
      "=================================\n",
      "in 6460 epoch, average loss: -55598.98125\n",
      "                , loss1: -5575.19453125\n",
      "                , loss2: 152.97117919921874\n",
      "=================================\n",
      "in 6470 epoch, average loss: -55756.10625\n",
      "                , loss1: -5594.221875\n",
      "                , loss2: 186.1049560546875\n",
      "=================================\n",
      "in 6480 epoch, average loss: -55777.7875\n",
      "                , loss1: -5589.849609375\n",
      "                , loss2: 120.70736083984374\n",
      "=================================\n",
      "in 6490 epoch, average loss: -55952.975\n",
      "                , loss1: -5605.202734375\n",
      "                , loss2: 99.05331420898438\n",
      "=================================\n",
      "in 6500 epoch, average loss: -55763.15\n",
      "                , loss1: -5591.30546875\n",
      "                , loss2: 149.89833984375\n",
      "=================================\n",
      "in 6510 epoch, average loss: -56042.8875\n",
      "                , loss1: -5619.44375\n",
      "                , loss2: 151.54342041015624\n",
      "=================================\n",
      "in 6520 epoch, average loss: -55912.475\n",
      "                , loss1: -5598.44765625\n",
      "                , loss2: 72.00003662109376\n",
      "=================================\n",
      "in 6530 epoch, average loss: -55796.73125\n",
      "                , loss1: -5587.102734375\n",
      "                , loss2: 74.29930419921875\n",
      "=================================\n",
      "in 6540 epoch, average loss: -55910.04375\n",
      "                , loss1: -5608.7109375\n",
      "                , loss2: 177.0604736328125\n",
      "=================================\n",
      "in 6550 epoch, average loss: -55924.875\n",
      "                , loss1: -5609.637109375\n",
      "                , loss2: 171.4896728515625\n",
      "=================================\n",
      "in 6560 epoch, average loss: -55690.875\n",
      "                , loss1: -5585.988671875\n",
      "                , loss2: 169.00601806640626\n",
      "=================================\n",
      "in 6570 epoch, average loss: -55447.16875\n",
      "                , loss1: -5585.6078125\n",
      "                , loss2: 408.9095947265625\n",
      "=================================\n",
      "in 6580 epoch, average loss: -55341.41875\n",
      "                , loss1: -5559.346875\n",
      "                , loss2: 252.052294921875\n",
      "=================================\n",
      "in 6590 epoch, average loss: -55458.7125\n",
      "                , loss1: -5587.131640625\n",
      "                , loss2: 412.610009765625\n",
      "=================================\n",
      "in 6600 epoch, average loss: -55832.075\n",
      "                , loss1: -5598.14921875\n",
      "                , loss2: 149.419580078125\n",
      "=================================\n",
      "in 6610 epoch, average loss: -55839.18125\n",
      "                , loss1: -5607.9546875\n",
      "                , loss2: 240.3711181640625\n",
      "=================================\n",
      "in 6620 epoch, average loss: -55821.81875\n",
      "                , loss1: -5590.88046875\n",
      "                , loss2: 86.986083984375\n",
      "=================================\n",
      "in 6630 epoch, average loss: -55634.5\n",
      "                , loss1: -5590.927734375\n",
      "                , loss2: 274.7834716796875\n",
      "=================================\n",
      "in 6640 epoch, average loss: -55800.21875\n",
      "                , loss1: -5602.41796875\n",
      "                , loss2: 223.96328125\n",
      "=================================\n",
      "in 6650 epoch, average loss: -55613.7125\n",
      "                , loss1: -5584.5421875\n",
      "                , loss2: 231.7188232421875\n",
      "=================================\n",
      "in 6660 epoch, average loss: -55784.65625\n",
      "                , loss1: -5593.180078125\n",
      "                , loss2: 147.14510498046874\n",
      "=================================\n",
      "in 6670 epoch, average loss: -55945.9625\n",
      "                , loss1: -5608.601171875\n",
      "                , loss2: 140.0526123046875\n",
      "=================================\n",
      "in 6680 epoch, average loss: -55668.275\n",
      "                , loss1: -5586.489453125\n",
      "                , loss2: 196.62652587890625\n",
      "=================================\n",
      "in 6690 epoch, average loss: -56079.51875\n",
      "                , loss1: -5616.176171875\n",
      "                , loss2: 82.24293212890625\n",
      "=================================\n",
      "in 6700 epoch, average loss: -56051.28125\n",
      "                , loss1: -5614.09921875\n",
      "                , loss2: 89.71646728515626\n",
      "=================================\n",
      "in 6710 epoch, average loss: -55932.1\n",
      "                , loss1: -5607.061328125\n",
      "                , loss2: 138.516748046875\n",
      "=================================\n",
      "in 6720 epoch, average loss: -55986.1625\n",
      "                , loss1: -5607.7703125\n",
      "                , loss2: 91.5385009765625\n",
      "=================================\n",
      "in 6730 epoch, average loss: -56099.05625\n",
      "                , loss1: -5625.87421875\n",
      "                , loss2: 159.69359130859374\n",
      "=================================\n",
      "in 6740 epoch, average loss: -56017.3125\n",
      "                , loss1: -5615.437109375\n",
      "                , loss2: 137.059326171875\n",
      "=================================\n",
      "in 6750 epoch, average loss: -56279.9375\n",
      "                , loss1: -5641.6234375\n",
      "                , loss2: 136.296435546875\n",
      "=================================\n",
      "in 6760 epoch, average loss: -56014.80625\n",
      "                , loss1: -5610.038671875\n",
      "                , loss2: 85.580712890625\n",
      "=================================\n",
      "in 6770 epoch, average loss: -56171.55625\n",
      "                , loss1: -5623.882421875\n",
      "                , loss2: 67.2676513671875\n",
      "=================================\n",
      "in 6780 epoch, average loss: -55888.24375\n",
      "                , loss1: -5611.58671875\n",
      "                , loss2: 227.6259521484375\n",
      "=================================\n",
      "in 6790 epoch, average loss: -55806.125\n",
      "                , loss1: -5611.5265625\n",
      "                , loss2: 309.1449462890625\n",
      "=================================\n",
      "in 6800 epoch, average loss: -55742.1375\n",
      "                , loss1: -5600.53984375\n",
      "                , loss2: 263.260546875\n",
      "=================================\n",
      "in 6810 epoch, average loss: -56115.025\n",
      "                , loss1: -5629.016015625\n",
      "                , loss2: 175.1357421875\n",
      "=================================\n",
      "in 6820 epoch, average loss: -56056.6375\n",
      "                , loss1: -5631.167578125\n",
      "                , loss2: 255.0335205078125\n",
      "=================================\n",
      "in 6830 epoch, average loss: -56055.3625\n",
      "                , loss1: -5613.0109375\n",
      "                , loss2: 74.74985961914062\n",
      "=================================\n",
      "in 6840 epoch, average loss: -56152.59375\n",
      "                , loss1: -5631.56796875\n",
      "                , loss2: 163.08673095703125\n",
      "=================================\n",
      "in 6850 epoch, average loss: -56168.73125\n",
      "                , loss1: -5638.05390625\n",
      "                , loss2: 211.81142578125\n",
      "=================================\n",
      "in 6860 epoch, average loss: -55887.46875\n",
      "                , loss1: -5624.340625\n",
      "                , loss2: 355.9298095703125\n",
      "=================================\n",
      "in 6870 epoch, average loss: -56174.0375\n",
      "                , loss1: -5632.15859375\n",
      "                , loss2: 147.550048828125\n",
      "=================================\n",
      "in 6880 epoch, average loss: -56278.1875\n",
      "                , loss1: -5640.3828125\n",
      "                , loss2: 125.64619140625\n",
      "=================================\n",
      "in 6890 epoch, average loss: -56201.15\n",
      "                , loss1: -5632.262109375\n",
      "                , loss2: 121.4656494140625\n",
      "=================================\n",
      "in 6900 epoch, average loss: -56428.18125\n",
      "                , loss1: -5655.725\n",
      "                , loss2: 129.07265625\n",
      "=================================\n",
      "in 6910 epoch, average loss: -56119.925\n",
      "                , loss1: -5625.385546875\n",
      "                , loss2: 133.9272216796875\n",
      "=================================\n",
      "in 6920 epoch, average loss: -56127.5625\n",
      "                , loss1: -5634.469140625\n",
      "                , loss2: 217.1268798828125\n",
      "=================================\n",
      "in 6930 epoch, average loss: -56062.69375\n",
      "                , loss1: -5616.948828125\n",
      "                , loss2: 106.789794921875\n",
      "=================================\n",
      "in 6940 epoch, average loss: -56219.99375\n",
      "                , loss1: -5628.08203125\n",
      "                , loss2: 60.82464599609375\n",
      "=================================\n",
      "in 6950 epoch, average loss: -56359.73125\n",
      "                , loss1: -5640.23984375\n",
      "                , loss2: 42.670892333984376\n",
      "=================================\n",
      "in 6960 epoch, average loss: -56473.6125\n",
      "                , loss1: -5654.334375\n",
      "                , loss2: 69.7248779296875\n",
      "=================================\n",
      "in 6970 epoch, average loss: -56257.3875\n",
      "                , loss1: -5640.36953125\n",
      "                , loss2: 146.30899658203126\n",
      "=================================\n",
      "in 6980 epoch, average loss: -56269.7125\n",
      "                , loss1: -5632.112890625\n",
      "                , loss2: 51.416741943359376\n",
      "=================================\n",
      "in 6990 epoch, average loss: -56386.525\n",
      "                , loss1: -5654.56015625\n",
      "                , loss2: 159.07618408203126\n",
      "=================================\n",
      "in 7000 epoch, average loss: -56272.875\n",
      "                , loss1: -5643.105859375\n",
      "                , loss2: 158.18870849609374\n",
      "=================================\n",
      "in 7010 epoch, average loss: -56481.8875\n",
      "                , loss1: -5658.66640625\n",
      "                , loss2: 104.7832763671875\n",
      "=================================\n",
      "in 7020 epoch, average loss: -56228.94375\n",
      "                , loss1: -5643.615234375\n",
      "                , loss2: 207.2107666015625\n",
      "=================================\n",
      "in 7030 epoch, average loss: -56317.0625\n",
      "                , loss1: -5646.101953125\n",
      "                , loss2: 143.95302734375\n",
      "=================================\n",
      "in 7040 epoch, average loss: -56352.21875\n",
      "                , loss1: -5650.4953125\n",
      "                , loss2: 152.72635498046876\n",
      "=================================\n",
      "in 7050 epoch, average loss: -56438.775\n",
      "                , loss1: -5650.88359375\n",
      "                , loss2: 70.05949096679687\n",
      "=================================\n",
      "in 7060 epoch, average loss: -56737.0\n",
      "                , loss1: -5689.35859375\n",
      "                , loss2: 156.58533935546876\n",
      "=================================\n",
      "in 7070 epoch, average loss: -56669.475\n",
      "                , loss1: -5673.16640625\n",
      "                , loss2: 62.18992309570312\n",
      "=================================\n",
      "in 7080 epoch, average loss: -56765.825\n",
      "                , loss1: -5690.359765625\n",
      "                , loss2: 137.77464599609374\n",
      "=================================\n",
      "in 7090 epoch, average loss: -56601.7125\n",
      "                , loss1: -5677.432421875\n",
      "                , loss2: 172.61192626953124\n",
      "=================================\n",
      "in 7100 epoch, average loss: -56452.24375\n",
      "                , loss1: -5693.38984375\n",
      "                , loss2: 481.6564453125\n",
      "=================================\n",
      "in 7110 epoch, average loss: -56966.6\n",
      "                , loss1: -5716.5484375\n",
      "                , loss2: 198.8810791015625\n",
      "=================================\n",
      "in 7120 epoch, average loss: -57004.75625\n",
      "                , loss1: -5728.0421875\n",
      "                , loss2: 275.6663818359375\n",
      "=================================\n",
      "in 7130 epoch, average loss: -56989.44375\n",
      "                , loss1: -5727.471875\n",
      "                , loss2: 285.2700927734375\n",
      "=================================\n",
      "in 7140 epoch, average loss: -57032.86875\n",
      "                , loss1: -5730.275390625\n",
      "                , loss2: 269.888720703125\n",
      "=================================\n",
      "in 7150 epoch, average loss: -57243.69375\n",
      "                , loss1: -5738.27421875\n",
      "                , loss2: 139.0453125\n",
      "=================================\n",
      "in 7160 epoch, average loss: -57295.975\n",
      "                , loss1: -5743.76796875\n",
      "                , loss2: 141.71058349609376\n",
      "=================================\n",
      "in 7170 epoch, average loss: -57390.625\n",
      "                , loss1: -5749.721875\n",
      "                , loss2: 106.5968017578125\n",
      "=================================\n",
      "in 7180 epoch, average loss: -57460.69375\n",
      "                , loss1: -5754.97578125\n",
      "                , loss2: 89.06658935546875\n",
      "=================================\n",
      "in 7190 epoch, average loss: -57351.85625\n",
      "                , loss1: -5745.960546875\n",
      "                , loss2: 107.74730224609375\n",
      "=================================\n",
      "in 7200 epoch, average loss: -57422.49375\n",
      "                , loss1: -5754.0171875\n",
      "                , loss2: 117.6783935546875\n",
      "=================================\n",
      "in 7210 epoch, average loss: -57487.0\n",
      "                , loss1: -5760.403125\n",
      "                , loss2: 117.03349609375\n",
      "=================================\n",
      "in 7220 epoch, average loss: -57375.30625\n",
      "                , loss1: -5751.3578125\n",
      "                , loss2: 138.27576904296876\n",
      "=================================\n",
      "in 7230 epoch, average loss: -57302.1\n",
      "                , loss1: -5759.52734375\n",
      "                , loss2: 293.1738525390625\n",
      "=================================\n",
      "in 7240 epoch, average loss: -57438.69375\n",
      "                , loss1: -5751.177734375\n",
      "                , loss2: 73.08008422851563\n",
      "=================================\n",
      "in 7250 epoch, average loss: -57455.83125\n",
      "                , loss1: -5757.46796875\n",
      "                , loss2: 118.846484375\n",
      "=================================\n",
      "in 7260 epoch, average loss: -57155.8375\n",
      "                , loss1: -5744.318359375\n",
      "                , loss2: 287.3560791015625\n",
      "=================================\n",
      "in 7270 epoch, average loss: -57394.85\n",
      "                , loss1: -5757.0671875\n",
      "                , loss2: 175.8276611328125\n",
      "=================================\n",
      "in 7280 epoch, average loss: -56887.16875\n",
      "                , loss1: -5717.598046875\n",
      "                , loss2: 288.8076904296875\n",
      "=================================\n",
      "in 7290 epoch, average loss: -57158.31875\n",
      "                , loss1: -5739.7921875\n",
      "                , loss2: 239.605078125\n",
      "=================================\n",
      "in 7300 epoch, average loss: -57420.76875\n",
      "                , loss1: -5755.621484375\n",
      "                , loss2: 135.451806640625\n",
      "=================================\n",
      "in 7310 epoch, average loss: -57409.50625\n",
      "                , loss1: -5759.949609375\n",
      "                , loss2: 189.982958984375\n",
      "=================================\n",
      "in 7320 epoch, average loss: -57516.8\n",
      "                , loss1: -5763.5015625\n",
      "                , loss2: 118.20859375\n",
      "=================================\n",
      "in 7330 epoch, average loss: -57435.7625\n",
      "                , loss1: -5757.682421875\n",
      "                , loss2: 141.06005859375\n",
      "=================================\n",
      "in 7340 epoch, average loss: -57460.33125\n",
      "                , loss1: -5764.4703125\n",
      "                , loss2: 184.3683349609375\n",
      "=================================\n",
      "in 7350 epoch, average loss: -56841.13125\n",
      "                , loss1: -5730.356640625\n",
      "                , loss2: 462.433544921875\n",
      "=================================\n",
      "in 7360 epoch, average loss: -57301.64375\n",
      "                , loss1: -5756.523828125\n",
      "                , loss2: 263.5941162109375\n",
      "=================================\n",
      "in 7370 epoch, average loss: -57295.075\n",
      "                , loss1: -5756.95625\n",
      "                , loss2: 274.48740234375\n",
      "=================================\n",
      "in 7380 epoch, average loss: -57564.7625\n",
      "                , loss1: -5779.353125\n",
      "                , loss2: 228.761669921875\n",
      "=================================\n",
      "in 7390 epoch, average loss: -57516.45625\n",
      "                , loss1: -5775.19453125\n",
      "                , loss2: 235.4892822265625\n",
      "=================================\n",
      "in 7400 epoch, average loss: -57760.575\n",
      "                , loss1: -5781.718359375\n",
      "                , loss2: 56.60371704101563\n",
      "=================================\n",
      "in 7410 epoch, average loss: -57675.26875\n",
      "                , loss1: -5772.709375\n",
      "                , loss2: 51.8300048828125\n",
      "=================================\n",
      "in 7420 epoch, average loss: -57746.2125\n",
      "                , loss1: -5789.78125\n",
      "                , loss2: 151.59945068359374\n",
      "=================================\n",
      "in 7430 epoch, average loss: -57755.55625\n",
      "                , loss1: -5782.43671875\n",
      "                , loss2: 68.80497436523437\n",
      "=================================\n",
      "in 7440 epoch, average loss: -57665.7375\n",
      "                , loss1: -5780.15234375\n",
      "                , loss2: 135.782275390625\n",
      "=================================\n",
      "in 7450 epoch, average loss: -57851.85625\n",
      "                , loss1: -5791.46953125\n",
      "                , loss2: 62.8444580078125\n",
      "=================================\n",
      "in 7460 epoch, average loss: -57843.1\n",
      "                , loss1: -5787.954296875\n",
      "                , loss2: 36.442630004882815\n",
      "=================================\n",
      "in 7470 epoch, average loss: -57876.9875\n",
      "                , loss1: -5794.950390625\n",
      "                , loss2: 72.52317504882812\n",
      "=================================\n",
      "in 7480 epoch, average loss: -57893.85\n",
      "                , loss1: -5794.303515625\n",
      "                , loss2: 49.182778930664064\n",
      "=================================\n",
      "in 7490 epoch, average loss: -57825.3875\n",
      "                , loss1: -5791.076171875\n",
      "                , loss2: 85.3806640625\n",
      "=================================\n",
      "in 7500 epoch, average loss: -57823.2\n",
      "                , loss1: -5789.71875\n",
      "                , loss2: 73.9823486328125\n",
      "=================================\n",
      "in 7510 epoch, average loss: -57919.875\n",
      "                , loss1: -5795.190625\n",
      "                , loss2: 32.03245544433594\n",
      "=================================\n",
      "in 7520 epoch, average loss: -57883.21875\n",
      "                , loss1: -5791.133984375\n",
      "                , loss2: 28.117974853515626\n",
      "=================================\n",
      "in 7530 epoch, average loss: -57940.0625\n",
      "                , loss1: -5796.44453125\n",
      "                , loss2: 24.38260498046875\n",
      "=================================\n",
      "in 7540 epoch, average loss: -57934.18125\n",
      "                , loss1: -5798.10625\n",
      "                , loss2: 46.88172912597656\n",
      "=================================\n",
      "in 7550 epoch, average loss: -57933.54375\n",
      "                , loss1: -5799.35078125\n",
      "                , loss2: 59.96053466796875\n",
      "=================================\n",
      "in 7560 epoch, average loss: -57990.83125\n",
      "                , loss1: -5803.484375\n",
      "                , loss2: 44.01419677734375\n",
      "=================================\n",
      "in 7570 epoch, average loss: -57924.175\n",
      "                , loss1: -5800.280078125\n",
      "                , loss2: 78.62726440429688\n",
      "=================================\n",
      "in 7580 epoch, average loss: -57924.83125\n",
      "                , loss1: -5800.456640625\n",
      "                , loss2: 79.72708740234376\n",
      "=================================\n",
      "in 7590 epoch, average loss: -57783.55\n",
      "                , loss1: -5792.312890625\n",
      "                , loss2: 139.58057861328126\n",
      "=================================\n",
      "in 7600 epoch, average loss: -57751.04375\n",
      "                , loss1: -5783.2375\n",
      "                , loss2: 81.33218383789062\n",
      "=================================\n",
      "in 7610 epoch, average loss: -57940.94375\n",
      "                , loss1: -5801.914453125\n",
      "                , loss2: 78.1990966796875\n",
      "=================================\n",
      "in 7620 epoch, average loss: -57772.8125\n",
      "                , loss1: -5783.448046875\n",
      "                , loss2: 61.666046142578125\n",
      "=================================\n",
      "in 7630 epoch, average loss: -57888.26875\n",
      "                , loss1: -5801.56875\n",
      "                , loss2: 127.42166748046876\n",
      "=================================\n",
      "in 7640 epoch, average loss: -57778.61875\n",
      "                , loss1: -5781.001171875\n",
      "                , loss2: 31.392425537109375\n",
      "=================================\n",
      "in 7650 epoch, average loss: -57835.26875\n",
      "                , loss1: -5792.465234375\n",
      "                , loss2: 89.38015747070312\n",
      "=================================\n",
      "in 7660 epoch, average loss: -57733.21875\n",
      "                , loss1: -5784.71328125\n",
      "                , loss2: 113.90791015625\n",
      "=================================\n",
      "in 7670 epoch, average loss: -57841.45\n",
      "                , loss1: -5798.56953125\n",
      "                , loss2: 144.24375\n",
      "=================================\n",
      "in 7680 epoch, average loss: -57719.2875\n",
      "                , loss1: -5781.4875\n",
      "                , loss2: 95.58863525390625\n",
      "=================================\n",
      "in 7690 epoch, average loss: -57902.54375\n",
      "                , loss1: -5803.56796875\n",
      "                , loss2: 133.1306396484375\n",
      "=================================\n",
      "in 7700 epoch, average loss: -57844.86875\n",
      "                , loss1: -5791.52578125\n",
      "                , loss2: 70.38999633789062\n",
      "=================================\n",
      "in 7710 epoch, average loss: -57736.0375\n",
      "                , loss1: -5791.965234375\n",
      "                , loss2: 183.6163818359375\n",
      "=================================\n",
      "in 7720 epoch, average loss: -57884.725\n",
      "                , loss1: -5796.0421875\n",
      "                , loss2: 75.6998291015625\n",
      "=================================\n",
      "in 7730 epoch, average loss: -57893.20625\n",
      "                , loss1: -5793.84609375\n",
      "                , loss2: 45.256109619140624\n",
      "=================================\n",
      "in 7740 epoch, average loss: -57943.175\n",
      "                , loss1: -5804.66328125\n",
      "                , loss2: 103.45660400390625\n",
      "=================================\n",
      "in 7750 epoch, average loss: -57897.04375\n",
      "                , loss1: -5803.55390625\n",
      "                , loss2: 138.495947265625\n",
      "=================================\n",
      "in 7760 epoch, average loss: -57979.8875\n",
      "                , loss1: -5802.447265625\n",
      "                , loss2: 44.5856201171875\n",
      "=================================\n",
      "in 7770 epoch, average loss: -58048.16875\n",
      "                , loss1: -5813.19765625\n",
      "                , loss2: 83.80625\n",
      "=================================\n",
      "in 7780 epoch, average loss: -57993.825\n",
      "                , loss1: -5807.45859375\n",
      "                , loss2: 80.76875\n",
      "=================================\n",
      "in 7790 epoch, average loss: -57895.2\n",
      "                , loss1: -5792.74296875\n",
      "                , loss2: 32.22762451171875\n",
      "=================================\n",
      "in 7800 epoch, average loss: -57894.09375\n",
      "                , loss1: -5808.293359375\n",
      "                , loss2: 188.84293212890626\n",
      "=================================\n",
      "in 7810 epoch, average loss: -57850.58125\n",
      "                , loss1: -5795.36953125\n",
      "                , loss2: 103.11334228515625\n",
      "=================================\n",
      "in 7820 epoch, average loss: -57731.525\n",
      "                , loss1: -5790.6609375\n",
      "                , loss2: 175.087109375\n",
      "=================================\n",
      "in 7830 epoch, average loss: -57357.06875\n",
      "                , loss1: -5760.88984375\n",
      "                , loss2: 251.822216796875\n",
      "=================================\n",
      "in 7840 epoch, average loss: -57323.61875\n",
      "                , loss1: -5758.646875\n",
      "                , loss2: 262.8476318359375\n",
      "=================================\n",
      "in 7850 epoch, average loss: -57366.075\n",
      "                , loss1: -5753.67109375\n",
      "                , loss2: 170.631982421875\n",
      "=================================\n",
      "in 7860 epoch, average loss: -57483.54375\n",
      "                , loss1: -5782.3828125\n",
      "                , loss2: 340.279296875\n",
      "=================================\n",
      "in 7870 epoch, average loss: -57439.525\n",
      "                , loss1: -5768.13828125\n",
      "                , loss2: 241.8547119140625\n",
      "=================================\n",
      "in 7880 epoch, average loss: -57611.39375\n",
      "                , loss1: -5786.64765625\n",
      "                , loss2: 255.084716796875\n",
      "=================================\n",
      "in 7890 epoch, average loss: -57767.25\n",
      "                , loss1: -5789.93046875\n",
      "                , loss2: 132.06295166015624\n",
      "=================================\n",
      "in 7900 epoch, average loss: -57831.325\n",
      "                , loss1: -5792.236328125\n",
      "                , loss2: 91.03590698242188\n",
      "=================================\n",
      "in 7910 epoch, average loss: -57743.7\n",
      "                , loss1: -5796.37578125\n",
      "                , loss2: 220.0610107421875\n",
      "=================================\n",
      "in 7920 epoch, average loss: -57789.95625\n",
      "                , loss1: -5788.82265625\n",
      "                , loss2: 98.27579345703126\n",
      "=================================\n",
      "in 7930 epoch, average loss: -57772.25625\n",
      "                , loss1: -5790.10625\n",
      "                , loss2: 128.808544921875\n",
      "=================================\n",
      "in 7940 epoch, average loss: -57821.05625\n",
      "                , loss1: -5797.46953125\n",
      "                , loss2: 153.6403564453125\n",
      "=================================\n",
      "in 7950 epoch, average loss: -57846.775\n",
      "                , loss1: -5793.75234375\n",
      "                , loss2: 90.74371337890625\n",
      "=================================\n",
      "in 7960 epoch, average loss: -57757.7375\n",
      "                , loss1: -5794.61953125\n",
      "                , loss2: 188.4574951171875\n",
      "=================================\n",
      "in 7970 epoch, average loss: -57581.44375\n",
      "                , loss1: -5789.154296875\n",
      "                , loss2: 310.0982421875\n",
      "=================================\n",
      "in 7980 epoch, average loss: -57829.30625\n",
      "                , loss1: -5793.0296875\n",
      "                , loss2: 100.99077758789062\n",
      "=================================\n",
      "in 7990 epoch, average loss: -57892.8\n",
      "                , loss1: -5802.986328125\n",
      "                , loss2: 137.06595458984376\n",
      "=================================\n",
      "in 8000 epoch, average loss: -57872.03125\n",
      "                , loss1: -5798.420703125\n",
      "                , loss2: 112.17813720703126\n",
      "=================================\n",
      "in 8010 epoch, average loss: -57921.25\n",
      "                , loss1: -5798.773046875\n",
      "                , loss2: 66.47116088867188\n",
      "=================================\n",
      "in 8020 epoch, average loss: -57998.65\n",
      "                , loss1: -5809.42421875\n",
      "                , loss2: 95.5923095703125\n",
      "=================================\n",
      "in 8030 epoch, average loss: -58061.7125\n",
      "                , loss1: -5811.75234375\n",
      "                , loss2: 55.80314331054687\n",
      "=================================\n",
      "in 8040 epoch, average loss: -58012.46875\n",
      "                , loss1: -5811.887890625\n",
      "                , loss2: 106.40904541015625\n",
      "=================================\n",
      "in 8050 epoch, average loss: -57988.45\n",
      "                , loss1: -5810.06875\n",
      "                , loss2: 112.23408203125\n",
      "=================================\n",
      "in 8060 epoch, average loss: -57769.48125\n",
      "                , loss1: -5802.37265625\n",
      "                , loss2: 254.2467529296875\n",
      "=================================\n",
      "in 8070 epoch, average loss: -58022.51875\n",
      "                , loss1: -5812.814453125\n",
      "                , loss2: 105.6173095703125\n",
      "=================================\n",
      "in 8080 epoch, average loss: -57985.7625\n",
      "                , loss1: -5809.09921875\n",
      "                , loss2: 105.2395263671875\n",
      "=================================\n",
      "in 8090 epoch, average loss: -57822.3375\n",
      "                , loss1: -5808.998828125\n",
      "                , loss2: 267.6523193359375\n",
      "=================================\n",
      "in 8100 epoch, average loss: -57852.675\n",
      "                , loss1: -5801.998046875\n",
      "                , loss2: 167.303857421875\n",
      "=================================\n",
      "in 8110 epoch, average loss: -58025.09375\n",
      "                , loss1: -5814.983984375\n",
      "                , loss2: 124.74453125\n",
      "=================================\n",
      "in 8120 epoch, average loss: -57886.3875\n",
      "                , loss1: -5796.24453125\n",
      "                , loss2: 76.0593017578125\n",
      "=================================\n",
      "in 8130 epoch, average loss: -58069.625\n",
      "                , loss1: -5822.316796875\n",
      "                , loss2: 153.543212890625\n",
      "=================================\n",
      "in 8140 epoch, average loss: -58063.71875\n",
      "                , loss1: -5822.74453125\n",
      "                , loss2: 163.7260009765625\n",
      "=================================\n",
      "in 8150 epoch, average loss: -57901.3125\n",
      "                , loss1: -5807.95546875\n",
      "                , loss2: 178.2368896484375\n",
      "=================================\n",
      "in 8160 epoch, average loss: -57910.9125\n",
      "                , loss1: -5811.05234375\n",
      "                , loss2: 199.61160888671876\n",
      "=================================\n",
      "in 8170 epoch, average loss: -58000.91875\n",
      "                , loss1: -5811.01796875\n",
      "                , loss2: 109.26265869140624\n",
      "=================================\n",
      "in 8180 epoch, average loss: -57975.96875\n",
      "                , loss1: -5812.25703125\n",
      "                , loss2: 146.60220947265626\n",
      "=================================\n",
      "in 8190 epoch, average loss: -58025.71875\n",
      "                , loss1: -5811.398828125\n",
      "                , loss2: 88.2732177734375\n",
      "=================================\n",
      "in 8200 epoch, average loss: -57983.975\n",
      "                , loss1: -5808.483984375\n",
      "                , loss2: 100.86056518554688\n",
      "=================================\n",
      "in 8210 epoch, average loss: -57892.8625\n",
      "                , loss1: -5795.221875\n",
      "                , loss2: 59.35989990234375\n",
      "=================================\n",
      "in 8220 epoch, average loss: -58001.85625\n",
      "                , loss1: -5804.319921875\n",
      "                , loss2: 41.341705322265625\n",
      "=================================\n",
      "in 8230 epoch, average loss: -58081.95625\n",
      "                , loss1: -5813.3078125\n",
      "                , loss2: 51.12025451660156\n",
      "=================================\n",
      "in 8240 epoch, average loss: -57981.49375\n",
      "                , loss1: -5816.606640625\n",
      "                , loss2: 184.57056884765626\n",
      "=================================\n",
      "in 8250 epoch, average loss: -57920.43125\n",
      "                , loss1: -5803.37890625\n",
      "                , loss2: 113.358935546875\n",
      "=================================\n",
      "in 8260 epoch, average loss: -58054.625\n",
      "                , loss1: -5812.055078125\n",
      "                , loss2: 65.92993774414063\n",
      "=================================\n",
      "in 8270 epoch, average loss: -58093.1\n",
      "                , loss1: -5824.673046875\n",
      "                , loss2: 153.633984375\n",
      "=================================\n",
      "in 8280 epoch, average loss: -57896.3875\n",
      "                , loss1: -5802.88515625\n",
      "                , loss2: 132.47252197265624\n",
      "=================================\n",
      "in 8290 epoch, average loss: -57810.68125\n",
      "                , loss1: -5792.914453125\n",
      "                , loss2: 118.46663818359374\n",
      "=================================\n",
      "in 8300 epoch, average loss: -57183.4125\n",
      "                , loss1: -5769.38203125\n",
      "                , loss2: 510.405322265625\n",
      "=================================\n",
      "in 8310 epoch, average loss: -57859.2625\n",
      "                , loss1: -5802.40390625\n",
      "                , loss2: 164.77630615234375\n",
      "=================================\n",
      "in 8320 epoch, average loss: -57113.9625\n",
      "                , loss1: -5761.93359375\n",
      "                , loss2: 505.366748046875\n",
      "=================================\n",
      "in 8330 epoch, average loss: -57814.5875\n",
      "                , loss1: -5803.546484375\n",
      "                , loss2: 220.877392578125\n",
      "=================================\n",
      "in 8340 epoch, average loss: -57846.50625\n",
      "                , loss1: -5808.643359375\n",
      "                , loss2: 239.9324951171875\n",
      "=================================\n",
      "in 8350 epoch, average loss: -57901.2\n",
      "                , loss1: -5806.6015625\n",
      "                , loss2: 164.8129638671875\n",
      "=================================\n",
      "in 8360 epoch, average loss: -58001.925\n",
      "                , loss1: -5816.812890625\n",
      "                , loss2: 166.19945068359374\n",
      "=================================\n",
      "in 8370 epoch, average loss: -57997.0875\n",
      "                , loss1: -5807.154296875\n",
      "                , loss2: 74.44734497070313\n",
      "=================================\n",
      "in 8380 epoch, average loss: -58057.4625\n",
      "                , loss1: -5808.436328125\n",
      "                , loss2: 26.898956298828125\n",
      "=================================\n",
      "in 8390 epoch, average loss: -58037.5125\n",
      "                , loss1: -5808.80390625\n",
      "                , loss2: 50.52468566894531\n",
      "=================================\n",
      "in 8400 epoch, average loss: -58085.875\n",
      "                , loss1: -5819.731640625\n",
      "                , loss2: 111.4460693359375\n",
      "=================================\n",
      "in 8410 epoch, average loss: -58047.18125\n",
      "                , loss1: -5818.087109375\n",
      "                , loss2: 133.68966064453124\n",
      "=================================\n",
      "in 8420 epoch, average loss: -58131.99375\n",
      "                , loss1: -5818.303125\n",
      "                , loss2: 51.043603515625\n",
      "=================================\n",
      "in 8430 epoch, average loss: -58110.7875\n",
      "                , loss1: -5822.530859375\n",
      "                , loss2: 114.5283203125\n",
      "=================================\n",
      "in 8440 epoch, average loss: -57954.575\n",
      "                , loss1: -5813.24296875\n",
      "                , loss2: 177.8573486328125\n",
      "=================================\n",
      "in 8450 epoch, average loss: -58019.31875\n",
      "                , loss1: -5828.415625\n",
      "                , loss2: 264.8402099609375\n",
      "=================================\n",
      "in 8460 epoch, average loss: -57906.95625\n",
      "                , loss1: -5798.3765625\n",
      "                , loss2: 76.81422729492188\n",
      "=================================\n",
      "in 8470 epoch, average loss: -57932.83125\n",
      "                , loss1: -5818.984375\n",
      "                , loss2: 257.017236328125\n",
      "=================================\n",
      "in 8480 epoch, average loss: -58001.45\n",
      "                , loss1: -5811.253125\n",
      "                , loss2: 111.08367919921875\n",
      "=================================\n",
      "in 8490 epoch, average loss: -57919.80625\n",
      "                , loss1: -5801.1296875\n",
      "                , loss2: 91.49277954101562\n",
      "=================================\n",
      "in 8500 epoch, average loss: -58053.0625\n",
      "                , loss1: -5810.72890625\n",
      "                , loss2: 54.22349243164062\n",
      "=================================\n",
      "in 8510 epoch, average loss: -58094.4\n",
      "                , loss1: -5817.8609375\n",
      "                , loss2: 84.20387573242188\n",
      "=================================\n",
      "in 8520 epoch, average loss: -57987.19375\n",
      "                , loss1: -5813.09609375\n",
      "                , loss2: 143.76881103515626\n",
      "=================================\n",
      "in 8530 epoch, average loss: -57891.93125\n",
      "                , loss1: -5807.237109375\n",
      "                , loss2: 180.4340576171875\n",
      "=================================\n",
      "in 8540 epoch, average loss: -58088.73125\n",
      "                , loss1: -5819.0203125\n",
      "                , loss2: 101.47809448242188\n",
      "=================================\n",
      "in 8550 epoch, average loss: -58128.675\n",
      "                , loss1: -5821.11484375\n",
      "                , loss2: 82.47320556640625\n",
      "=================================\n",
      "in 8560 epoch, average loss: -58151.94375\n",
      "                , loss1: -5821.859765625\n",
      "                , loss2: 66.65443115234375\n",
      "=================================\n",
      "in 8570 epoch, average loss: -58137.03125\n",
      "                , loss1: -5817.725\n",
      "                , loss2: 40.219915771484374\n",
      "=================================\n",
      "in 8580 epoch, average loss: -58172.20625\n",
      "                , loss1: -5824.59921875\n",
      "                , loss2: 73.7865966796875\n",
      "=================================\n",
      "in 8590 epoch, average loss: -58210.69375\n",
      "                , loss1: -5829.014453125\n",
      "                , loss2: 79.45397338867187\n",
      "=================================\n",
      "in 8600 epoch, average loss: -58137.34375\n",
      "                , loss1: -5818.51171875\n",
      "                , loss2: 47.774993896484375\n",
      "=================================\n",
      "in 8610 epoch, average loss: -58216.71875\n",
      "                , loss1: -5825.68984375\n",
      "                , loss2: 40.178219604492185\n",
      "=================================\n",
      "in 8620 epoch, average loss: -58250.7125\n",
      "                , loss1: -5829.826953125\n",
      "                , loss2: 47.54835815429688\n",
      "=================================\n",
      "in 8630 epoch, average loss: -58187.4375\n",
      "                , loss1: -5826.2109375\n",
      "                , loss2: 74.67306518554688\n",
      "=================================\n",
      "in 8640 epoch, average loss: -58132.40625\n",
      "                , loss1: -5828.5109375\n",
      "                , loss2: 152.708056640625\n",
      "=================================\n",
      "in 8650 epoch, average loss: -58144.05\n",
      "                , loss1: -5817.0171875\n",
      "                , loss2: 26.1246826171875\n",
      "=================================\n",
      "in 8660 epoch, average loss: -58091.43125\n",
      "                , loss1: -5822.531640625\n",
      "                , loss2: 133.88533935546874\n",
      "=================================\n",
      "in 8670 epoch, average loss: -58172.325\n",
      "                , loss1: -5826.114453125\n",
      "                , loss2: 88.80859985351563\n",
      "=================================\n",
      "in 8680 epoch, average loss: -58150.69375\n",
      "                , loss1: -5824.46953125\n",
      "                , loss2: 94.00089721679687\n",
      "=================================\n",
      "in 8690 epoch, average loss: -58201.1375\n",
      "                , loss1: -5823.62265625\n",
      "                , loss2: 35.093658447265625\n",
      "=================================\n",
      "in 8700 epoch, average loss: -58238.95625\n",
      "                , loss1: -5826.325\n",
      "                , loss2: 24.293154907226562\n",
      "=================================\n",
      "in 8710 epoch, average loss: -58226.60625\n",
      "                , loss1: -5827.6828125\n",
      "                , loss2: 50.21822509765625\n",
      "=================================\n",
      "in 8720 epoch, average loss: -58134.4\n",
      "                , loss1: -5819.835546875\n",
      "                , loss2: 63.954315185546875\n",
      "=================================\n",
      "in 8730 epoch, average loss: -58187.1\n",
      "                , loss1: -5821.63125\n",
      "                , loss2: 29.210443115234376\n",
      "=================================\n",
      "in 8740 epoch, average loss: -58072.71875\n",
      "                , loss1: -5812.415234375\n",
      "                , loss2: 51.43552856445312\n",
      "=================================\n",
      "in 8750 epoch, average loss: -58054.49375\n",
      "                , loss1: -5820.935546875\n",
      "                , loss2: 154.8622314453125\n",
      "=================================\n",
      "in 8760 epoch, average loss: -58056.175\n",
      "                , loss1: -5813.525\n",
      "                , loss2: 79.07427368164062\n",
      "=================================\n",
      "in 8770 epoch, average loss: -58086.9\n",
      "                , loss1: -5820.7375\n",
      "                , loss2: 120.47525634765626\n",
      "=================================\n",
      "in 8780 epoch, average loss: -58030.1125\n",
      "                , loss1: -5811.378125\n",
      "                , loss2: 83.6690185546875\n",
      "=================================\n",
      "in 8790 epoch, average loss: -57972.2625\n",
      "                , loss1: -5806.8390625\n",
      "                , loss2: 96.12655639648438\n",
      "=================================\n",
      "in 8800 epoch, average loss: -58093.39375\n",
      "                , loss1: -5819.722265625\n",
      "                , loss2: 103.83363037109375\n",
      "=================================\n",
      "in 8810 epoch, average loss: -58140.9125\n",
      "                , loss1: -5828.539453125\n",
      "                , loss2: 144.487451171875\n",
      "=================================\n",
      "in 8820 epoch, average loss: -58101.2625\n",
      "                , loss1: -5818.266015625\n",
      "                , loss2: 81.40377197265624\n",
      "=================================\n",
      "in 8830 epoch, average loss: -58047.2125\n",
      "                , loss1: -5818.03515625\n",
      "                , loss2: 133.1412841796875\n",
      "=================================\n",
      "in 8840 epoch, average loss: -57909.4625\n",
      "                , loss1: -5818.140625\n",
      "                , loss2: 271.9450927734375\n",
      "=================================\n",
      "in 8850 epoch, average loss: -57971.375\n",
      "                , loss1: -5810.057421875\n",
      "                , loss2: 129.19786376953124\n",
      "=================================\n",
      "in 8860 epoch, average loss: -57795.70625\n",
      "                , loss1: -5801.521875\n",
      "                , loss2: 219.511572265625\n",
      "=================================\n",
      "in 8870 epoch, average loss: -57994.6125\n",
      "                , loss1: -5819.3765625\n",
      "                , loss2: 199.16046142578125\n",
      "=================================\n",
      "in 8880 epoch, average loss: -58124.71875\n",
      "                , loss1: -5826.820703125\n",
      "                , loss2: 143.481689453125\n",
      "=================================\n",
      "in 8890 epoch, average loss: -57809.325\n",
      "                , loss1: -5806.55390625\n",
      "                , loss2: 256.2064453125\n",
      "=================================\n",
      "in 8900 epoch, average loss: -57963.525\n",
      "                , loss1: -5821.38203125\n",
      "                , loss2: 250.2939453125\n",
      "=================================\n",
      "in 8910 epoch, average loss: -58096.5625\n",
      "                , loss1: -5819.23515625\n",
      "                , loss2: 95.78455200195313\n",
      "=================================\n",
      "in 8920 epoch, average loss: -58118.34375\n",
      "                , loss1: -5832.191015625\n",
      "                , loss2: 203.57213134765624\n",
      "=================================\n",
      "in 8930 epoch, average loss: -58151.7125\n",
      "                , loss1: -5829.033984375\n",
      "                , loss2: 138.6252197265625\n",
      "=================================\n",
      "in 8940 epoch, average loss: -58198.44375\n",
      "                , loss1: -5827.48828125\n",
      "                , loss2: 76.437841796875\n",
      "=================================\n",
      "in 8950 epoch, average loss: -58129.19375\n",
      "                , loss1: -5828.38125\n",
      "                , loss2: 154.61673583984376\n",
      "=================================\n",
      "in 8960 epoch, average loss: -58146.50625\n",
      "                , loss1: -5822.489453125\n",
      "                , loss2: 78.38671875\n",
      "=================================\n",
      "in 8970 epoch, average loss: -57925.34375\n",
      "                , loss1: -5802.315234375\n",
      "                , loss2: 97.80457763671875\n",
      "=================================\n",
      "in 8980 epoch, average loss: -57947.8\n",
      "                , loss1: -5812.41640625\n",
      "                , loss2: 176.36575927734376\n",
      "=================================\n",
      "in 8990 epoch, average loss: -58164.4375\n",
      "                , loss1: -5824.251171875\n",
      "                , loss2: 78.07432861328125\n",
      "=================================\n",
      "in 9000 epoch, average loss: -58185.1875\n",
      "                , loss1: -5823.05078125\n",
      "                , loss2: 45.31645812988281\n",
      "=================================\n",
      "in 9010 epoch, average loss: -58167.06875\n",
      "                , loss1: -5824.468359375\n",
      "                , loss2: 77.61920776367188\n",
      "=================================\n",
      "in 9020 epoch, average loss: -58117.6375\n",
      "                , loss1: -5822.807421875\n",
      "                , loss2: 110.43905029296874\n",
      "=================================\n",
      "in 9030 epoch, average loss: -57917.7625\n",
      "                , loss1: -5808.665234375\n",
      "                , loss2: 168.88597412109374\n",
      "=================================\n",
      "in 9040 epoch, average loss: -58098.16875\n",
      "                , loss1: -5824.586328125\n",
      "                , loss2: 147.69488525390625\n",
      "=================================\n",
      "in 9050 epoch, average loss: -58186.15\n",
      "                , loss1: -5826.984375\n",
      "                , loss2: 83.69564819335938\n",
      "=================================\n",
      "in 9060 epoch, average loss: -58037.56875\n",
      "                , loss1: -5812.34140625\n",
      "                , loss2: 85.84647827148437\n",
      "=================================\n",
      "in 9070 epoch, average loss: -58189.84375\n",
      "                , loss1: -5830.55390625\n",
      "                , loss2: 115.691796875\n",
      "=================================\n",
      "in 9080 epoch, average loss: -58217.6125\n",
      "                , loss1: -5827.6984375\n",
      "                , loss2: 59.36741333007812\n",
      "=================================\n",
      "in 9090 epoch, average loss: -58037.94375\n",
      "                , loss1: -5812.71875\n",
      "                , loss2: 89.24600830078126\n",
      "=================================\n",
      "in 9100 epoch, average loss: -57913.88125\n",
      "                , loss1: -5822.861328125\n",
      "                , loss2: 314.7307861328125\n",
      "=================================\n",
      "in 9110 epoch, average loss: -58179.29375\n",
      "                , loss1: -5825.13203125\n",
      "                , loss2: 72.0223876953125\n",
      "=================================\n",
      "in 9120 epoch, average loss: -58191.40625\n",
      "                , loss1: -5822.130078125\n",
      "                , loss2: 29.900588989257812\n",
      "=================================\n",
      "in 9130 epoch, average loss: -58209.0125\n",
      "                , loss1: -5834.40859375\n",
      "                , loss2: 135.0734130859375\n",
      "=================================\n",
      "in 9140 epoch, average loss: -58149.29375\n",
      "                , loss1: -5834.85390625\n",
      "                , loss2: 199.246435546875\n",
      "=================================\n",
      "in 9150 epoch, average loss: -58131.06875\n",
      "                , loss1: -5819.32109375\n",
      "                , loss2: 62.141717529296876\n",
      "=================================\n",
      "in 9160 epoch, average loss: -57959.925\n",
      "                , loss1: -5804.477734375\n",
      "                , loss2: 84.84954223632812\n",
      "=================================\n",
      "in 9170 epoch, average loss: -58094.81875\n",
      "                , loss1: -5820.56015625\n",
      "                , loss2: 110.77611083984375\n",
      "=================================\n",
      "in 9180 epoch, average loss: -58159.5375\n",
      "                , loss1: -5832.041796875\n",
      "                , loss2: 160.885498046875\n",
      "=================================\n",
      "in 9190 epoch, average loss: -58183.55625\n",
      "                , loss1: -5827.912109375\n",
      "                , loss2: 95.56716918945312\n",
      "=================================\n",
      "in 9200 epoch, average loss: -58209.25625\n",
      "                , loss1: -5841.84453125\n",
      "                , loss2: 209.190283203125\n",
      "=================================\n",
      "in 9210 epoch, average loss: -58101.6625\n",
      "                , loss1: -5816.6234375\n",
      "                , loss2: 64.5741943359375\n",
      "=================================\n",
      "in 9220 epoch, average loss: -58206.7\n",
      "                , loss1: -5828.367578125\n",
      "                , loss2: 76.97167358398437\n",
      "=================================\n",
      "in 9230 epoch, average loss: -58046.1\n",
      "                , loss1: -5820.10546875\n",
      "                , loss2: 154.96214599609374\n",
      "=================================\n",
      "in 9240 epoch, average loss: -57785.4875\n",
      "                , loss1: -5807.34296875\n",
      "                , loss2: 287.9389404296875\n",
      "=================================\n",
      "in 9250 epoch, average loss: -57962.19375\n",
      "                , loss1: -5817.9765625\n",
      "                , loss2: 217.5638916015625\n",
      "=================================\n",
      "in 9260 epoch, average loss: -57679.68125\n",
      "                , loss1: -5794.5734375\n",
      "                , loss2: 266.053857421875\n",
      "=================================\n",
      "in 9270 epoch, average loss: -57776.1\n",
      "                , loss1: -5814.10703125\n",
      "                , loss2: 364.972509765625\n",
      "=================================\n",
      "in 9280 epoch, average loss: -58008.05625\n",
      "                , loss1: -5819.10546875\n",
      "                , loss2: 182.99730224609374\n",
      "=================================\n",
      "in 9290 epoch, average loss: -57512.68125\n",
      "                , loss1: -5804.17265625\n",
      "                , loss2: 529.041552734375\n",
      "=================================\n",
      "in 9300 epoch, average loss: -57893.925\n",
      "                , loss1: -5811.4296875\n",
      "                , loss2: 220.3789794921875\n",
      "=================================\n",
      "in 9310 epoch, average loss: -57905.53125\n",
      "                , loss1: -5813.501171875\n",
      "                , loss2: 229.484228515625\n",
      "=================================\n",
      "in 9320 epoch, average loss: -58138.9\n",
      "                , loss1: -5819.990234375\n",
      "                , loss2: 60.99766845703125\n",
      "=================================\n",
      "in 9330 epoch, average loss: -58206.4875\n",
      "                , loss1: -5831.9671875\n",
      "                , loss2: 113.18914794921875\n",
      "=================================\n",
      "in 9340 epoch, average loss: -58227.63125\n",
      "                , loss1: -5830.9265625\n",
      "                , loss2: 81.63570556640624\n",
      "=================================\n",
      "in 9350 epoch, average loss: -58328.2\n",
      "                , loss1: -5836.337890625\n",
      "                , loss2: 35.18016662597656\n",
      "=================================\n",
      "in 9360 epoch, average loss: -58272.13125\n",
      "                , loss1: -5834.47109375\n",
      "                , loss2: 72.57333374023438\n",
      "=================================\n",
      "in 9370 epoch, average loss: -58238.0875\n",
      "                , loss1: -5826.78828125\n",
      "                , loss2: 29.800164794921876\n",
      "=================================\n",
      "in 9380 epoch, average loss: -58293.79375\n",
      "                , loss1: -5832.12734375\n",
      "                , loss2: 27.48139343261719\n",
      "=================================\n",
      "in 9390 epoch, average loss: -58290.5625\n",
      "                , loss1: -5834.369921875\n",
      "                , loss2: 53.13594970703125\n",
      "=================================\n",
      "in 9400 epoch, average loss: -58254.8625\n",
      "                , loss1: -5833.04453125\n",
      "                , loss2: 75.58650512695313\n",
      "=================================\n",
      "in 9410 epoch, average loss: -58192.775\n",
      "                , loss1: -5824.76328125\n",
      "                , loss2: 54.852972412109374\n",
      "=================================\n",
      "in 9420 epoch, average loss: -58060.1375\n",
      "                , loss1: -5816.267578125\n",
      "                , loss2: 102.53590087890625\n",
      "=================================\n",
      "in 9430 epoch, average loss: -58096.125\n",
      "                , loss1: -5829.330078125\n",
      "                , loss2: 197.17474365234375\n",
      "=================================\n",
      "in 9440 epoch, average loss: -58217.66875\n",
      "                , loss1: -5830.190625\n",
      "                , loss2: 84.2322509765625\n",
      "=================================\n",
      "in 9450 epoch, average loss: -58212.45\n",
      "                , loss1: -5824.353515625\n",
      "                , loss2: 31.08511962890625\n",
      "=================================\n",
      "in 9460 epoch, average loss: -58256.83125\n",
      "                , loss1: -5836.89765625\n",
      "                , loss2: 112.13973388671874\n",
      "=================================\n",
      "in 9470 epoch, average loss: -58250.03125\n",
      "                , loss1: -5836.459375\n",
      "                , loss2: 114.5609130859375\n",
      "=================================\n",
      "in 9480 epoch, average loss: -58214.55625\n",
      "                , loss1: -5832.100390625\n",
      "                , loss2: 106.4499755859375\n",
      "=================================\n",
      "in 9490 epoch, average loss: -58199.19375\n",
      "                , loss1: -5828.428125\n",
      "                , loss2: 85.08538208007812\n",
      "=================================\n",
      "in 9500 epoch, average loss: -58290.825\n",
      "                , loss1: -5833.483984375\n",
      "                , loss2: 44.023129272460935\n",
      "=================================\n",
      "in 9510 epoch, average loss: -58237.84375\n",
      "                , loss1: -5828.931640625\n",
      "                , loss2: 51.471484375\n",
      "=================================\n",
      "in 9520 epoch, average loss: -58220.8875\n",
      "                , loss1: -5835.226171875\n",
      "                , loss2: 131.380126953125\n",
      "=================================\n",
      "in 9530 epoch, average loss: -58283.33125\n",
      "                , loss1: -5834.81953125\n",
      "                , loss2: 64.87018432617188\n",
      "=================================\n",
      "in 9540 epoch, average loss: -58297.25625\n",
      "                , loss1: -5839.13828125\n",
      "                , loss2: 94.1302490234375\n",
      "=================================\n",
      "in 9550 epoch, average loss: -58081.1875\n",
      "                , loss1: -5822.79140625\n",
      "                , loss2: 146.72835693359374\n",
      "=================================\n",
      "in 9560 epoch, average loss: -58262.24375\n",
      "                , loss1: -5834.6203125\n",
      "                , loss2: 83.95794677734375\n",
      "=================================\n",
      "in 9570 epoch, average loss: -58111.65625\n",
      "                , loss1: -5819.108984375\n",
      "                , loss2: 79.43267211914062\n",
      "=================================\n",
      "in 9580 epoch, average loss: -58248.9875\n",
      "                , loss1: -5831.48515625\n",
      "                , loss2: 65.86315307617187\n",
      "=================================\n",
      "in 9590 epoch, average loss: -58141.08125\n",
      "                , loss1: -5822.21953125\n",
      "                , loss2: 81.12443237304687\n",
      "=================================\n",
      "in 9600 epoch, average loss: -58185.61875\n",
      "                , loss1: -5828.040234375\n",
      "                , loss2: 94.78937377929688\n",
      "=================================\n",
      "in 9610 epoch, average loss: -58132.2875\n",
      "                , loss1: -5817.70390625\n",
      "                , loss2: 44.751287841796874\n",
      "=================================\n",
      "in 9620 epoch, average loss: -58048.63125\n",
      "                , loss1: -5822.56015625\n",
      "                , loss2: 176.971923828125\n",
      "=================================\n",
      "in 9630 epoch, average loss: -57993.36875\n",
      "                , loss1: -5819.136328125\n",
      "                , loss2: 197.99737548828125\n",
      "=================================\n",
      "in 9640 epoch, average loss: -58084.65625\n",
      "                , loss1: -5821.02890625\n",
      "                , loss2: 125.636962890625\n",
      "=================================\n",
      "in 9650 epoch, average loss: -58026.59375\n",
      "                , loss1: -5817.78046875\n",
      "                , loss2: 151.20799560546874\n",
      "=================================\n",
      "in 9660 epoch, average loss: -58148.5625\n",
      "                , loss1: -5838.463671875\n",
      "                , loss2: 236.076025390625\n",
      "=================================\n",
      "in 9670 epoch, average loss: -58262.5375\n",
      "                , loss1: -5833.816796875\n",
      "                , loss2: 75.63394165039062\n",
      "=================================\n",
      "in 9680 epoch, average loss: -58190.625\n",
      "                , loss1: -5837.244921875\n",
      "                , loss2: 181.8179443359375\n",
      "=================================\n",
      "in 9690 epoch, average loss: -58195.575\n",
      "                , loss1: -5832.231640625\n",
      "                , loss2: 126.744677734375\n",
      "=================================\n",
      "in 9700 epoch, average loss: -58172.86875\n",
      "                , loss1: -5821.008984375\n",
      "                , loss2: 37.22083740234375\n",
      "=================================\n",
      "in 9710 epoch, average loss: -58230.2\n",
      "                , loss1: -5829.38046875\n",
      "                , loss2: 63.609552001953126\n",
      "=================================\n",
      "in 9720 epoch, average loss: -58204.625\n",
      "                , loss1: -5840.00703125\n",
      "                , loss2: 195.4430908203125\n",
      "=================================\n",
      "in 9730 epoch, average loss: -58259.35625\n",
      "                , loss1: -5840.05546875\n",
      "                , loss2: 141.19588623046874\n",
      "=================================\n",
      "in 9740 epoch, average loss: -58207.94375\n",
      "                , loss1: -5833.7109375\n",
      "                , loss2: 129.1609375\n",
      "=================================\n",
      "in 9750 epoch, average loss: -58190.40625\n",
      "                , loss1: -5840.328125\n",
      "                , loss2: 212.87783203125\n",
      "=================================\n",
      "in 9760 epoch, average loss: -58024.7875\n",
      "                , loss1: -5814.823828125\n",
      "                , loss2: 123.45498046875\n",
      "=================================\n",
      "in 9770 epoch, average loss: -57994.0625\n",
      "                , loss1: -5826.10546875\n",
      "                , loss2: 266.99375\n",
      "=================================\n",
      "in 9780 epoch, average loss: -58131.36875\n",
      "                , loss1: -5825.675390625\n",
      "                , loss2: 125.3868896484375\n",
      "=================================\n",
      "in 9790 epoch, average loss: -58167.75\n",
      "                , loss1: -5839.596484375\n",
      "                , loss2: 228.21416015625\n",
      "=================================\n",
      "in 9800 epoch, average loss: -58217.56875\n",
      "                , loss1: -5831.01875\n",
      "                , loss2: 92.61868286132812\n",
      "=================================\n",
      "in 9810 epoch, average loss: -58041.56875\n",
      "                , loss1: -5825.64609375\n",
      "                , loss2: 214.8844970703125\n",
      "=================================\n",
      "in 9820 epoch, average loss: -58141.08125\n",
      "                , loss1: -5836.925390625\n",
      "                , loss2: 228.1747802734375\n",
      "=================================\n",
      "in 9830 epoch, average loss: -58325.4\n",
      "                , loss1: -5835.409765625\n",
      "                , loss2: 28.697512817382812\n",
      "=================================\n",
      "in 9840 epoch, average loss: -58249.8125\n",
      "                , loss1: -5833.530859375\n",
      "                , loss2: 85.49227294921874\n",
      "=================================\n",
      "in 9850 epoch, average loss: -58195.41875\n",
      "                , loss1: -5834.465625\n",
      "                , loss2: 149.23812255859374\n",
      "=================================\n",
      "in 9860 epoch, average loss: -58355.19375\n",
      "                , loss1: -5841.71328125\n",
      "                , loss2: 61.931451416015626\n",
      "=================================\n",
      "in 9870 epoch, average loss: -58361.0\n",
      "                , loss1: -5838.377734375\n",
      "                , loss2: 22.77205810546875\n",
      "=================================\n",
      "in 9880 epoch, average loss: -58371.35\n",
      "                , loss1: -5839.92421875\n",
      "                , loss2: 27.899624633789063\n",
      "=================================\n",
      "in 9890 epoch, average loss: -58354.3\n",
      "                , loss1: -5843.612109375\n",
      "                , loss2: 81.8173828125\n",
      "=================================\n",
      "in 9900 epoch, average loss: -58316.6875\n",
      "                , loss1: -5837.8265625\n",
      "                , loss2: 61.58231811523437\n",
      "=================================\n",
      "in 9910 epoch, average loss: -58225.86875\n",
      "                , loss1: -5836.416015625\n",
      "                , loss2: 138.2978271484375\n",
      "=================================\n",
      "in 9920 epoch, average loss: -58226.9125\n",
      "                , loss1: -5843.05390625\n",
      "                , loss2: 203.627392578125\n",
      "=================================\n",
      "in 9930 epoch, average loss: -58330.29375\n",
      "                , loss1: -5839.242578125\n",
      "                , loss2: 62.13243408203125\n",
      "=================================\n",
      "in 9940 epoch, average loss: -58385.93125\n",
      "                , loss1: -5840.91953125\n",
      "                , loss2: 23.265017700195312\n",
      "=================================\n",
      "in 9950 epoch, average loss: -58269.7\n",
      "                , loss1: -5839.641015625\n",
      "                , loss2: 126.7069580078125\n",
      "=================================\n",
      "in 9960 epoch, average loss: -58350.2125\n",
      "                , loss1: -5841.4234375\n",
      "                , loss2: 64.01923217773438\n",
      "=================================\n",
      "in 9970 epoch, average loss: -58368.5625\n",
      "                , loss1: -5840.302734375\n",
      "                , loss2: 34.45535583496094\n",
      "=================================\n",
      "in 9980 epoch, average loss: -58230.5875\n",
      "                , loss1: -5832.75234375\n",
      "                , loss2: 96.9311279296875\n",
      "=================================\n",
      "in 9990 epoch, average loss: -58150.24375\n",
      "                , loss1: -5829.04921875\n",
      "                , loss2: 140.24840087890624\n",
      "=================================\n",
      "in 10000 epoch, average loss: -58274.925\n",
      "                , loss1: -5839.10390625\n",
      "                , loss2: 116.1185546875\n",
      "=================================\n",
      "in 10010 epoch, average loss: -58095.29375\n",
      "                , loss1: -5816.258203125\n",
      "                , loss2: 67.28870239257813\n",
      "=================================\n",
      "in 10020 epoch, average loss: -58130.375\n",
      "                , loss1: -5822.903515625\n",
      "                , loss2: 98.6647705078125\n",
      "=================================\n",
      "in 10030 epoch, average loss: -58196.8\n",
      "                , loss1: -5829.093359375\n",
      "                , loss2: 94.12740478515624\n",
      "=================================\n",
      "in 10040 epoch, average loss: -58303.6\n",
      "                , loss1: -5838.879296875\n",
      "                , loss2: 85.1902099609375\n",
      "=================================\n",
      "in 10050 epoch, average loss: -58316.58125\n",
      "                , loss1: -5833.9765625\n",
      "                , loss2: 23.187763977050782\n",
      "=================================\n",
      "in 10060 epoch, average loss: -58317.20625\n",
      "                , loss1: -5839.726171875\n",
      "                , loss2: 80.06260375976562\n",
      "=================================\n",
      "in 10070 epoch, average loss: -58309.70625\n",
      "                , loss1: -5841.578125\n",
      "                , loss2: 106.072265625\n",
      "=================================\n",
      "in 10080 epoch, average loss: -58257.54375\n",
      "                , loss1: -5831.31953125\n",
      "                , loss2: 55.64820556640625\n",
      "=================================\n",
      "in 10090 epoch, average loss: -58330.3\n",
      "                , loss1: -5835.9234375\n",
      "                , loss2: 28.93829345703125\n",
      "=================================\n",
      "in 10100 epoch, average loss: -58285.975\n",
      "                , loss1: -5835.901953125\n",
      "                , loss2: 73.04495239257812\n",
      "=================================\n",
      "in 10110 epoch, average loss: -58253.31875\n",
      "                , loss1: -5827.87578125\n",
      "                , loss2: 25.433531188964842\n",
      "=================================\n",
      "in 10120 epoch, average loss: -58312.05\n",
      "                , loss1: -5836.5109375\n",
      "                , loss2: 53.05953369140625\n",
      "=================================\n",
      "in 10130 epoch, average loss: -58228.575\n",
      "                , loss1: -5833.748828125\n",
      "                , loss2: 108.9127197265625\n",
      "=================================\n",
      "in 10140 epoch, average loss: -58174.79375\n",
      "                , loss1: -5838.437109375\n",
      "                , loss2: 209.5841796875\n",
      "=================================\n",
      "in 10150 epoch, average loss: -58280.55625\n",
      "                , loss1: -5834.38359375\n",
      "                , loss2: 63.27467041015625\n",
      "=================================\n",
      "in 10160 epoch, average loss: -58229.6\n",
      "                , loss1: -5835.248046875\n",
      "                , loss2: 122.88504638671876\n",
      "=================================\n",
      "in 10170 epoch, average loss: -58260.25625\n",
      "                , loss1: -5838.8015625\n",
      "                , loss2: 127.75556640625\n",
      "=================================\n",
      "in 10180 epoch, average loss: -58214.86875\n",
      "                , loss1: -5837.123046875\n",
      "                , loss2: 156.3623046875\n",
      "=================================\n",
      "in 10190 epoch, average loss: -58238.16875\n",
      "                , loss1: -5830.358203125\n",
      "                , loss2: 65.41658935546874\n",
      "=================================\n",
      "in 10200 epoch, average loss: -58237.7625\n",
      "                , loss1: -5835.941796875\n",
      "                , loss2: 121.6549560546875\n",
      "=================================\n",
      "in 10210 epoch, average loss: -58249.20625\n",
      "                , loss1: -5828.7640625\n",
      "                , loss2: 38.43088073730469\n",
      "=================================\n",
      "in 10220 epoch, average loss: -58228.75625\n",
      "                , loss1: -5829.55859375\n",
      "                , loss2: 66.83174438476563\n",
      "=================================\n",
      "in 10230 epoch, average loss: -58292.41875\n",
      "                , loss1: -5837.7921875\n",
      "                , loss2: 85.50706176757812\n",
      "=================================\n",
      "in 10240 epoch, average loss: -58272.575\n",
      "                , loss1: -5833.493359375\n",
      "                , loss2: 62.36202392578125\n",
      "=================================\n",
      "in 10250 epoch, average loss: -58290.84375\n",
      "                , loss1: -5837.431640625\n",
      "                , loss2: 83.47066040039063\n",
      "=================================\n",
      "in 10260 epoch, average loss: -58333.65625\n",
      "                , loss1: -5841.041015625\n",
      "                , loss2: 76.75679931640624\n",
      "=================================\n",
      "in 10270 epoch, average loss: -58283.15\n",
      "                , loss1: -5832.426953125\n",
      "                , loss2: 41.119659423828125\n",
      "=================================\n",
      "in 10280 epoch, average loss: -58238.55\n",
      "                , loss1: -5830.673046875\n",
      "                , loss2: 68.1848388671875\n",
      "=================================\n",
      "in 10290 epoch, average loss: -58341.0375\n",
      "                , loss1: -5844.1828125\n",
      "                , loss2: 100.7825927734375\n",
      "=================================\n",
      "in 10300 epoch, average loss: -58288.20625\n",
      "                , loss1: -5834.289453125\n",
      "                , loss2: 54.693426513671874\n",
      "=================================\n",
      "in 10310 epoch, average loss: -58347.725\n",
      "                , loss1: -5844.369921875\n",
      "                , loss2: 95.9784423828125\n",
      "=================================\n",
      "in 10320 epoch, average loss: -58389.21875\n",
      "                , loss1: -5841.759765625\n",
      "                , loss2: 28.374832153320312\n",
      "=================================\n",
      "in 10330 epoch, average loss: -58222.7625\n",
      "                , loss1: -5840.603125\n",
      "                , loss2: 183.27691650390625\n",
      "=================================\n",
      "in 10340 epoch, average loss: -58344.7\n",
      "                , loss1: -5843.8484375\n",
      "                , loss2: 93.78138427734375\n",
      "=================================\n",
      "in 10350 epoch, average loss: -58334.85\n",
      "                , loss1: -5842.205859375\n",
      "                , loss2: 87.21107177734375\n",
      "=================================\n",
      "in 10360 epoch, average loss: -58282.7875\n",
      "                , loss1: -5843.96015625\n",
      "                , loss2: 156.80948486328126\n",
      "=================================\n",
      "in 10370 epoch, average loss: -58064.36875\n",
      "                , loss1: -5828.486328125\n",
      "                , loss2: 220.4906982421875\n",
      "=================================\n",
      "in 10380 epoch, average loss: -58233.225\n",
      "                , loss1: -5840.10703125\n",
      "                , loss2: 167.84832763671875\n",
      "=================================\n",
      "in 10390 epoch, average loss: -58031.2625\n",
      "                , loss1: -5824.418359375\n",
      "                , loss2: 212.913671875\n",
      "=================================\n",
      "in 10400 epoch, average loss: -58285.175\n",
      "                , loss1: -5849.026171875\n",
      "                , loss2: 205.08798828125\n",
      "=================================\n",
      "in 10410 epoch, average loss: -58356.28125\n",
      "                , loss1: -5842.728125\n",
      "                , loss2: 71.0029296875\n",
      "=================================\n",
      "in 10420 epoch, average loss: -58340.96875\n",
      "                , loss1: -5844.85703125\n",
      "                , loss2: 107.59412841796875\n",
      "=================================\n",
      "in 10430 epoch, average loss: -58391.81875\n",
      "                , loss1: -5845.867578125\n",
      "                , loss2: 66.85020751953125\n",
      "=================================\n",
      "in 10440 epoch, average loss: -58348.225\n",
      "                , loss1: -5837.66484375\n",
      "                , loss2: 28.429794311523438\n",
      "=================================\n",
      "in 10450 epoch, average loss: -58400.2875\n",
      "                , loss1: -5843.82578125\n",
      "                , loss2: 37.96876831054688\n",
      "=================================\n",
      "in 10460 epoch, average loss: -58338.75\n",
      "                , loss1: -5847.567578125\n",
      "                , loss2: 136.9241455078125\n",
      "=================================\n",
      "in 10470 epoch, average loss: -58265.95625\n",
      "                , loss1: -5835.044140625\n",
      "                , loss2: 84.48146362304688\n",
      "=================================\n",
      "in 10480 epoch, average loss: -58016.1875\n",
      "                , loss1: -5814.70859375\n",
      "                , loss2: 130.902734375\n",
      "=================================\n",
      "in 10490 epoch, average loss: -58327.34375\n",
      "                , loss1: -5842.237890625\n",
      "                , loss2: 95.03937377929688\n",
      "=================================\n",
      "in 10500 epoch, average loss: -58274.475\n",
      "                , loss1: -5835.69453125\n",
      "                , loss2: 82.46328735351562\n",
      "=================================\n",
      "in 10510 epoch, average loss: -58256.00625\n",
      "                , loss1: -5838.70546875\n",
      "                , loss2: 131.04658203125\n",
      "=================================\n",
      "in 10520 epoch, average loss: -58282.7375\n",
      "                , loss1: -5842.630859375\n",
      "                , loss2: 143.56787109375\n",
      "=================================\n",
      "in 10530 epoch, average loss: -58344.99375\n",
      "                , loss1: -5841.325390625\n",
      "                , loss2: 68.25573120117187\n",
      "=================================\n",
      "in 10540 epoch, average loss: -58326.26875\n",
      "                , loss1: -5840.538671875\n",
      "                , loss2: 79.11923828125\n",
      "=================================\n",
      "in 10550 epoch, average loss: -58350.55625\n",
      "                , loss1: -5849.387109375\n",
      "                , loss2: 143.31348876953126\n",
      "=================================\n",
      "in 10560 epoch, average loss: -58345.90625\n",
      "                , loss1: -5841.556640625\n",
      "                , loss2: 69.65443115234375\n",
      "=================================\n",
      "in 10570 epoch, average loss: -58280.55\n",
      "                , loss1: -5841.091015625\n",
      "                , loss2: 130.36923828125\n",
      "=================================\n",
      "in 10580 epoch, average loss: -58309.0375\n",
      "                , loss1: -5844.80625\n",
      "                , loss2: 139.02498779296874\n",
      "=================================\n",
      "in 10590 epoch, average loss: -58280.51875\n",
      "                , loss1: -5838.226171875\n",
      "                , loss2: 101.7524658203125\n",
      "=================================\n",
      "in 10600 epoch, average loss: -58328.74375\n",
      "                , loss1: -5848.371484375\n",
      "                , loss2: 154.96650390625\n",
      "=================================\n",
      "in 10610 epoch, average loss: -58432.2625\n",
      "                , loss1: -5847.66796875\n",
      "                , loss2: 44.412908935546874\n",
      "=================================\n",
      "in 10620 epoch, average loss: -58093.15\n",
      "                , loss1: -5819.523046875\n",
      "                , loss2: 102.076123046875\n",
      "=================================\n",
      "in 10630 epoch, average loss: -58186.0125\n",
      "                , loss1: -5835.816015625\n",
      "                , loss2: 172.14755859375\n",
      "=================================\n",
      "in 10640 epoch, average loss: -58219.41875\n",
      "                , loss1: -5846.4390625\n",
      "                , loss2: 244.96552734375\n",
      "=================================\n",
      "in 10650 epoch, average loss: -58300.4875\n",
      "                , loss1: -5841.67421875\n",
      "                , loss2: 116.25733642578125\n",
      "=================================\n",
      "in 10660 epoch, average loss: -58372.8375\n",
      "                , loss1: -5843.3421875\n",
      "                , loss2: 60.58780517578125\n",
      "=================================\n",
      "in 10670 epoch, average loss: -58365.725\n",
      "                , loss1: -5847.405859375\n",
      "                , loss2: 108.3340087890625\n",
      "=================================\n",
      "in 10680 epoch, average loss: -58387.9\n",
      "                , loss1: -5847.531640625\n",
      "                , loss2: 87.41430053710937\n",
      "=================================\n",
      "in 10690 epoch, average loss: -58404.5375\n",
      "                , loss1: -5843.4375\n",
      "                , loss2: 29.82964172363281\n",
      "=================================\n",
      "in 10700 epoch, average loss: -58366.56875\n",
      "                , loss1: -5845.01015625\n",
      "                , loss2: 83.5315673828125\n",
      "=================================\n",
      "in 10710 epoch, average loss: -58391.66875\n",
      "                , loss1: -5849.355859375\n",
      "                , loss2: 101.88471069335938\n",
      "=================================\n",
      "in 10720 epoch, average loss: -58345.475\n",
      "                , loss1: -5838.08359375\n",
      "                , loss2: 35.363870239257814\n",
      "=================================\n",
      "in 10730 epoch, average loss: -58354.025\n",
      "                , loss1: -5841.5859375\n",
      "                , loss2: 61.83726806640625\n",
      "=================================\n",
      "in 10740 epoch, average loss: -58178.71875\n",
      "                , loss1: -5836.9828125\n",
      "                , loss2: 191.10926513671876\n",
      "=================================\n",
      "in 10750 epoch, average loss: -58264.275\n",
      "                , loss1: -5835.31875\n",
      "                , loss2: 88.9128662109375\n",
      "=================================\n",
      "in 10760 epoch, average loss: -58213.49375\n",
      "                , loss1: -5839.441015625\n",
      "                , loss2: 180.91744384765624\n",
      "=================================\n",
      "in 10770 epoch, average loss: -58283.2125\n",
      "                , loss1: -5844.406640625\n",
      "                , loss2: 160.85784912109375\n",
      "=================================\n",
      "in 10780 epoch, average loss: -58241.5\n",
      "                , loss1: -5839.4625\n",
      "                , loss2: 153.13026123046876\n",
      "=================================\n",
      "in 10790 epoch, average loss: -58149.10625\n",
      "                , loss1: -5830.85390625\n",
      "                , loss2: 159.42889404296875\n",
      "=================================\n",
      "in 10800 epoch, average loss: -58270.23125\n",
      "                , loss1: -5834.583984375\n",
      "                , loss2: 75.60709838867187\n",
      "=================================\n",
      "in 10810 epoch, average loss: -58134.90625\n",
      "                , loss1: -5822.4515625\n",
      "                , loss2: 89.61148681640626\n",
      "=================================\n",
      "in 10820 epoch, average loss: -58310.3\n",
      "                , loss1: -5846.7015625\n",
      "                , loss2: 156.713818359375\n",
      "=================================\n",
      "in 10830 epoch, average loss: -58357.5875\n",
      "                , loss1: -5844.853515625\n",
      "                , loss2: 90.95176391601562\n",
      "=================================\n",
      "in 10840 epoch, average loss: -58363.075\n",
      "                , loss1: -5845.08046875\n",
      "                , loss2: 87.72703247070312\n",
      "=================================\n",
      "in 10850 epoch, average loss: -58385.74375\n",
      "                , loss1: -5846.648046875\n",
      "                , loss2: 80.74003295898437\n",
      "=================================\n",
      "in 10860 epoch, average loss: -58374.25\n",
      "                , loss1: -5846.49140625\n",
      "                , loss2: 90.6624267578125\n",
      "=================================\n",
      "in 10870 epoch, average loss: -58429.56875\n",
      "                , loss1: -5848.0609375\n",
      "                , loss2: 51.03575439453125\n",
      "=================================\n",
      "in 10880 epoch, average loss: -58366.85625\n",
      "                , loss1: -5843.8453125\n",
      "                , loss2: 71.5999755859375\n",
      "=================================\n",
      "in 10890 epoch, average loss: -58427.38125\n",
      "                , loss1: -5850.418359375\n",
      "                , loss2: 76.80072021484375\n",
      "=================================\n",
      "in 10900 epoch, average loss: -58493.775\n",
      "                , loss1: -5854.618359375\n",
      "                , loss2: 52.4104736328125\n",
      "=================================\n",
      "in 10910 epoch, average loss: -58382.59375\n",
      "                , loss1: -5842.23984375\n",
      "                , loss2: 39.809689331054685\n",
      "=================================\n",
      "in 10920 epoch, average loss: -58319.34375\n",
      "                , loss1: -5836.96953125\n",
      "                , loss2: 50.35395202636719\n",
      "=================================\n",
      "in 10930 epoch, average loss: -58315.94375\n",
      "                , loss1: -5838.559375\n",
      "                , loss2: 69.646923828125\n",
      "=================================\n",
      "in 10940 epoch, average loss: -58435.14375\n",
      "                , loss1: -5849.018359375\n",
      "                , loss2: 55.033013916015626\n",
      "=================================\n",
      "in 10950 epoch, average loss: -58360.68125\n",
      "                , loss1: -5841.881640625\n",
      "                , loss2: 58.1259521484375\n",
      "=================================\n",
      "in 10960 epoch, average loss: -58453.65\n",
      "                , loss1: -5848.885546875\n",
      "                , loss2: 35.20481567382812\n",
      "=================================\n",
      "in 10970 epoch, average loss: -58326.65625\n",
      "                , loss1: -5856.1796875\n",
      "                , loss2: 235.15078125\n",
      "=================================\n",
      "in 10980 epoch, average loss: -58316.41875\n",
      "                , loss1: -5835.044921875\n",
      "                , loss2: 34.034793090820315\n",
      "=================================\n",
      "in 10990 epoch, average loss: -58297.3375\n",
      "                , loss1: -5840.473046875\n",
      "                , loss2: 107.39202880859375\n",
      "=================================\n",
      "in 11000 epoch, average loss: -58254.15625\n",
      "                , loss1: -5842.5328125\n",
      "                , loss2: 171.164794921875\n",
      "=================================\n",
      "in 11010 epoch, average loss: -58179.9375\n",
      "                , loss1: -5838.06875\n",
      "                , loss2: 200.75408935546875\n",
      "=================================\n",
      "in 11020 epoch, average loss: -58366.9375\n",
      "                , loss1: -5847.26328125\n",
      "                , loss2: 105.703564453125\n",
      "=================================\n",
      "in 11030 epoch, average loss: -58215.84375\n",
      "                , loss1: -5836.9546875\n",
      "                , loss2: 153.70443115234374\n",
      "=================================\n",
      "in 11040 epoch, average loss: -58341.61875\n",
      "                , loss1: -5843.41640625\n",
      "                , loss2: 92.54269409179688\n",
      "=================================\n",
      "in 11050 epoch, average loss: -58381.675\n",
      "                , loss1: -5840.404296875\n",
      "                , loss2: 22.369203186035158\n",
      "=================================\n",
      "in 11060 epoch, average loss: -58428.78125\n",
      "                , loss1: -5849.839453125\n",
      "                , loss2: 69.61118774414062\n",
      "=================================\n",
      "in 11070 epoch, average loss: -58474.13125\n",
      "                , loss1: -5852.524609375\n",
      "                , loss2: 51.11351318359375\n",
      "=================================\n",
      "in 11080 epoch, average loss: -58258.98125\n",
      "                , loss1: -5837.34140625\n",
      "                , loss2: 114.43326416015626\n",
      "=================================\n",
      "in 11090 epoch, average loss: -58216.69375\n",
      "                , loss1: -5837.132421875\n",
      "                , loss2: 154.62928466796876\n",
      "=================================\n",
      "in 11100 epoch, average loss: -58108.275\n",
      "                , loss1: -5842.08671875\n",
      "                , loss2: 312.59140625\n",
      "=================================\n",
      "in 11110 epoch, average loss: -58160.4\n",
      "                , loss1: -5831.475\n",
      "                , loss2: 154.3444580078125\n",
      "=================================\n",
      "in 11120 epoch, average loss: -58357.25\n",
      "                , loss1: -5845.659765625\n",
      "                , loss2: 99.34552612304688\n",
      "=================================\n",
      "in 11130 epoch, average loss: -58376.3875\n",
      "                , loss1: -5846.20546875\n",
      "                , loss2: 85.66759033203125\n",
      "=================================\n",
      "in 11140 epoch, average loss: -58407.5375\n",
      "                , loss1: -5854.910546875\n",
      "                , loss2: 141.57171630859375\n",
      "=================================\n",
      "in 11150 epoch, average loss: -58456.83125\n",
      "                , loss1: -5850.154296875\n",
      "                , loss2: 44.70655212402344\n",
      "=================================\n",
      "in 11160 epoch, average loss: -58427.51875\n",
      "                , loss1: -5845.425390625\n",
      "                , loss2: 26.73670654296875\n",
      "=================================\n",
      "in 11170 epoch, average loss: -58448.70625\n",
      "                , loss1: -5849.575\n",
      "                , loss2: 47.03321533203125\n",
      "=================================\n",
      "in 11180 epoch, average loss: -58338.78125\n",
      "                , loss1: -5843.74765625\n",
      "                , loss2: 98.69262084960937\n",
      "=================================\n",
      "in 11190 epoch, average loss: -58234.975\n",
      "                , loss1: -5835.553125\n",
      "                , loss2: 120.5521728515625\n",
      "=================================\n",
      "in 11200 epoch, average loss: -58388.8125\n",
      "                , loss1: -5849.242578125\n",
      "                , loss2: 103.61572265625\n",
      "=================================\n",
      "in 11210 epoch, average loss: -58281.31875\n",
      "                , loss1: -5837.615234375\n",
      "                , loss2: 94.83811645507812\n",
      "=================================\n",
      "in 11220 epoch, average loss: -58405.39375\n",
      "                , loss1: -5842.56953125\n",
      "                , loss2: 20.300582885742188\n",
      "=================================\n",
      "in 11230 epoch, average loss: -58414.89375\n",
      "                , loss1: -5844.32734375\n",
      "                , loss2: 28.374057006835937\n",
      "=================================\n",
      "in 11240 epoch, average loss: -58307.5625\n",
      "                , loss1: -5850.43671875\n",
      "                , loss2: 196.8015869140625\n",
      "=================================\n",
      "in 11250 epoch, average loss: -58398.29375\n",
      "                , loss1: -5846.533984375\n",
      "                , loss2: 67.044921875\n",
      "=================================\n",
      "in 11260 epoch, average loss: -58472.39375\n",
      "                , loss1: -5849.19296875\n",
      "                , loss2: 19.534268188476563\n",
      "=================================\n",
      "in 11270 epoch, average loss: -58480.95\n",
      "                , loss1: -5852.48203125\n",
      "                , loss2: 43.866268920898435\n",
      "=================================\n",
      "in 11280 epoch, average loss: -58384.025\n",
      "                , loss1: -5851.38984375\n",
      "                , loss2: 129.87420654296875\n",
      "=================================\n",
      "in 11290 epoch, average loss: -58383.45\n",
      "                , loss1: -5852.133203125\n",
      "                , loss2: 137.88316650390624\n",
      "=================================\n",
      "in 11300 epoch, average loss: -58379.24375\n",
      "                , loss1: -5845.51640625\n",
      "                , loss2: 75.91543579101562\n",
      "=================================\n",
      "in 11310 epoch, average loss: -58249.59375\n",
      "                , loss1: -5838.021875\n",
      "                , loss2: 130.62308349609376\n",
      "=================================\n",
      "in 11320 epoch, average loss: -58459.575\n",
      "                , loss1: -5854.157421875\n",
      "                , loss2: 81.99700927734375\n",
      "=================================\n",
      "in 11330 epoch, average loss: -58507.96875\n",
      "                , loss1: -5855.62734375\n",
      "                , loss2: 48.29886169433594\n",
      "=================================\n",
      "in 11340 epoch, average loss: -58463.65\n",
      "                , loss1: -5851.42109375\n",
      "                , loss2: 50.5616455078125\n",
      "=================================\n",
      "in 11350 epoch, average loss: -58393.65\n",
      "                , loss1: -5851.186328125\n",
      "                , loss2: 118.20911865234375\n",
      "=================================\n",
      "in 11360 epoch, average loss: -58486.95625\n",
      "                , loss1: -5851.7125\n",
      "                , loss2: 30.17034912109375\n",
      "=================================\n",
      "in 11370 epoch, average loss: -58462.2\n",
      "                , loss1: -5848.80859375\n",
      "                , loss2: 25.885736083984376\n",
      "=================================\n",
      "in 11380 epoch, average loss: -58347.0375\n",
      "                , loss1: -5843.213671875\n",
      "                , loss2: 85.1001220703125\n",
      "=================================\n",
      "in 11390 epoch, average loss: -58436.45625\n",
      "                , loss1: -5851.271484375\n",
      "                , loss2: 76.256640625\n",
      "=================================\n",
      "in 11400 epoch, average loss: -58367.63125\n",
      "                , loss1: -5843.656640625\n",
      "                , loss2: 68.93328247070312\n",
      "=================================\n",
      "in 11410 epoch, average loss: -58264.375\n",
      "                , loss1: -5836.73203125\n",
      "                , loss2: 102.9377685546875\n",
      "=================================\n",
      "in 11420 epoch, average loss: -58334.5375\n",
      "                , loss1: -5848.836328125\n",
      "                , loss2: 153.82647705078125\n",
      "=================================\n",
      "in 11430 epoch, average loss: -58440.59375\n",
      "                , loss1: -5848.891796875\n",
      "                , loss2: 48.32142028808594\n",
      "=================================\n",
      "in 11440 epoch, average loss: -58245.5875\n",
      "                , loss1: -5843.87421875\n",
      "                , loss2: 193.15234375\n",
      "=================================\n",
      "in 11450 epoch, average loss: -58149.05\n",
      "                , loss1: -5823.059375\n",
      "                , loss2: 81.54508056640626\n",
      "=================================\n",
      "in 11460 epoch, average loss: -58223.05\n",
      "                , loss1: -5832.879296875\n",
      "                , loss2: 105.73939208984375\n",
      "=================================\n",
      "in 11470 epoch, average loss: -58306.2\n",
      "                , loss1: -5836.309375\n",
      "                , loss2: 56.89964599609375\n",
      "=================================\n",
      "in 11480 epoch, average loss: -58414.03125\n",
      "                , loss1: -5853.08125\n",
      "                , loss2: 116.77603759765626\n",
      "=================================\n",
      "in 11490 epoch, average loss: -58480.2\n",
      "                , loss1: -5852.55\n",
      "                , loss2: 45.295022583007814\n",
      "=================================\n",
      "in 11500 epoch, average loss: -58309.40625\n",
      "                , loss1: -5849.550390625\n",
      "                , loss2: 186.0929931640625\n",
      "=================================\n",
      "in 11510 epoch, average loss: -58258.825\n",
      "                , loss1: -5842.237109375\n",
      "                , loss2: 163.5463134765625\n",
      "=================================\n",
      "in 11520 epoch, average loss: -58366.5625\n",
      "                , loss1: -5840.6703125\n",
      "                , loss2: 40.13576965332031\n",
      "=================================\n",
      "in 11530 epoch, average loss: -58432.51875\n",
      "                , loss1: -5848.92890625\n",
      "                , loss2: 56.770880126953124\n",
      "=================================\n",
      "in 11540 epoch, average loss: -58509.64375\n",
      "                , loss1: -5855.48515625\n",
      "                , loss2: 45.21021728515625\n",
      "=================================\n",
      "in 11550 epoch, average loss: -58478.9625\n",
      "                , loss1: -5853.843359375\n",
      "                , loss2: 59.468572998046874\n",
      "=================================\n",
      "in 11560 epoch, average loss: -58515.50625\n",
      "                , loss1: -5857.64453125\n",
      "                , loss2: 60.94105834960938\n",
      "=================================\n",
      "in 11570 epoch, average loss: -58365.65\n",
      "                , loss1: -5848.833203125\n",
      "                , loss2: 122.66959228515626\n",
      "=================================\n",
      "in 11580 epoch, average loss: -58304.3375\n",
      "                , loss1: -5852.83359375\n",
      "                , loss2: 223.9897216796875\n",
      "=================================\n",
      "in 11590 epoch, average loss: -58445.88125\n",
      "                , loss1: -5849.000390625\n",
      "                , loss2: 44.12471008300781\n",
      "=================================\n",
      "in 11600 epoch, average loss: -58450.4375\n",
      "                , loss1: -5858.359765625\n",
      "                , loss2: 133.1634765625\n",
      "=================================\n",
      "in 11610 epoch, average loss: -58488.8875\n",
      "                , loss1: -5856.139453125\n",
      "                , loss2: 72.51392822265625\n",
      "=================================\n",
      "in 11620 epoch, average loss: -58453.96875\n",
      "                , loss1: -5851.923828125\n",
      "                , loss2: 65.2697998046875\n",
      "=================================\n",
      "in 11630 epoch, average loss: -58408.35\n",
      "                , loss1: -5848.1546875\n",
      "                , loss2: 73.1910888671875\n",
      "=================================\n",
      "in 11640 epoch, average loss: -58441.2\n",
      "                , loss1: -5853.321484375\n",
      "                , loss2: 92.00653076171875\n",
      "=================================\n",
      "in 11650 epoch, average loss: -58243.375\n",
      "                , loss1: -5836.912890625\n",
      "                , loss2: 125.747607421875\n",
      "=================================\n",
      "in 11660 epoch, average loss: -58372.4125\n",
      "                , loss1: -5852.0234375\n",
      "                , loss2: 147.82896728515624\n",
      "=================================\n",
      "in 11670 epoch, average loss: -58502.61875\n",
      "                , loss1: -5855.75859375\n",
      "                , loss2: 54.9677490234375\n",
      "=================================\n",
      "in 11680 epoch, average loss: -58478.7875\n",
      "                , loss1: -5851.513671875\n",
      "                , loss2: 36.355157470703126\n",
      "=================================\n",
      "in 11690 epoch, average loss: -58252.69375\n",
      "                , loss1: -5852.764453125\n",
      "                , loss2: 274.9581787109375\n",
      "=================================\n",
      "in 11700 epoch, average loss: -58449.35\n",
      "                , loss1: -5851.414453125\n",
      "                , loss2: 64.7942138671875\n",
      "=================================\n",
      "in 11710 epoch, average loss: -58480.6625\n",
      "                , loss1: -5854.40234375\n",
      "                , loss2: 63.359814453125\n",
      "=================================\n",
      "in 11720 epoch, average loss: -58553.275\n",
      "                , loss1: -5861.73515625\n",
      "                , loss2: 64.07893676757813\n",
      "=================================\n",
      "in 11730 epoch, average loss: -58481.69375\n",
      "                , loss1: -5853.31015625\n",
      "                , loss2: 51.40712890625\n",
      "=================================\n",
      "in 11740 epoch, average loss: -58316.84375\n",
      "                , loss1: -5846.596875\n",
      "                , loss2: 149.128271484375\n",
      "=================================\n",
      "in 11750 epoch, average loss: -58502.275\n",
      "                , loss1: -5856.7484375\n",
      "                , loss2: 65.20450439453126\n",
      "=================================\n",
      "in 11760 epoch, average loss: -58517.85625\n",
      "                , loss1: -5854.62734375\n",
      "                , loss2: 28.425271606445314\n",
      "=================================\n",
      "in 11770 epoch, average loss: -58424.5875\n",
      "                , loss1: -5852.168359375\n",
      "                , loss2: 97.10079956054688\n",
      "=================================\n",
      "in 11780 epoch, average loss: -57630.9125\n",
      "                , loss1: -5812.156640625\n",
      "                , loss2: 490.651904296875\n",
      "=================================\n",
      "in 11790 epoch, average loss: -58257.78125\n",
      "                , loss1: -5839.76875\n",
      "                , loss2: 139.9019287109375\n",
      "=================================\n",
      "in 11800 epoch, average loss: -58425.9375\n",
      "                , loss1: -5849.58671875\n",
      "                , loss2: 69.9387451171875\n",
      "=================================\n",
      "in 11810 epoch, average loss: -58517.8625\n",
      "                , loss1: -5856.96484375\n",
      "                , loss2: 51.78867797851562\n",
      "=================================\n",
      "in 11820 epoch, average loss: -58447.2375\n",
      "                , loss1: -5855.11328125\n",
      "                , loss2: 103.8982177734375\n",
      "=================================\n",
      "in 11830 epoch, average loss: -58492.425\n",
      "                , loss1: -5857.497265625\n",
      "                , loss2: 82.555029296875\n",
      "=================================\n",
      "in 11840 epoch, average loss: -58430.35625\n",
      "                , loss1: -5849.10078125\n",
      "                , loss2: 60.65118408203125\n",
      "=================================\n",
      "in 11850 epoch, average loss: -58472.91875\n",
      "                , loss1: -5858.10078125\n",
      "                , loss2: 108.08660888671875\n",
      "=================================\n",
      "in 11860 epoch, average loss: -58493.34375\n",
      "                , loss1: -5854.840625\n",
      "                , loss2: 55.066357421875\n",
      "=================================\n",
      "in 11870 epoch, average loss: -58438.5125\n",
      "                , loss1: -5858.398046875\n",
      "                , loss2: 145.46781005859376\n",
      "=================================\n",
      "in 11880 epoch, average loss: -58539.1125\n",
      "                , loss1: -5858.84453125\n",
      "                , loss2: 49.3399169921875\n",
      "=================================\n",
      "in 11890 epoch, average loss: -58471.6875\n",
      "                , loss1: -5854.19375\n",
      "                , loss2: 70.24664916992188\n",
      "=================================\n",
      "in 11900 epoch, average loss: -58508.1625\n",
      "                , loss1: -5865.7296875\n",
      "                , loss2: 149.130126953125\n",
      "=================================\n",
      "in 11910 epoch, average loss: -58514.0375\n",
      "                , loss1: -5862.838671875\n",
      "                , loss2: 114.35018310546874\n",
      "=================================\n",
      "in 11920 epoch, average loss: -58453.9125\n",
      "                , loss1: -5852.376953125\n",
      "                , loss2: 69.86365356445313\n",
      "=================================\n",
      "in 11930 epoch, average loss: -58428.95\n",
      "                , loss1: -5856.9234375\n",
      "                , loss2: 140.2883056640625\n",
      "=================================\n",
      "in 11940 epoch, average loss: -58341.325\n",
      "                , loss1: -5848.926953125\n",
      "                , loss2: 147.94256591796875\n",
      "=================================\n",
      "in 11950 epoch, average loss: -58398.9125\n",
      "                , loss1: -5847.74453125\n",
      "                , loss2: 78.52894897460938\n",
      "=================================\n",
      "in 11960 epoch, average loss: -58359.275\n",
      "                , loss1: -5847.880859375\n",
      "                , loss2: 119.53160400390625\n",
      "=================================\n",
      "in 11970 epoch, average loss: -58390.16875\n",
      "                , loss1: -5850.00859375\n",
      "                , loss2: 109.91422119140626\n",
      "=================================\n",
      "in 11980 epoch, average loss: -58428.19375\n",
      "                , loss1: -5855.621484375\n",
      "                , loss2: 128.02415771484374\n",
      "=================================\n",
      "in 11990 epoch, average loss: -58428.54375\n",
      "                , loss1: -5851.690625\n",
      "                , loss2: 88.35654296875\n",
      "=================================\n",
      "in 12000 epoch, average loss: -58359.74375\n",
      "                , loss1: -5848.228125\n",
      "                , loss2: 122.53367919921875\n",
      "=================================\n",
      "in 12010 epoch, average loss: -58289.7375\n",
      "                , loss1: -5839.698046875\n",
      "                , loss2: 107.24775390625\n",
      "=================================\n",
      "in 12020 epoch, average loss: -58448.73125\n",
      "                , loss1: -5851.04375\n",
      "                , loss2: 61.706005859375\n",
      "=================================\n",
      "in 12030 epoch, average loss: -58460.8125\n",
      "                , loss1: -5852.383984375\n",
      "                , loss2: 63.0228271484375\n",
      "=================================\n",
      "in 12040 epoch, average loss: -58356.25\n",
      "                , loss1: -5846.398828125\n",
      "                , loss2: 107.73580322265624\n",
      "=================================\n",
      "in 12050 epoch, average loss: -58514.21875\n",
      "                , loss1: -5860.78828125\n",
      "                , loss2: 93.66389770507813\n",
      "=================================\n",
      "in 12060 epoch, average loss: -58424.00625\n",
      "                , loss1: -5847.278515625\n",
      "                , loss2: 48.7771240234375\n",
      "=================================\n",
      "in 12070 epoch, average loss: -58491.0375\n",
      "                , loss1: -5852.228125\n",
      "                , loss2: 31.238079833984376\n",
      "=================================\n",
      "in 12080 epoch, average loss: -58370.13125\n",
      "                , loss1: -5855.65078125\n",
      "                , loss2: 186.37904052734376\n",
      "=================================\n",
      "in 12090 epoch, average loss: -58413.03125\n",
      "                , loss1: -5847.721484375\n",
      "                , loss2: 64.18600463867188\n",
      "=================================\n",
      "in 12100 epoch, average loss: -58271.5\n",
      "                , loss1: -5836.55625\n",
      "                , loss2: 94.05848388671875\n",
      "=================================\n",
      "in 12110 epoch, average loss: -58339.625\n",
      "                , loss1: -5840.08203125\n",
      "                , loss2: 61.186639404296876\n",
      "=================================\n",
      "in 12120 epoch, average loss: -58286.91875\n",
      "                , loss1: -5849.526171875\n",
      "                , loss2: 208.3391845703125\n",
      "=================================\n",
      "in 12130 epoch, average loss: -58329.1875\n",
      "                , loss1: -5850.244140625\n",
      "                , loss2: 173.25533447265624\n",
      "=================================\n",
      "in 12140 epoch, average loss: -58442.20625\n",
      "                , loss1: -5848.233203125\n",
      "                , loss2: 40.11564636230469\n",
      "=================================\n",
      "in 12150 epoch, average loss: -58389.575\n",
      "                , loss1: -5856.414453125\n",
      "                , loss2: 174.57086181640625\n",
      "=================================\n",
      "in 12160 epoch, average loss: -58106.74375\n",
      "                , loss1: -5818.64921875\n",
      "                , loss2: 79.7504150390625\n",
      "=================================\n",
      "in 12170 epoch, average loss: -58462.35\n",
      "                , loss1: -5851.5\n",
      "                , loss2: 52.65504150390625\n",
      "=================================\n",
      "in 12180 epoch, average loss: -58448.75\n",
      "                , loss1: -5851.503125\n",
      "                , loss2: 66.28133544921874\n",
      "=================================\n",
      "in 12190 epoch, average loss: -58267.60625\n",
      "                , loss1: -5842.028515625\n",
      "                , loss2: 152.66893310546874\n",
      "=================================\n",
      "in 12200 epoch, average loss: -58332.5625\n",
      "                , loss1: -5855.48828125\n",
      "                , loss2: 222.3259765625\n",
      "=================================\n",
      "in 12210 epoch, average loss: -58449.24375\n",
      "                , loss1: -5852.0734375\n",
      "                , loss2: 71.48349609375\n",
      "=================================\n",
      "in 12220 epoch, average loss: -58488.31875\n",
      "                , loss1: -5851.765234375\n",
      "                , loss2: 29.330230712890625\n",
      "=================================\n",
      "in 12230 epoch, average loss: -58476.875\n",
      "                , loss1: -5852.707421875\n",
      "                , loss2: 50.200384521484374\n",
      "=================================\n",
      "in 12240 epoch, average loss: -58383.54375\n",
      "                , loss1: -5854.33515625\n",
      "                , loss2: 159.81229248046876\n",
      "=================================\n",
      "in 12250 epoch, average loss: -58492.60625\n",
      "                , loss1: -5860.742578125\n",
      "                , loss2: 114.8196044921875\n",
      "=================================\n",
      "in 12260 epoch, average loss: -58479.64375\n",
      "                , loss1: -5855.0578125\n",
      "                , loss2: 70.93595581054687\n",
      "=================================\n",
      "in 12270 epoch, average loss: -58526.08125\n",
      "                , loss1: -5855.498046875\n",
      "                , loss2: 28.898760986328124\n",
      "=================================\n",
      "in 12280 epoch, average loss: -58326.3625\n",
      "                , loss1: -5861.38671875\n",
      "                , loss2: 287.4995361328125\n",
      "=================================\n",
      "in 12290 epoch, average loss: -58455.8125\n",
      "                , loss1: -5851.791015625\n",
      "                , loss2: 62.0963134765625\n",
      "=================================\n",
      "in 12300 epoch, average loss: -58375.15625\n",
      "                , loss1: -5844.29609375\n",
      "                , loss2: 67.81095581054687\n",
      "=================================\n",
      "in 12310 epoch, average loss: -58222.0875\n",
      "                , loss1: -5844.171875\n",
      "                , loss2: 219.6290283203125\n",
      "=================================\n",
      "in 12320 epoch, average loss: -58459.175\n",
      "                , loss1: -5851.599609375\n",
      "                , loss2: 56.82119140625\n",
      "=================================\n",
      "in 12330 epoch, average loss: -58531.1\n",
      "                , loss1: -5854.73984375\n",
      "                , loss2: 16.293977355957033\n",
      "=================================\n",
      "in 12340 epoch, average loss: -58396.425\n",
      "                , loss1: -5853.44140625\n",
      "                , loss2: 137.9914306640625\n",
      "=================================\n",
      "in 12350 epoch, average loss: -58504.60625\n",
      "                , loss1: -5854.4125\n",
      "                , loss2: 39.52171020507812\n",
      "=================================\n",
      "in 12360 epoch, average loss: -58446.81875\n",
      "                , loss1: -5853.71484375\n",
      "                , loss2: 90.32667236328125\n",
      "=================================\n",
      "in 12370 epoch, average loss: -58506.3\n",
      "                , loss1: -5855.821484375\n",
      "                , loss2: 51.91561279296875\n",
      "=================================\n",
      "in 12380 epoch, average loss: -58492.5875\n",
      "                , loss1: -5856.765625\n",
      "                , loss2: 75.06661987304688\n",
      "=================================\n",
      "in 12390 epoch, average loss: -58365.98125\n",
      "                , loss1: -5843.6234375\n",
      "                , loss2: 70.2499755859375\n",
      "=================================\n",
      "in 12400 epoch, average loss: -58306.40625\n",
      "                , loss1: -5843.64296875\n",
      "                , loss2: 130.0179931640625\n",
      "=================================\n",
      "in 12410 epoch, average loss: -58478.2375\n",
      "                , loss1: -5856.1046875\n",
      "                , loss2: 82.80368041992188\n",
      "=================================\n",
      "in 12420 epoch, average loss: -58558.4375\n",
      "                , loss1: -5865.438671875\n",
      "                , loss2: 95.95658569335937\n",
      "=================================\n",
      "in 12430 epoch, average loss: -58535.74375\n",
      "                , loss1: -5857.95703125\n",
      "                , loss2: 43.82239990234375\n",
      "=================================\n",
      "in 12440 epoch, average loss: -58559.2875\n",
      "                , loss1: -5858.1015625\n",
      "                , loss2: 21.7361328125\n",
      "=================================\n",
      "in 12450 epoch, average loss: -58486.1\n",
      "                , loss1: -5855.04296875\n",
      "                , loss2: 64.33084106445312\n",
      "=================================\n",
      "in 12460 epoch, average loss: -58506.5875\n",
      "                , loss1: -5856.205078125\n",
      "                , loss2: 55.46482543945312\n",
      "=================================\n",
      "in 12470 epoch, average loss: -58410.93125\n",
      "                , loss1: -5849.2421875\n",
      "                , loss2: 81.48574829101562\n",
      "=================================\n",
      "in 12480 epoch, average loss: -58370.23125\n",
      "                , loss1: -5844.95546875\n",
      "                , loss2: 79.318359375\n",
      "=================================\n",
      "in 12490 epoch, average loss: -58513.63125\n",
      "                , loss1: -5861.43046875\n",
      "                , loss2: 100.66689453125\n",
      "=================================\n",
      "in 12500 epoch, average loss: -58380.7375\n",
      "                , loss1: -5847.016796875\n",
      "                , loss2: 89.42713012695313\n",
      "=================================\n",
      "in 12510 epoch, average loss: -58541.7875\n",
      "                , loss1: -5859.09140625\n",
      "                , loss2: 49.12498168945312\n",
      "=================================\n",
      "in 12520 epoch, average loss: -58359.3625\n",
      "                , loss1: -5855.929296875\n",
      "                , loss2: 199.9312744140625\n",
      "=================================\n",
      "in 12530 epoch, average loss: -58378.43125\n",
      "                , loss1: -5852.584375\n",
      "                , loss2: 147.419921875\n",
      "=================================\n",
      "in 12540 epoch, average loss: -58393.45625\n",
      "                , loss1: -5860.06484375\n",
      "                , loss2: 207.1937744140625\n",
      "=================================\n",
      "in 12550 epoch, average loss: -58480.41875\n",
      "                , loss1: -5856.82890625\n",
      "                , loss2: 87.86470947265624\n",
      "=================================\n",
      "in 12560 epoch, average loss: -58513.325\n",
      "                , loss1: -5856.505078125\n",
      "                , loss2: 51.72581787109375\n",
      "=================================\n",
      "in 12570 epoch, average loss: -58506.75\n",
      "                , loss1: -5855.9109375\n",
      "                , loss2: 52.361236572265625\n",
      "=================================\n",
      "in 12580 epoch, average loss: -58572.6625\n",
      "                , loss1: -5862.734765625\n",
      "                , loss2: 54.691650390625\n",
      "=================================\n",
      "in 12590 epoch, average loss: -58572.6375\n",
      "                , loss1: -5863.98515625\n",
      "                , loss2: 67.21411743164063\n",
      "=================================\n",
      "in 12600 epoch, average loss: -58542.76875\n",
      "                , loss1: -5860.087890625\n",
      "                , loss2: 58.10274658203125\n",
      "=================================\n",
      "in 12610 epoch, average loss: -58506.2\n",
      "                , loss1: -5860.2046875\n",
      "                , loss2: 95.8476318359375\n",
      "=================================\n",
      "in 12620 epoch, average loss: -58578.05625\n",
      "                , loss1: -5863.30546875\n",
      "                , loss2: 54.99246826171875\n",
      "=================================\n",
      "in 12630 epoch, average loss: -58594.0375\n",
      "                , loss1: -5862.737890625\n",
      "                , loss2: 33.33694763183594\n",
      "=================================\n",
      "in 12640 epoch, average loss: -58442.1375\n",
      "                , loss1: -5857.662109375\n",
      "                , loss2: 134.48109130859376\n",
      "=================================\n",
      "in 12650 epoch, average loss: -58590.625\n",
      "                , loss1: -5861.979296875\n",
      "                , loss2: 29.17049560546875\n",
      "=================================\n",
      "in 12660 epoch, average loss: -58593.0875\n",
      "                , loss1: -5865.894921875\n",
      "                , loss2: 65.8603515625\n",
      "=================================\n",
      "in 12670 epoch, average loss: -58208.8125\n",
      "                , loss1: -5835.191015625\n",
      "                , loss2: 143.09661865234375\n",
      "=================================\n",
      "in 12680 epoch, average loss: -58441.03125\n",
      "                , loss1: -5853.53125\n",
      "                , loss2: 94.2767578125\n",
      "=================================\n",
      "in 12690 epoch, average loss: -58456.01875\n",
      "                , loss1: -5849.338671875\n",
      "                , loss2: 37.362326049804686\n",
      "=================================\n",
      "in 12700 epoch, average loss: -58430.6625\n",
      "                , loss1: -5853.52578125\n",
      "                , loss2: 104.5936767578125\n",
      "=================================\n",
      "in 12710 epoch, average loss: -58485.6\n",
      "                , loss1: -5856.457421875\n",
      "                , loss2: 78.97281494140626\n",
      "=================================\n",
      "in 12720 epoch, average loss: -58437.34375\n",
      "                , loss1: -5854.644140625\n",
      "                , loss2: 109.09234619140625\n",
      "=================================\n",
      "in 12730 epoch, average loss: -58464.35\n",
      "                , loss1: -5855.2859375\n",
      "                , loss2: 88.51138305664062\n",
      "=================================\n",
      "in 12740 epoch, average loss: -58494.45\n",
      "                , loss1: -5859.991015625\n",
      "                , loss2: 105.45733642578125\n",
      "=================================\n",
      "in 12750 epoch, average loss: -58538.98125\n",
      "                , loss1: -5858.66015625\n",
      "                , loss2: 47.62568359375\n",
      "=================================\n",
      "in 12760 epoch, average loss: -58552.40625\n",
      "                , loss1: -5861.329296875\n",
      "                , loss2: 60.89002685546875\n",
      "=================================\n",
      "in 12770 epoch, average loss: -58467.1125\n",
      "                , loss1: -5850.618359375\n",
      "                , loss2: 39.06819458007813\n",
      "=================================\n",
      "in 12780 epoch, average loss: -58514.16875\n",
      "                , loss1: -5857.72265625\n",
      "                , loss2: 63.0531982421875\n",
      "=================================\n",
      "in 12790 epoch, average loss: -58537.4625\n",
      "                , loss1: -5864.11484375\n",
      "                , loss2: 103.68607177734376\n",
      "=================================\n",
      "in 12800 epoch, average loss: -58598.89375\n",
      "                , loss1: -5866.173828125\n",
      "                , loss2: 62.839971923828124\n",
      "=================================\n",
      "in 12810 epoch, average loss: -58545.94375\n",
      "                , loss1: -5860.01328125\n",
      "                , loss2: 54.186956787109374\n",
      "=================================\n",
      "in 12820 epoch, average loss: -58480.875\n",
      "                , loss1: -5859.20546875\n",
      "                , loss2: 111.17205810546875\n",
      "=================================\n",
      "in 12830 epoch, average loss: -58490.475\n",
      "                , loss1: -5860.49765625\n",
      "                , loss2: 114.4979248046875\n",
      "=================================\n",
      "in 12840 epoch, average loss: -58593.08125\n",
      "                , loss1: -5861.9125\n",
      "                , loss2: 26.03905334472656\n",
      "=================================\n",
      "in 12850 epoch, average loss: -58584.06875\n",
      "                , loss1: -5860.0484375\n",
      "                , loss2: 16.421463012695312\n",
      "=================================\n",
      "in 12860 epoch, average loss: -58564.5\n",
      "                , loss1: -5859.205078125\n",
      "                , loss2: 27.549258422851562\n",
      "=================================\n",
      "in 12870 epoch, average loss: -58465.91875\n",
      "                , loss1: -5851.16640625\n",
      "                , loss2: 45.743408203125\n",
      "=================================\n",
      "in 12880 epoch, average loss: -58418.83125\n",
      "                , loss1: -5856.454296875\n",
      "                , loss2: 145.71671142578126\n",
      "=================================\n",
      "in 12890 epoch, average loss: -58350.2125\n",
      "                , loss1: -5843.093359375\n",
      "                , loss2: 80.7203125\n",
      "=================================\n",
      "in 12900 epoch, average loss: -58474.3875\n",
      "                , loss1: -5859.79140625\n",
      "                , loss2: 123.5315185546875\n",
      "=================================\n",
      "in 12910 epoch, average loss: -58447.7125\n",
      "                , loss1: -5856.175390625\n",
      "                , loss2: 114.03402099609374\n",
      "=================================\n",
      "in 12920 epoch, average loss: -58487.4\n",
      "                , loss1: -5851.464453125\n",
      "                , loss2: 27.24833984375\n",
      "=================================\n",
      "in 12930 epoch, average loss: -58487.3125\n",
      "                , loss1: -5854.38671875\n",
      "                , loss2: 56.5560791015625\n",
      "=================================\n",
      "in 12940 epoch, average loss: -58448.95625\n",
      "                , loss1: -5851.8703125\n",
      "                , loss2: 69.74996948242188\n",
      "=================================\n",
      "in 12950 epoch, average loss: -58441.46875\n",
      "                , loss1: -5847.7625\n",
      "                , loss2: 36.15653076171875\n",
      "=================================\n",
      "in 12960 epoch, average loss: -58525.14375\n",
      "                , loss1: -5858.467578125\n",
      "                , loss2: 59.53380126953125\n",
      "=================================\n",
      "in 12970 epoch, average loss: -58524.625\n",
      "                , loss1: -5861.60234375\n",
      "                , loss2: 91.39998168945313\n",
      "=================================\n",
      "in 12980 epoch, average loss: -58525.85625\n",
      "                , loss1: -5857.351171875\n",
      "                , loss2: 47.65174560546875\n",
      "=================================\n",
      "in 12990 epoch, average loss: -58464.2875\n",
      "                , loss1: -5853.247265625\n",
      "                , loss2: 68.18931884765625\n",
      "=================================\n",
      "in 13000 epoch, average loss: -58495.9\n",
      "                , loss1: -5858.516796875\n",
      "                , loss2: 89.27296752929688\n",
      "=================================\n",
      "in 13010 epoch, average loss: -58499.16875\n",
      "                , loss1: -5853.481640625\n",
      "                , loss2: 35.652505493164064\n",
      "=================================\n",
      "in 13020 epoch, average loss: -58464.3625\n",
      "                , loss1: -5861.36796875\n",
      "                , loss2: 149.3111083984375\n",
      "=================================\n",
      "in 13030 epoch, average loss: -58334.55\n",
      "                , loss1: -5852.465625\n",
      "                , loss2: 190.1089111328125\n",
      "=================================\n",
      "in 13040 epoch, average loss: -58497.125\n",
      "                , loss1: -5856.465234375\n",
      "                , loss2: 67.52609252929688\n",
      "=================================\n",
      "in 13050 epoch, average loss: -58361.425\n",
      "                , loss1: -5845.1578125\n",
      "                , loss2: 90.15167236328125\n",
      "=================================\n",
      "in 13060 epoch, average loss: -58511.93125\n",
      "                , loss1: -5858.83125\n",
      "                , loss2: 76.3810791015625\n",
      "=================================\n",
      "in 13070 epoch, average loss: -58450.5875\n",
      "                , loss1: -5852.5015625\n",
      "                , loss2: 74.4251220703125\n",
      "=================================\n",
      "in 13080 epoch, average loss: -58505.4375\n",
      "                , loss1: -5856.158984375\n",
      "                , loss2: 56.15407104492188\n",
      "=================================\n",
      "in 13090 epoch, average loss: -58485.00625\n",
      "                , loss1: -5861.0765625\n",
      "                , loss2: 125.756494140625\n",
      "=================================\n",
      "in 13100 epoch, average loss: -58521.75\n",
      "                , loss1: -5857.9703125\n",
      "                , loss2: 57.95206298828125\n",
      "=================================\n",
      "in 13110 epoch, average loss: -58515.56875\n",
      "                , loss1: -5860.7140625\n",
      "                , loss2: 91.57589111328124\n",
      "=================================\n",
      "in 13120 epoch, average loss: -58502.89375\n",
      "                , loss1: -5854.95546875\n",
      "                , loss2: 46.66307373046875\n",
      "=================================\n",
      "in 13130 epoch, average loss: -58477.88125\n",
      "                , loss1: -5853.070703125\n",
      "                , loss2: 52.8243408203125\n",
      "=================================\n",
      "in 13140 epoch, average loss: -58510.6375\n",
      "                , loss1: -5859.55390625\n",
      "                , loss2: 84.90318603515625\n",
      "=================================\n",
      "in 13150 epoch, average loss: -58545.13125\n",
      "                , loss1: -5858.8625\n",
      "                , loss2: 43.49281005859375\n",
      "=================================\n",
      "in 13160 epoch, average loss: -58530.8\n",
      "                , loss1: -5856.391015625\n",
      "                , loss2: 33.11039733886719\n",
      "=================================\n",
      "in 13170 epoch, average loss: -58500.48125\n",
      "                , loss1: -5862.967578125\n",
      "                , loss2: 129.19527587890624\n",
      "=================================\n",
      "in 13180 epoch, average loss: -58507.0875\n",
      "                , loss1: -5864.858203125\n",
      "                , loss2: 141.490869140625\n",
      "=================================\n",
      "in 13190 epoch, average loss: -58430.6625\n",
      "                , loss1: -5850.1265625\n",
      "                , loss2: 70.60879516601562\n",
      "=================================\n",
      "in 13200 epoch, average loss: -58107.025\n",
      "                , loss1: -5830.948828125\n",
      "                , loss2: 202.4693359375\n",
      "=================================\n",
      "in 13210 epoch, average loss: -58205.475\n",
      "                , loss1: -5836.58671875\n",
      "                , loss2: 160.39013671875\n",
      "=================================\n",
      "in 13220 epoch, average loss: -58366.29375\n",
      "                , loss1: -5845.95078125\n",
      "                , loss2: 93.214599609375\n",
      "=================================\n",
      "in 13230 epoch, average loss: -58517.75\n",
      "                , loss1: -5862.10234375\n",
      "                , loss2: 103.2706787109375\n",
      "=================================\n",
      "in 13240 epoch, average loss: -58533.1\n",
      "                , loss1: -5856.63203125\n",
      "                , loss2: 33.222021484375\n",
      "=================================\n",
      "in 13250 epoch, average loss: -58577.5875\n",
      "                , loss1: -5859.934765625\n",
      "                , loss2: 21.759255981445314\n",
      "=================================\n",
      "in 13260 epoch, average loss: -58539.2625\n",
      "                , loss1: -5859.337890625\n",
      "                , loss2: 54.12431030273437\n",
      "=================================\n",
      "in 13270 epoch, average loss: -58536.14375\n",
      "                , loss1: -5855.97578125\n",
      "                , loss2: 23.607888793945314\n",
      "=================================\n",
      "in 13280 epoch, average loss: -58532.125\n",
      "                , loss1: -5856.7859375\n",
      "                , loss2: 35.72655029296875\n",
      "=================================\n",
      "in 13290 epoch, average loss: -58317.00625\n",
      "                , loss1: -5845.71328125\n",
      "                , loss2: 140.129638671875\n",
      "=================================\n",
      "in 13300 epoch, average loss: -58223.4875\n",
      "                , loss1: -5839.21015625\n",
      "                , loss2: 168.61953125\n",
      "=================================\n",
      "in 13310 epoch, average loss: -58268.0125\n",
      "                , loss1: -5838.234765625\n",
      "                , loss2: 114.3430419921875\n",
      "=================================\n",
      "in 13320 epoch, average loss: -58372.3625\n",
      "                , loss1: -5846.17421875\n",
      "                , loss2: 89.384375\n",
      "=================================\n",
      "in 13330 epoch, average loss: -58402.05625\n",
      "                , loss1: -5851.586328125\n",
      "                , loss2: 113.8048583984375\n",
      "=================================\n",
      "in 13340 epoch, average loss: -58278.55\n",
      "                , loss1: -5842.712109375\n",
      "                , loss2: 148.5646484375\n",
      "=================================\n",
      "in 13350 epoch, average loss: -58314.0875\n",
      "                , loss1: -5840.51640625\n",
      "                , loss2: 91.077734375\n",
      "=================================\n",
      "in 13360 epoch, average loss: -58343.725\n",
      "                , loss1: -5849.125390625\n",
      "                , loss2: 147.53770751953124\n",
      "=================================\n",
      "in 13370 epoch, average loss: -58380.275\n",
      "                , loss1: -5848.333203125\n",
      "                , loss2: 103.0558837890625\n",
      "=================================\n",
      "in 13380 epoch, average loss: -58355.8\n",
      "                , loss1: -5840.426171875\n",
      "                , loss2: 48.466983032226565\n",
      "=================================\n",
      "in 13390 epoch, average loss: -58482.975\n",
      "                , loss1: -5853.260546875\n",
      "                , loss2: 49.63233337402344\n",
      "=================================\n",
      "in 13400 epoch, average loss: -58501.4875\n",
      "                , loss1: -5854.358203125\n",
      "                , loss2: 42.096612548828126\n",
      "=================================\n",
      "in 13410 epoch, average loss: -58424.3875\n",
      "                , loss1: -5845.471875\n",
      "                , loss2: 30.331460571289064\n",
      "=================================\n",
      "in 13420 epoch, average loss: -58427.625\n",
      "                , loss1: -5851.9234375\n",
      "                , loss2: 91.61116943359374\n",
      "=================================\n",
      "in 13430 epoch, average loss: -58526.9625\n",
      "                , loss1: -5856.76640625\n",
      "                , loss2: 40.70527038574219\n",
      "=================================\n",
      "in 13440 epoch, average loss: -58535.9375\n",
      "                , loss1: -5856.325390625\n",
      "                , loss2: 27.321438598632813\n",
      "=================================\n",
      "in 13450 epoch, average loss: -58486.775\n",
      "                , loss1: -5855.113671875\n",
      "                , loss2: 64.358642578125\n",
      "=================================\n",
      "in 13460 epoch, average loss: -58427.25\n",
      "                , loss1: -5848.662109375\n",
      "                , loss2: 59.3630615234375\n",
      "=================================\n",
      "in 13470 epoch, average loss: -58316.925\n",
      "                , loss1: -5847.701171875\n",
      "                , loss2: 160.089013671875\n",
      "=================================\n",
      "in 13480 epoch, average loss: -58401.7375\n",
      "                , loss1: -5844.6453125\n",
      "                , loss2: 44.71284484863281\n",
      "=================================\n",
      "in 13490 epoch, average loss: -58462.8125\n",
      "                , loss1: -5856.683984375\n",
      "                , loss2: 104.03387451171875\n",
      "=================================\n",
      "in 13500 epoch, average loss: -58536.08125\n",
      "                , loss1: -5861.16640625\n",
      "                , loss2: 75.58562622070312\n",
      "=================================\n",
      "in 13510 epoch, average loss: -58319.325\n",
      "                , loss1: -5855.680078125\n",
      "                , loss2: 237.4717529296875\n",
      "=================================\n",
      "in 13520 epoch, average loss: -58479.00625\n",
      "                , loss1: -5865.440234375\n",
      "                , loss2: 175.39112548828126\n",
      "=================================\n",
      "in 13530 epoch, average loss: -58379.74375\n",
      "                , loss1: -5844.746484375\n",
      "                , loss2: 67.71571044921875\n",
      "=================================\n",
      "in 13540 epoch, average loss: -58289.5\n",
      "                , loss1: -5852.50859375\n",
      "                , loss2: 235.582861328125\n",
      "=================================\n",
      "in 13550 epoch, average loss: -58075.5375\n",
      "                , loss1: -5820.916796875\n",
      "                , loss2: 133.62879638671876\n",
      "=================================\n",
      "in 13560 epoch, average loss: -58403.20625\n",
      "                , loss1: -5846.17265625\n",
      "                , loss2: 58.51217041015625\n",
      "=================================\n",
      "in 13570 epoch, average loss: -58418.44375\n",
      "                , loss1: -5853.5546875\n",
      "                , loss2: 117.10667724609375\n",
      "=================================\n",
      "in 13580 epoch, average loss: -58351.99375\n",
      "                , loss1: -5839.7265625\n",
      "                , loss2: 45.27102355957031\n",
      "=================================\n",
      "in 13590 epoch, average loss: -58449.06875\n",
      "                , loss1: -5850.4859375\n",
      "                , loss2: 55.795233154296874\n",
      "=================================\n",
      "in 13600 epoch, average loss: -58372.225\n",
      "                , loss1: -5850.3171875\n",
      "                , loss2: 130.94580078125\n",
      "=================================\n",
      "in 13610 epoch, average loss: -58496.34375\n",
      "                , loss1: -5855.556640625\n",
      "                , loss2: 59.2161865234375\n",
      "=================================\n",
      "in 13620 epoch, average loss: -58531.5875\n",
      "                , loss1: -5857.30078125\n",
      "                , loss2: 41.431402587890624\n",
      "=================================\n",
      "in 13630 epoch, average loss: -58511.7625\n",
      "                , loss1: -5856.20546875\n",
      "                , loss2: 50.291571044921874\n",
      "=================================\n",
      "in 13640 epoch, average loss: -58404.3375\n",
      "                , loss1: -5845.628515625\n",
      "                , loss2: 51.952606201171875\n",
      "=================================\n",
      "in 13650 epoch, average loss: -58350.68125\n",
      "                , loss1: -5842.22421875\n",
      "                , loss2: 71.55455932617187\n",
      "=================================\n",
      "in 13660 epoch, average loss: -58234.6375\n",
      "                , loss1: -5838.4640625\n",
      "                , loss2: 150.00416259765626\n",
      "=================================\n",
      "in 13670 epoch, average loss: -58281.90625\n",
      "                , loss1: -5842.50078125\n",
      "                , loss2: 143.10291748046876\n",
      "=================================\n",
      "in 13680 epoch, average loss: -58153.56875\n",
      "                , loss1: -5832.009375\n",
      "                , loss2: 166.52501220703124\n",
      "=================================\n",
      "in 13690 epoch, average loss: -58423.48125\n",
      "                , loss1: -5852.21015625\n",
      "                , loss2: 98.61384887695313\n",
      "=================================\n",
      "in 13700 epoch, average loss: -58377.26875\n",
      "                , loss1: -5848.062109375\n",
      "                , loss2: 103.34990234375\n",
      "=================================\n",
      "in 13710 epoch, average loss: -58446.05625\n",
      "                , loss1: -5850.830859375\n",
      "                , loss2: 62.24832763671875\n",
      "=================================\n",
      "in 13720 epoch, average loss: -58329.7375\n",
      "                , loss1: -5842.31796875\n",
      "                , loss2: 93.43922729492188\n",
      "=================================\n",
      "in 13730 epoch, average loss: -58450.2625\n",
      "                , loss1: -5859.046875\n",
      "                , loss2: 140.20902099609376\n",
      "=================================\n",
      "in 13740 epoch, average loss: -58557.73125\n",
      "                , loss1: -5859.921484375\n",
      "                , loss2: 41.48768615722656\n",
      "=================================\n",
      "in 13750 epoch, average loss: -58485.3\n",
      "                , loss1: -5852.29921875\n",
      "                , loss2: 37.69668273925781\n",
      "=================================\n",
      "in 13760 epoch, average loss: -58545.99375\n",
      "                , loss1: -5865.128515625\n",
      "                , loss2: 105.2951904296875\n",
      "=================================\n",
      "in 13770 epoch, average loss: -58565.55\n",
      "                , loss1: -5862.788671875\n",
      "                , loss2: 62.342718505859374\n",
      "=================================\n",
      "in 13780 epoch, average loss: -58511.8\n",
      "                , loss1: -5856.93359375\n",
      "                , loss2: 57.53927001953125\n",
      "=================================\n",
      "in 13790 epoch, average loss: -58535.00625\n",
      "                , loss1: -5862.93515625\n",
      "                , loss2: 94.3508544921875\n",
      "=================================\n",
      "in 13800 epoch, average loss: -58490.325\n",
      "                , loss1: -5855.628125\n",
      "                , loss2: 65.95628051757812\n",
      "=================================\n",
      "in 13810 epoch, average loss: -58542.625\n",
      "                , loss1: -5860.495703125\n",
      "                , loss2: 62.32679443359375\n",
      "=================================\n",
      "in 13820 epoch, average loss: -58556.7125\n",
      "                , loss1: -5862.690234375\n",
      "                , loss2: 70.19425659179687\n",
      "=================================\n",
      "in 13830 epoch, average loss: -58529.6375\n",
      "                , loss1: -5856.990625\n",
      "                , loss2: 40.264706420898435\n",
      "=================================\n",
      "in 13840 epoch, average loss: -58554.31875\n",
      "                , loss1: -5862.076953125\n",
      "                , loss2: 66.45092163085937\n",
      "=================================\n",
      "in 13850 epoch, average loss: -58593.05\n",
      "                , loss1: -5864.7359375\n",
      "                , loss2: 54.309014892578126\n",
      "=================================\n",
      "in 13860 epoch, average loss: -58587.9875\n",
      "                , loss1: -5860.927734375\n",
      "                , loss2: 21.286521911621094\n",
      "=================================\n",
      "in 13870 epoch, average loss: -58568.31875\n",
      "                , loss1: -5860.005078125\n",
      "                , loss2: 31.738629150390626\n",
      "=================================\n",
      "in 13880 epoch, average loss: -58633.76875\n",
      "                , loss1: -5867.4828125\n",
      "                , loss2: 41.06250915527344\n",
      "=================================\n",
      "in 13890 epoch, average loss: -58529.54375\n",
      "                , loss1: -5857.66484375\n",
      "                , loss2: 47.11217346191406\n",
      "=================================\n",
      "in 13900 epoch, average loss: -58613.45625\n",
      "                , loss1: -5865.6125\n",
      "                , loss2: 42.6666748046875\n",
      "=================================\n",
      "in 13910 epoch, average loss: -58593.275\n",
      "                , loss1: -5861.933203125\n",
      "                , loss2: 26.062136840820312\n",
      "=================================\n",
      "in 13920 epoch, average loss: -58566.8\n",
      "                , loss1: -5866.116015625\n",
      "                , loss2: 94.3563232421875\n",
      "=================================\n",
      "in 13930 epoch, average loss: -58578.08125\n",
      "                , loss1: -5866.280078125\n",
      "                , loss2: 84.7209716796875\n",
      "=================================\n",
      "in 13940 epoch, average loss: -58614.325\n",
      "                , loss1: -5865.273046875\n",
      "                , loss2: 38.40902099609375\n",
      "=================================\n",
      "in 13950 epoch, average loss: -58643.23125\n",
      "                , loss1: -5868.6875\n",
      "                , loss2: 43.64375610351563\n",
      "=================================\n",
      "in 13960 epoch, average loss: -58618.7\n",
      "                , loss1: -5864.4625\n",
      "                , loss2: 25.927960205078126\n",
      "=================================\n",
      "in 13970 epoch, average loss: -58621.68125\n",
      "                , loss1: -5864.940625\n",
      "                , loss2: 27.732498168945312\n",
      "=================================\n",
      "in 13980 epoch, average loss: -58594.11875\n",
      "                , loss1: -5863.966015625\n",
      "                , loss2: 45.55040283203125\n",
      "=================================\n",
      "in 13990 epoch, average loss: -58629.025\n",
      "                , loss1: -5864.74453125\n",
      "                , loss2: 18.417453002929687\n",
      "=================================\n",
      "in 14000 epoch, average loss: -58606.7625\n",
      "                , loss1: -5865.5203125\n",
      "                , loss2: 48.4456787109375\n",
      "=================================\n",
      "in 14010 epoch, average loss: -58513.54375\n",
      "                , loss1: -5860.548046875\n",
      "                , loss2: 91.93125610351562\n",
      "=================================\n",
      "in 14020 epoch, average loss: -58502.425\n",
      "                , loss1: -5857.15\n",
      "                , loss2: 69.07013549804688\n",
      "=================================\n",
      "in 14030 epoch, average loss: -58559.4\n",
      "                , loss1: -5862.9375\n",
      "                , loss2: 69.96331176757812\n",
      "=================================\n",
      "in 14040 epoch, average loss: -58341.15625\n",
      "                , loss1: -5854.99453125\n",
      "                , loss2: 208.7985107421875\n",
      "=================================\n",
      "in 14050 epoch, average loss: -58291.2375\n",
      "                , loss1: -5842.480078125\n",
      "                , loss2: 133.559765625\n",
      "=================================\n",
      "in 14060 epoch, average loss: -58521.43125\n",
      "                , loss1: -5864.784375\n",
      "                , loss2: 126.415087890625\n",
      "=================================\n",
      "in 14070 epoch, average loss: -58603.9125\n",
      "                , loss1: -5865.6859375\n",
      "                , loss2: 52.9520263671875\n",
      "=================================\n",
      "in 14080 epoch, average loss: -58504.9625\n",
      "                , loss1: -5855.50703125\n",
      "                , loss2: 50.10145874023438\n",
      "=================================\n",
      "in 14090 epoch, average loss: -58605.55625\n",
      "                , loss1: -5866.502734375\n",
      "                , loss2: 59.475457763671876\n",
      "=================================\n",
      "in 14100 epoch, average loss: -58579.48125\n",
      "                , loss1: -5865.315625\n",
      "                , loss2: 73.67215576171876\n",
      "=================================\n",
      "in 14110 epoch, average loss: -58534.5125\n",
      "                , loss1: -5871.49609375\n",
      "                , loss2: 180.45050048828125\n",
      "=================================\n",
      "in 14120 epoch, average loss: -58569.53125\n",
      "                , loss1: -5864.880078125\n",
      "                , loss2: 79.27000732421875\n",
      "=================================\n",
      "in 14130 epoch, average loss: -58635.05625\n",
      "                , loss1: -5875.019921875\n",
      "                , loss2: 115.145751953125\n",
      "=================================\n",
      "in 14140 epoch, average loss: -58668.2\n",
      "                , loss1: -5872.202734375\n",
      "                , loss2: 53.832147216796876\n",
      "=================================\n",
      "in 14150 epoch, average loss: -58627.975\n",
      "                , loss1: -5872.378125\n",
      "                , loss2: 95.80653076171875\n",
      "=================================\n",
      "in 14160 epoch, average loss: -58591.325\n",
      "                , loss1: -5871.4953125\n",
      "                , loss2: 123.6270751953125\n",
      "=================================\n",
      "in 14170 epoch, average loss: -58493.975\n",
      "                , loss1: -5862.36328125\n",
      "                , loss2: 129.662548828125\n",
      "=================================\n",
      "in 14180 epoch, average loss: -58377.65\n",
      "                , loss1: -5849.747265625\n",
      "                , loss2: 119.81444091796875\n",
      "=================================\n",
      "in 14190 epoch, average loss: -58589.6375\n",
      "                , loss1: -5876.12890625\n",
      "                , loss2: 171.64893798828126\n",
      "=================================\n",
      "in 14200 epoch, average loss: -58691.58125\n",
      "                , loss1: -5874.05703125\n",
      "                , loss2: 48.992062377929685\n",
      "=================================\n",
      "in 14210 epoch, average loss: -58589.05\n",
      "                , loss1: -5864.36953125\n",
      "                , loss2: 54.63941650390625\n",
      "=================================\n",
      "in 14220 epoch, average loss: -58640.35625\n",
      "                , loss1: -5870.9296875\n",
      "                , loss2: 68.94520874023438\n",
      "=================================\n",
      "in 14230 epoch, average loss: -58636.1875\n",
      "                , loss1: -5870.360546875\n",
      "                , loss2: 67.41690673828126\n",
      "=================================\n",
      "in 14240 epoch, average loss: -58584.7875\n",
      "                , loss1: -5864.203125\n",
      "                , loss2: 57.252020263671874\n",
      "=================================\n",
      "in 14250 epoch, average loss: -58589.7625\n",
      "                , loss1: -5866.93359375\n",
      "                , loss2: 79.57156372070312\n",
      "=================================\n",
      "in 14260 epoch, average loss: -58549.1875\n",
      "                , loss1: -5859.63359375\n",
      "                , loss2: 47.145654296875\n",
      "=================================\n",
      "in 14270 epoch, average loss: -58344.1125\n",
      "                , loss1: -5840.19609375\n",
      "                , loss2: 57.84735107421875\n",
      "=================================\n",
      "in 14280 epoch, average loss: -58376.625\n",
      "                , loss1: -5856.0265625\n",
      "                , loss2: 183.6412353515625\n",
      "=================================\n",
      "in 14290 epoch, average loss: -58183.78125\n",
      "                , loss1: -5866.284375\n",
      "                , loss2: 479.0513671875\n",
      "=================================\n",
      "in 14300 epoch, average loss: -58432.30625\n",
      "                , loss1: -5860.769140625\n",
      "                , loss2: 175.3786865234375\n",
      "=================================\n",
      "in 14310 epoch, average loss: -58518.425\n",
      "                , loss1: -5859.087890625\n",
      "                , loss2: 72.45672607421875\n",
      "=================================\n",
      "in 14320 epoch, average loss: -58529.6\n",
      "                , loss1: -5858.33828125\n",
      "                , loss2: 53.788177490234375\n",
      "=================================\n",
      "in 14330 epoch, average loss: -58524.66875\n",
      "                , loss1: -5862.509765625\n",
      "                , loss2: 100.4292724609375\n",
      "=================================\n",
      "in 14340 epoch, average loss: -58590.7875\n",
      "                , loss1: -5863.42578125\n",
      "                , loss2: 43.47261047363281\n",
      "=================================\n",
      "in 14350 epoch, average loss: -58614.15625\n",
      "                , loss1: -5864.080078125\n",
      "                , loss2: 26.640472412109375\n",
      "=================================\n",
      "in 14360 epoch, average loss: -58593.11875\n",
      "                , loss1: -5860.84453125\n",
      "                , loss2: 15.318089294433594\n",
      "=================================\n",
      "in 14370 epoch, average loss: -58097.15\n",
      "                , loss1: -5859.491015625\n",
      "                , loss2: 497.755712890625\n",
      "=================================\n",
      "in 14380 epoch, average loss: -58328.51875\n",
      "                , loss1: -5851.730859375\n",
      "                , loss2: 188.79052734375\n",
      "=================================\n",
      "in 14390 epoch, average loss: -58581.11875\n",
      "                , loss1: -5866.247265625\n",
      "                , loss2: 81.3534423828125\n",
      "=================================\n",
      "in 14400 epoch, average loss: -58256.7875\n",
      "                , loss1: -5843.865625\n",
      "                , loss2: 181.8621337890625\n",
      "=================================\n",
      "in 14410 epoch, average loss: -58359.04375\n",
      "                , loss1: -5863.763671875\n",
      "                , loss2: 278.5961669921875\n",
      "=================================\n",
      "in 14420 epoch, average loss: -58518.1875\n",
      "                , loss1: -5860.241796875\n",
      "                , loss2: 84.22225341796874\n",
      "=================================\n",
      "in 14430 epoch, average loss: -58400.625\n",
      "                , loss1: -5856.378125\n",
      "                , loss2: 163.1555419921875\n",
      "=================================\n",
      "in 14440 epoch, average loss: -58073.0\n",
      "                , loss1: -5839.691796875\n",
      "                , loss2: 323.91640625\n",
      "=================================\n",
      "in 14450 epoch, average loss: -58557.51875\n",
      "                , loss1: -5870.828125\n",
      "                , loss2: 150.7683837890625\n",
      "=================================\n",
      "in 14460 epoch, average loss: -58224.2625\n",
      "                , loss1: -5864.1453125\n",
      "                , loss2: 417.189404296875\n",
      "=================================\n",
      "in 14470 epoch, average loss: -57493.3125\n",
      "                , loss1: -5812.86484375\n",
      "                , loss2: 635.337353515625\n",
      "=================================\n",
      "in 14480 epoch, average loss: -57951.58125\n",
      "                , loss1: -5842.234765625\n",
      "                , loss2: 470.773095703125\n",
      "=================================\n",
      "in 14490 epoch, average loss: -58446.0\n",
      "                , loss1: -5860.0921875\n",
      "                , loss2: 154.91513671875\n",
      "=================================\n",
      "in 14500 epoch, average loss: -58442.0\n",
      "                , loss1: -5867.15078125\n",
      "                , loss2: 229.50966796875\n",
      "=================================\n",
      "in 14510 epoch, average loss: -58583.8375\n",
      "                , loss1: -5873.1546875\n",
      "                , loss2: 147.7085205078125\n",
      "=================================\n",
      "in 14520 epoch, average loss: -58617.99375\n",
      "                , loss1: -5867.674609375\n",
      "                , loss2: 58.747161865234375\n",
      "=================================\n",
      "in 14530 epoch, average loss: -58690.525\n",
      "                , loss1: -5871.4296875\n",
      "                , loss2: 23.77124481201172\n",
      "=================================\n",
      "in 14540 epoch, average loss: -58647.96875\n",
      "                , loss1: -5869.958984375\n",
      "                , loss2: 51.6217529296875\n",
      "=================================\n",
      "in 14550 epoch, average loss: -58582.09375\n",
      "                , loss1: -5877.63359375\n",
      "                , loss2: 194.24056396484374\n",
      "=================================\n",
      "in 14560 epoch, average loss: -58649.01875\n",
      "                , loss1: -5874.560546875\n",
      "                , loss2: 96.58746948242188\n",
      "=================================\n",
      "in 14570 epoch, average loss: -58659.73125\n",
      "                , loss1: -5869.975\n",
      "                , loss2: 40.02039794921875\n",
      "=================================\n",
      "in 14580 epoch, average loss: -58711.71875\n",
      "                , loss1: -5875.584765625\n",
      "                , loss2: 44.11919250488281\n",
      "=================================\n",
      "in 14590 epoch, average loss: -58734.025\n",
      "                , loss1: -5875.82421875\n",
      "                , loss2: 24.217454528808595\n",
      "=================================\n",
      "in 14600 epoch, average loss: -58701.75625\n",
      "                , loss1: -5873.26171875\n",
      "                , loss2: 30.864279174804686\n",
      "=================================\n",
      "in 14610 epoch, average loss: -58640.8125\n",
      "                , loss1: -5873.959765625\n",
      "                , loss2: 98.78023681640624\n",
      "=================================\n",
      "in 14620 epoch, average loss: -58675.78125\n",
      "                , loss1: -5872.584765625\n",
      "                , loss2: 50.069760131835935\n",
      "=================================\n",
      "in 14630 epoch, average loss: -58709.675\n",
      "                , loss1: -5875.483203125\n",
      "                , loss2: 45.16077880859375\n",
      "=================================\n",
      "in 14640 epoch, average loss: -58708.35\n",
      "                , loss1: -5877.721875\n",
      "                , loss2: 68.86971435546874\n",
      "=================================\n",
      "in 14650 epoch, average loss: -58750.36875\n",
      "                , loss1: -5880.444140625\n",
      "                , loss2: 54.0706298828125\n",
      "=================================\n",
      "in 14660 epoch, average loss: -58660.7\n",
      "                , loss1: -5871.302734375\n",
      "                , loss2: 52.33323974609375\n",
      "=================================\n",
      "in 14670 epoch, average loss: -58733.225\n",
      "                , loss1: -5878.44140625\n",
      "                , loss2: 51.191592407226565\n",
      "=================================\n",
      "in 14680 epoch, average loss: -58745.46875\n",
      "                , loss1: -5882.4015625\n",
      "                , loss2: 78.54662475585937\n",
      "=================================\n",
      "in 14690 epoch, average loss: -58621.0875\n",
      "                , loss1: -5866.46796875\n",
      "                , loss2: 43.59510498046875\n",
      "=================================\n",
      "in 14700 epoch, average loss: -58710.3\n",
      "                , loss1: -5874.180859375\n",
      "                , loss2: 31.512478637695313\n",
      "=================================\n",
      "in 14710 epoch, average loss: -58714.65625\n",
      "                , loss1: -5881.74921875\n",
      "                , loss2: 102.838671875\n",
      "=================================\n",
      "in 14720 epoch, average loss: -58689.43125\n",
      "                , loss1: -5887.525390625\n",
      "                , loss2: 185.8155517578125\n",
      "=================================\n",
      "in 14730 epoch, average loss: -58721.3625\n",
      "                , loss1: -5884.7640625\n",
      "                , loss2: 126.2779296875\n",
      "=================================\n",
      "in 14740 epoch, average loss: -58629.325\n",
      "                , loss1: -5868.355859375\n",
      "                , loss2: 54.23756103515625\n",
      "=================================\n",
      "in 14750 epoch, average loss: -58591.93125\n",
      "                , loss1: -5867.96015625\n",
      "                , loss2: 87.673974609375\n",
      "=================================\n",
      "in 14760 epoch, average loss: -58636.2625\n",
      "                , loss1: -5874.156640625\n",
      "                , loss2: 105.30555419921875\n",
      "=================================\n",
      "in 14770 epoch, average loss: -58761.675\n",
      "                , loss1: -5880.223828125\n",
      "                , loss2: 40.56619567871094\n",
      "=================================\n",
      "in 14780 epoch, average loss: -58802.1625\n",
      "                , loss1: -5885.45546875\n",
      "                , loss2: 52.3849365234375\n",
      "=================================\n",
      "in 14790 epoch, average loss: -58748.11875\n",
      "                , loss1: -5882.44765625\n",
      "                , loss2: 76.35631103515625\n",
      "=================================\n",
      "in 14800 epoch, average loss: -58770.8625\n",
      "                , loss1: -5881.802734375\n",
      "                , loss2: 47.169439697265624\n",
      "=================================\n",
      "in 14810 epoch, average loss: -58676.95\n",
      "                , loss1: -5877.28828125\n",
      "                , loss2: 95.93765869140626\n",
      "=================================\n",
      "in 14820 epoch, average loss: -58669.48125\n",
      "                , loss1: -5871.2296875\n",
      "                , loss2: 42.82314758300781\n",
      "=================================\n",
      "in 14830 epoch, average loss: -58709.4125\n",
      "                , loss1: -5882.409375\n",
      "                , loss2: 114.682666015625\n",
      "=================================\n",
      "in 14840 epoch, average loss: -58815.0875\n",
      "                , loss1: -5885.36796875\n",
      "                , loss2: 38.59461364746094\n",
      "=================================\n",
      "in 14850 epoch, average loss: -58734.1\n",
      "                , loss1: -5881.79921875\n",
      "                , loss2: 83.8905029296875\n",
      "=================================\n",
      "in 14860 epoch, average loss: -58749.19375\n",
      "                , loss1: -5883.10546875\n",
      "                , loss2: 81.85928344726562\n",
      "=================================\n",
      "in 14870 epoch, average loss: -58755.53125\n",
      "                , loss1: -5883.862890625\n",
      "                , loss2: 83.09696655273437\n",
      "=================================\n",
      "in 14880 epoch, average loss: -58780.44375\n",
      "                , loss1: -5882.220703125\n",
      "                , loss2: 41.754702758789065\n",
      "=================================\n",
      "in 14890 epoch, average loss: -58782.7375\n",
      "                , loss1: -5880.43046875\n",
      "                , loss2: 21.565896606445314\n",
      "=================================\n",
      "in 14900 epoch, average loss: -58851.08125\n",
      "                , loss1: -5887.965234375\n",
      "                , loss2: 28.57747802734375\n",
      "=================================\n",
      "in 14910 epoch, average loss: -58820.54375\n",
      "                , loss1: -5885.278125\n",
      "                , loss2: 32.239035034179686\n",
      "=================================\n",
      "in 14920 epoch, average loss: -58779.31875\n",
      "                , loss1: -5881.27109375\n",
      "                , loss2: 33.39097595214844\n",
      "=================================\n",
      "in 14930 epoch, average loss: -58734.5625\n",
      "                , loss1: -5879.1984375\n",
      "                , loss2: 57.41781005859375\n",
      "=================================\n",
      "in 14940 epoch, average loss: -58669.68125\n",
      "                , loss1: -5883.453125\n",
      "                , loss2: 164.84613037109375\n",
      "=================================\n",
      "in 14950 epoch, average loss: -58709.8125\n",
      "                , loss1: -5875.8171875\n",
      "                , loss2: 48.362771606445314\n",
      "=================================\n",
      "in 14960 epoch, average loss: -58618.0125\n",
      "                , loss1: -5868.656640625\n",
      "                , loss2: 68.54820556640625\n",
      "=================================\n",
      "in 14970 epoch, average loss: -58663.8875\n",
      "                , loss1: -5883.074609375\n",
      "                , loss2: 166.863037109375\n",
      "=================================\n",
      "in 14980 epoch, average loss: -58723.475\n",
      "                , loss1: -5878.2078125\n",
      "                , loss2: 58.60792236328125\n",
      "=================================\n",
      "in 14990 epoch, average loss: -58639.14375\n",
      "                , loss1: -5879.83125\n",
      "                , loss2: 159.1703369140625\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)\n",
    "for epoch in range(15000):\n",
    "    loss,loss_1,loss_2 = hgnn_trainer.run(epoch=epoch)\n",
    "    # train\n",
    "    temp_loss_total += loss\n",
    "    temp_loss1 += loss_1\n",
    "    temp_loss2 += loss_2\n",
    "    # validation\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"in {epoch} epoch, average loss: {temp_loss_total.item() / 10}\")\n",
    "        print(f\"                , loss1: {temp_loss1.item() / 10}\")\n",
    "        print(f\"                , loss2: {temp_loss2.item() / 10}\")\n",
    "        print(f\"=================================\")\n",
    "        sys.stdout.flush()\n",
    "        temp_loss_total,temp_loss1,temp_loss2 = torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False),torch.zeros(1, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgnn_trainer.eval()\n",
    "outs = hgnn_trainer.forward(hgnn_trainer.X)\n",
    "outs_straight = StraightThroughEstimator.apply(outs)\n",
    "G_clone = G.clone()\n",
    "edges, _  = G_clone.e\n",
    "cut = 0\n",
    "for vertices in edges:\n",
    "    if torch.prod(outs_straight[list(vertices)], dim=0).sum() == 0:\n",
    "        cut += 1\n",
    "    else:\n",
    "        G_clone.remove_hyperedges(vertices)\n",
    "assert cut == G_clone.num_e\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([746., 770., 766., 771., 771.], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = torch.sum(outs_straight, dim = 0)\n",
    "#bs = torch.sum(outs, dim = 0)\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([1., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[0.0,1.,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0]])\n",
    "H = torch.tensor([[1.,1],[1,1],[0,1],[1,1],[0,1],[1,1]])\n",
    "#H = torch.tensor([[0,1.,0,1,0,1],[1,0,1,0,1,1]])\n",
    "nn = torch.matmul(a, (1 - torch.transpose(a, 0, 1)))\n",
    "#ne_k = torch.matmul(nn, H)\n",
    "ne_k = torch.matmul(nn, H)\n",
    "ne_k = ne_k.mul(H)\n",
    "H_degree = torch.sum(H, dim=0)\n",
    "H_degree = H_degree\n",
    "H_1 = ne_k / H_degree\n",
    "    #bs = torch.where(H_1>=1)\n",
    "    #print(bs)\n",
    "a2 = 1 - H_1\n",
    "a2 = a2.sqrt()\n",
    "print('a2:',a2)\n",
    "a3 = torch.prod(a2, dim=0)\n",
    "print(a3)\n",
    "a3 = a3.sum()\n",
    "loss_1 = -1 * a3\n",
    "\n",
    "a3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
